This is pspp.info, produced by makeinfo version 7.1 from pspp.texi.

This manual is for GNU PSPP version 2.0.1, software for statistical
analysis.

   Copyright © 1997, 1998, 2004, 2005, 2009, 2012, 2013, 2014, 2016,
2019, 2020, 2023 Free Software Foundation, Inc.

     Permission is granted to copy, distribute and/or modify this
     document under the terms of the GNU Free Documentation License,
     Version 1.3 or any later version published by the Free Software
     Foundation; with no Invariant Sections, no Front-Cover Texts, and
     no Back-Cover Texts.  A copy of the license is included in the
     section entitled "GNU Free Documentation License".
INFO-DIR-SECTION Math
START-INFO-DIR-ENTRY
* PSPP: (pspp).             Statistical analysis package.
* PSPPIRE: (pspp).          Graphical user interface to PSPP.
END-INFO-DIR-ENTRY


File: pspp.info,  Node: LEAVE,  Prev: MRSETS,  Up: Manipulating Variables

11.21 LEAVE
===========

‘LEAVE’ prevents the specified variables from being reinitialized
whenever a new case is processed.

     LEAVE VAR_LIST.

   Normally, when a data file is processed, every variable in the active
dataset is initialized to the system-missing value or spaces at the
beginning of processing for each case.  When a variable has been
specified on ‘LEAVE’, this is not the case.  Instead, that variable is
initialized to 0 (not system-missing) or spaces for the first case.
After that, it retains its value between cases.

   This becomes useful for counters.  For instance, in the example below
the variable ‘SUM’ maintains a running total of the values in the ‘ITEM’
variable.

     DATA LIST /ITEM 1-3.
     COMPUTE SUM=SUM+ITEM.
     PRINT /ITEM SUM.
     LEAVE SUM
     BEGIN DATA.
     123
     404
     555
     999
     END DATA.

Partial output from this example:

     123   123.00
     404   527.00
     555  1082.00
     999  2081.00

   It is best to use ‘LEAVE’ command immediately before invoking a
procedure command, because the left status of variables is reset by
certain transformations--for instance, ‘COMPUTE’ and ‘IF’.  Left status
is also reset by all procedure invocations.


File: pspp.info,  Node: Data Manipulation,  Next: Data Selection,  Prev: Manipulating Variables,  Up: Top

12 Data transformations
***********************

The PSPP procedures examined in this chapter manipulate data and prepare
the active dataset for later analyses.  They do not produce output, as a
rule.

* Menu:

* AGGREGATE::                   Summarize multiple cases into a single case.
* AUTORECODE::                  Automatic recoding of variables.
* COMPUTE::                     Assigning a variable a calculated value.
* COUNT::                       Counting variables with particular values.
* FLIP::                        Exchange variables with cases.
* IF::                          Conditionally assigning a calculated value.
* RECODE::                      Mapping values from one set to another.
* SORT CASES::                  Sort the active dataset.


File: pspp.info,  Node: AGGREGATE,  Next: AUTORECODE,  Up: Data Manipulation

12.1 AGGREGATE
==============

     AGGREGATE
             [OUTFILE={*,'FILE_NAME',FILE_HANDLE} [MODE={REPLACE,ADDVARIABLES}]]
             [/MISSING=COLUMNWISE]
             [/PRESORTED]
             [/DOCUMENT]
             [/BREAK=VAR_LIST]
             /DEST_VAR['LABEL']...=AGR_FUNC(SRC_VARS[, ARGS]...)...

   ‘AGGREGATE’ summarizes groups of cases into single cases.  It divides
cases into groups that have the same values for one or more variables
called “break variables”.  Several functions are available for
summarizing case contents.

   The ‘AGGREGATE’ syntax consists of subcommands to control its
behavior, all of which are optional, followed by one or more destination
variable assigments, each of which uses an aggregation function to
define how it is calculated.

   The ‘OUTFILE’ subcommand, which must be first, names the destination
for ‘AGGREGATE’ output.  It may name a system file by file name or file
handle (*note File Handles::), a dataset by its name (*note Datasets::),
or ‘*’ to replace the active dataset.  ‘AGGREGATE’ writes its output to
this file.

   With ‘OUTFILE=*’ only, ‘MODE’ may be specified immediately afterward
with the value ‘ADDVARIABLES’ or ‘REPLACE’:

   • With ‘REPLACE’, the default, the active dataset is replaced by a
     new dataset which contains just the break variables and the
     destination varibles.  The new file contains as many cases as there
     are unique combinations of the break variables.

   • With ‘ADDVARIABLES’, the destination variables are added to those
     in the existing active dataset.  Cases that have the same
     combination of values in their break variables receive identical
     values for the destination variables.  The number of cases in the
     active dataset remains unchanged.  The data must be sorted on the
     break variables, that is, ‘ADDVARIABLES’ implies ‘PRESORTED’

   If ‘OUTFILE’ is omitted, ‘AGGREGATE’ acts as if ‘OUTFILE=*
MODE=ADDVARIABLES’ were specified.

   By default, ‘AGGREGATE’ first sorts the data on the break variables.
If the active dataset is already sorted or grouped by the break
variables, specify ‘PRESORTED’ to save time.  With ‘MODE=ADDVARIABLES’,
the data must be pre-sorted.

   Specify ‘DOCUMENT’ to copy the documents from the active dataset into
the aggregate file (*note DOCUMENT::).  Otherwise, the aggregate file
does not contain any documents, even if the aggregate file replaces the
active dataset.

   Normally, ‘AGGREGATE’ produces a non-missing value whenever there is
enough non-missing data for the aggregation function in use, that is,
just one non-missing value or, for the ‘SD’ and ‘SD.’ aggregation
functions, two non-missing values.  Specify ‘/MISSING=COLUMNWISE’ to
make ‘AGGREGATE’ output a missing value when one or more of the input
values are missing.

   The ‘BREAK’ subcommand is optionally but usually present.  On
‘BREAK’, list the variables used to divide the active dataset into
groups to be summarized.

   ‘AGGREGATE’ is particular about the order of subcommands.  ‘OUTFILE’
must be first, followed by ‘MISSING’.  ‘PRESORTED’ and ‘DOCUMENT’ follow
‘MISSING’, in either order, followed by ‘BREAK’, then followed by
aggregation variable specifications.

   At least one set of aggregation variables is required.  Each set
comprises a list of aggregation variables, an equals sign (‘=’), the
name of an aggregation function (see the list below), and a list of
source variables in parentheses.  A few aggregation functions do not
accept source variables, and some aggregation functions expect
additional arguments after the source variable names.

   ‘AGGREGATE’ typically creates aggregation variables with no variable
label, value labels, or missing values.  Their default print and write
formats depend on the aggregation function used, with details given in
the table below.  A variable label for an aggregation variable may be
specified just after the variable's name in the aggregation variable
list.

   Each set must have exactly as many source variables as aggregation
variables.  Each aggregation variable receives the results of applying
the specified aggregation function to the corresponding source variable.

   The following aggregation functions may be applied only to numeric
variables:

‘MEAN(VAR_NAME...)’
     Arithmetic mean.  Limited to numeric values.  The default format is
     F8.2.

‘MEDIAN(VAR_NAME...)’
     The median value.  Limited to numeric values.  The default format
     is F8.2.

‘SD(VAR_NAME...)’
     Standard deviation of the mean.  Limited to numeric values.  The
     default format is F8.2.

‘SUM(VAR_NAME...)’
     Sum.  Limited to numeric values.  The default format is F8.2.

   These aggregation functions may be applied to numeric and string
variables:

‘CGT(VAR_NAME..., VALUE)’
‘CLT(VAR_NAME..., VALUE)’
‘CIN(VAR_NAME..., LOW, HIGH)’
‘COUT(VAR_NAME..., LOW, HIGH)’
     Total weight of cases greater than or less than VALUE or inside or
     outside the closed range [LOW,HIGH], respectively.  The default
     format is F5.3.

‘FGT(VAR_NAME..., VALUE)’
‘FLT(VAR_NAME..., VALUE)’
‘FIN(VAR_NAME..., LOW, HIGH)’
‘FOUT(VAR_NAME..., LOW, HIGH)’
     Fraction of values greater than or less than VALUE or inside or
     outside the closed range [LOW,HIGH], respectively.  The default
     format is F5.3.

‘FIRST(VAR_NAME...)’
‘LAST(VAR_NAME...)’
     First or last non-missing value, respectively, in break group.  The
     aggregation variable receives the complete dictionary information
     from the source variable.  The sort performed by ‘AGGREGATE’ (and
     by ‘SORT CASES’) is stable.  This means that the first (or last)
     case with particular values for the break variables before sorting
     is also the first (or last) case in that break group after sorting.

‘MIN(VAR_NAME...)’
‘MAX(VAR_NAME...)’
     Minimum or maximum value, respectively.  The aggregation variable
     receives the complete dictionary information from the source
     variable.

‘N(VAR_NAME...)’
‘NMISS(VAR_NAME...)’
     Total weight of non-missing or missing values, respectively.  The
     default format is F7.0 if weighting is not enabled, F8.2 if it is
     (*note WEIGHT::).

‘NU(VAR_NAME...)’
‘NUMISS(VAR_NAME...)’
     Count of non-missing or missing values, respectively, ignoring case
     weights.  The default format is F7.0.

‘PGT(VAR_NAME..., VALUE)’
‘PLT(VAR_NAME..., VALUE)’
‘PIN(VAR_NAME..., LOW, HIGH)’
‘POUT(VAR_NAME..., LOW, HIGH)’
     Percentage between 0 and 100 of values greater than or less than
     VALUE or inside or outside the closed range [LOW,HIGH],
     respectively.  The default format is F5.1.

   These aggregation functions do not accept source variables:

‘N’
     Total weight of cases aggregated to form this group.  The default
     format is F7.0 if weighting is not enabled, F8.2 if it is (*note
     WEIGHT::).

‘NU’
     Count of cases aggregated to form this group, ignoring case
     weights.  The default format is F7.0.

   Aggregation functions compare string values in terms of internal
character codes.  On most modern computers, this is ASCII or a superset
thereof.

   The aggregation functions listed above exclude all user-missing
values from calculations.  To include user-missing values, insert a
period (‘.’) at the end of the function name.  (e.g. ‘SUM.’).  (Be aware
that specifying such a function as the last token on a line causes the
period to be interpreted as the end of the command.)

   ‘AGGREGATE’ both ignores and cancels the current ‘SPLIT FILE’
settings (*note SPLIT FILE::).

12.1.1 Aggregate Example
------------------------

The ‘personnel.sav’ dataset provides the occupations and salaries of
many individuals.  For many purposes however such detailed information
is not interesting, but often the aggregated statistics of each
occupation are of interest.  In *note Example 12.1: aggregate:ex. the
‘AGGREGATE’ command is used to calculate the mean, the median and the
standard deviation of each occupation.

     GET FILE="personnel.sav".
     AGGREGATE OUTFILE=* MODE=REPLACE
             /BREAK=occupation
             /occ_mean_salary=MEAN(salary)
             /occ_median_salary=MEDIAN(salary)
             /occ_std_dev_salary=SD(salary).
     LIST.

Example 12.1: Calculating aggregated statistics from the ‘personnel.sav’
file.

   Since we chose the ‘MODE=REPLACE’ option, in *note Results 12.1:
aggregate:res. cases for the individual persons are no longer present.
They have each been replaced by a single case per aggregated value.

 [image src="pspp-figures/aggregate.png" text="                                Data List
+------------------+---------------+-----------------+------------------+
|    occupation    |occ_mean_salary|occ_median_salary|occ_std_dev_salary|
+------------------+---------------+-----------------+------------------+
|Artist            |       37836.18|         34712.50|           7631.48|
|Baker             |       45075.20|         45075.20|           4411.21|
|Barrister         |       39504.00|         39504.00|                 .|
|Carpenter         |       39349.11|         36190.04|           7453.40|
|Cleaner           |       41142.50|         39647.49|          14378.98|
|Cook              |       40357.79|         43194.00|          11064.51|
|Manager           |       46452.14|         45657.56|           6901.69|
|Mathematician     |       34531.06|         34763.06|           5267.68|
|Painter           |       45063.55|         45063.55|          15159.67|
|Payload Specialist|       34355.72|         34355.72|                 .|
|Plumber           |       40413.91|         40410.00|           4726.05|
|Scientist         |       36687.07|         36803.83|          10873.54|
|Scrientist        |       42530.65|         42530.65|                 .|
|Tailor            |       34586.79|         34586.79|           3728.98|
+------------------+---------------+-----------------+------------------+" ]


Results 12.1: Aggregated mean, median and standard deviation per
occupation.

   Note that some values for the standard deviation are blank.  This is
because there is only one case with the respective occupation.


File: pspp.info,  Node: AUTORECODE,  Next: COMPUTE,  Prev: AGGREGATE,  Up: Data Manipulation

12.2 AUTORECODE
===============

     AUTORECODE VARIABLES=SRC_VARS INTO DEST_VARS
             [ /DESCENDING ]
             [ /PRINT ]
             [ /GROUP ]
             [ /BLANK = {VALID, MISSING} ]

   The ‘AUTORECODE’ procedure considers the N values that a variable
takes on and maps them onto values 1...N on a new numeric variable.

   Subcommand ‘VARIABLES’ is the only required subcommand and must come
first.  Specify ‘VARIABLES’, an equals sign (‘=’), a list of source
variables, ‘INTO’, and a list of target variables.  There must the same
number of source and target variables.  The target variables must not
already exist.

   ‘AUTORECODE’ ordinarily assigns each increasing non-missing value of
a source variable (for a string, this is based on character code
comparisons) to consecutive values of its target variable.  For example,
the smallest non-missing value of the source variable is recoded to
value 1, the next smallest to 2, and so on.  If the source variable has
user-missing values, they are recoded to consecutive values just above
the non-missing values.  For example, if a source variables has seven
distinct non-missing values, then the smallest missing value would be
recoded to 8, the next smallest to 9, and so on.

   Use ‘DESCENDING’ to reverse the sort order for non-missing values, so
that the largest non-missing value is recoded to 1, the second-largest
to 2, and so on.  Even with ‘DESCENDING’, user-missing values are still
recoded in ascending order just above the non-missing values.

   The system-missing value is always recoded into the system-missing
variable in target variables.

   If a source value has a value label, then that value label is
retained for the new value in the target variable.  Otherwise, the
source value itself becomes each new value's label.

   Variable labels are copied from the source to target variables.

   ‘PRINT’ is currently ignored.

   The ‘GROUP’ subcommand is relevant only if more than one variable is
to be recoded.  It causes a single mapping between source and target
values to be used, instead of one map per variable.  With ‘GROUP’,
user-missing values are taken from the first source variable that has
any user-missing values.

   If ‘/BLANK=MISSING’ is given, then string variables which contain
only whitespace are recoded as SYSMIS. If ‘/BLANK=VALID’ is specified
then they are allocated a value like any other.  ‘/BLANK’ is not
relevant to numeric values.  ‘/BLANK=VALID’ is the default.

   ‘AUTORECODE’ is a procedure.  It causes the data to be read.  It
ignores ‘TEMPORARY’ (*note TEMPORARY::), so that "temporary"
transformations become permanent.

12.2.1 Autorecode Example
-------------------------

In the file ‘personnel.sav’, the variable occupation is a string
variable.  Except for data of a purely commentary nature, string
variables are generally a bad idea.  One reason is that data entry
errors are easily overlooked.  This has happened in ‘personnel.sav’; one
entry which should read "Scientist" has been mistyped as "Scrientist".
In *note Example 12.2: autorecode:ex. first, this error is corrected by
the ‘DO IF’ clause, (1) then we use ‘AUTORECODE’ to create a new numeric
variable which takes recoded values of occupation.  Finally, we remove
the old variable and rename the new variable to the name of the old
variable.

     get file='personnel.sav'.
     
     * Correct a typing error in the original file.
     do if occupation = "Scrientist".
      compute occupation = "Scientist".
     end if.
     
     autorecode
     	variables = occupation into occ
     	/blank = missing.
     
     * Delete the old variable.
     delete variables occupation.
     
     * Rename the new variable to the old variable's name.
     rename variables (occ = occupation).
     
     * Inspect the new variable.
     display dictionary /variables=occupation.
     

Example 12.2: Changing a string variable to a numeric variable using
‘AUTORECODE’ after correcting a data entry error

 [image src="screenshots/autorecode-ad.png" ]

Screenshot 12.1: Autorecode dialog box set to recode occupation to occ

   Notice in *note Result 12.1: autorecode:res, how the new variable has
been automatically allocated value labels which correspond to the
strings of the old variable.  This means that in future analyses the
descriptive strings are reported instead of the numeric values.

 [image src="pspp-figures/autorecode.png" text="                                   Variables
+----------+--------+--------------+-----+-----+---------+----------+---------+
|          |        |  Measurement |     |     |         |   Print  |  Write  |
|Name      |Position|     Level    | Role|Width|Alignment|  Format  |  Format |
+----------+--------+--------------+-----+-----+---------+----------+---------+
|occupation|       6|Unknown       |Input|    8|Right    |F2.0      |F2.0     |
+----------+--------+--------------+-----+-----+---------+----------+---------+

            Value Labels
+---------------+------------------+
|Variable Value |       Label      |
+---------------+------------------+
|occupation 1   |Artist            |
|           2   |Baker             |
|           3   |Barrister         |
|           4   |Carpenter         |
|           5   |Cleaner           |
|           6   |Cook              |
|           7   |Manager           |
|           8   |Mathematician     |
|           9   |Painter           |
|           10  |Payload Specialist|
|           11  |Plumber           |
|           12  |Scientist         |
|           13  |Tailor            |
+---------------+------------------+" ]


Result 12.1: The properties of the occupation variable following
‘AUTORECODE’

   ---------- Footnotes ----------

   (1) One must use care when correcting such data input errors rather
than msimply marking them as missing.  For example, if an occupation has
been entered "Barister", did the person mean "Barrister" or did she mean
"Barista"?


File: pspp.info,  Node: COMPUTE,  Next: COUNT,  Prev: AUTORECODE,  Up: Data Manipulation

12.3 COMPUTE
============

     COMPUTE VARIABLE = EXPRESSION.
   or
     COMPUTE vector(INDEX) = EXPRESSION.

   ‘COMPUTE’ assigns the value of an expression to a target variable.
For each case, the expression is evaluated and its value assigned to the
target variable.  Numeric and string variables may be assigned.  When a
string expression's width differs from the target variable's width, the
string result of the expression is truncated or padded with spaces on
the right as necessary.  The expression and variable types must match.

   For numeric variables only, the target variable need not already
exist.  Numeric variables created by ‘COMPUTE’ are assigned an ‘F8.2’
output format.  String variables must be declared before they can be
used as targets for ‘COMPUTE’.

   The target variable may be specified as an element of a vector (*note
VECTOR::).  In this case, an expression INDEX must be specified in
parentheses following the vector name.  The expression INDEX must
evaluate to a numeric value that, after rounding down to the nearest
integer, is a valid index for the named vector.

   Using ‘COMPUTE’ to assign to a variable specified on ‘LEAVE’ (*note
LEAVE::) resets the variable's left state.  Therefore, ‘LEAVE’ should be
specified following ‘COMPUTE’, not before.

   ‘COMPUTE’ is a transformation.  It does not cause the active dataset
to be read.

   When ‘COMPUTE’ is specified following ‘TEMPORARY’ (*note
TEMPORARY::), the ‘LAG’ function may not be used (*note LAG::).

12.3.1 Compute Examples
-----------------------

The dataset ‘physiology.sav’ contains the height and weight of persons.
For some purposes, neither height nor weight alone is of interest.
Epidemiologists are often more interested in the “body mass index” which
can sometimes be used as a predictor for clinical conditions.  The body
mass index is defined as the weight of the person in kilograms divided
by the square of the person's height in metres.  (1)

     get file='physiology.sav'.
     
     * height is in mm so we must divide by 1000 to get metres.
     compute bmi = weight / (height/1000)**2.
     variable label bmi "Body Mass Index".
     
     descriptives /weight height bmi.

Example 12.3: Computing the body mass index from weight and height

   *note Example 12.3: bmi:ex. shows how you can use ‘COMPUTE’ to
generate a new variable called bmi and have every case's value
calculated from the existing values of weight and height.  It also shows
how you can add a label to this new variable (*note VARIABLE LABELS::),
so that a more descriptive label appears in subsequent analyses, and
this can be seen in the ouput from the ‘DESCRIPTIVES’ command in *note
Results 12.2: bmi:res.

 [image src="screenshots/compute-ad.png" ]

Screenshot 12.2: Using the dialog box to generate a new variable and
compute its values

   The expression which follows the ‘=’ sign can be as complicated as
necessary.  *Note Expressions:: for a precise description of the
language accepted.  Normally it is easiest to enter the code directly,
however there is a dialog box available if desired.  This is illustrated
in *note Screenshot 12.2: bmi:scr.  One advantage is that it offers a
list of mathematical functions which can be selected and pasted into the
expression.

 [image src="pspp-figures/compute.png" text="                  Descriptive Statistics
+---------------------+--+-------+-------+-------+-------+
|                     | N|  Mean |Std Dev|Minimum|Maximum|
+---------------------+--+-------+-------+-------+-------+
|Weight in kilograms  |40|  72.12|  26.70|  -55.6|   92.1|
|Height in millimeters|40|1677.12| 262.87|    179|   1903|
|Body Mass Index      |40|  67.46| 274.08| -21.62|1756.82|
|Valid N (listwise)   |40|       |       |       |       |
|Missing N (listwise) | 0|       |       |       |       |
+---------------------+--+-------+-------+-------+-------+" ]


Results 12.2: An analysis which includes bmi in its results

   ---------- Footnotes ----------

   (1) Since BMI is a quantity with a ratio scale and has units, the
term "index" is a misnomer, but that is what it is called.


File: pspp.info,  Node: COUNT,  Next: FLIP,  Prev: COMPUTE,  Up: Data Manipulation

12.4 COUNT
==========

     COUNT VAR_NAME = VAR... (VALUE...)
         [/VAR_NAME = VAR... (VALUE...)]...

     Each VALUE takes one of the following forms:
             NUMBER
             STRING
             NUM1 THRU NUM2
             MISSING
             SYSMIS
     where NUM1 is a numeric expression or the words ‘LO’  or ‘LOWEST’
           and NUM2 is a numeric expression  or ‘HI’ or ‘HIGHEST’.

   ‘COUNT’ creates or replaces a numeric “target” variable that counts
the occurrence of a “criterion” value or set of values over one or more
“test” variables for each case.

   The target variable values are always nonnegative integers.  They are
never missing.  The target variable is assigned an F8.2 output format.
*Note Input and Output Formats::.  Any variables, including string
variables, may be test variables.

   User-missing values of test variables are treated just like any other
values.  They are *not* treated as system-missing values.  User-missing
values that are criterion values or inside ranges of criterion values
are counted as any other values.  However (for numeric variables),
keyword ‘MISSING’ may be used to refer to all system- and user-missing
values.

   ‘COUNT’ target variables are assigned values in the order specified.
In the command ‘COUNT A=A B(1) /B=A B(2).’, the following actions occur:

   − The number of occurrences of 1 between A and B is counted.

   − A is assigned this value.

   − The number of occurrences of 1 between B and the *new* value of A
     is counted.

   − B is assigned this value.

   Despite this ordering, all ‘COUNT’ criterion variables must exist
before the procedure is executed--they may not be created as target
variables earlier in the command!  Break such a command into two
separate commands.

12.4.1 Count Examples
---------------------

In the survey results in dataset ‘hotel.sav’ a manager wishes to know
how many respondents answered with low valued answers to questions v1,
v2 and v3.  This can be found using the code in *note Example 12.4:
count:ex.  Specifically, this code creates a new variable, and populates
it with the number of values in v1-v2 which are 2 or lower.

     get file="hotel.sav".
     
     count low_counts = v1 v2 v3 (low thru 2).
     
     list /variables v1 v2 v3 low_counts.

Example 12.4: Counting low values to responses v1, v2 and v3

   In *note Example 12.4: count:ex. the ‘COUNT’ transformation creates a
new variable, low_counts and its values are shown using the ‘LIST’
command.

   If using the graphic user interface, a two step process must be used
to set up the ‘COUNT’ transformation.  The first dialog box (*note
Screenshot 12.3: count:scr.) provides for the variables to be chosen.
Then, one must click on the button marked "Define Values..."  to reveal
the dialog box for selecting the values to count.

 [image src="screenshots/count-ad.png" ]

Screenshot 12.3: The variables v1, v2 and v3 selected, ready to define
values to count

   In this dialog box, you must select the values you wish to count --
in this case all values up to and including 2 -- as shown in *note
Screenshot 12.4: count-define:scr. and click "Add".  As many ranges or
may be added as you desire.  When all desired ranges have been added
click "Continue".

 [image src="screenshots/count-define-ad.png" ]

Screenshot 12.4: Count "Define Values" dialog with ‘lowest thru 2’
selected

   In *note Result 12.2: count:res. we can see the values of low_counts
after the ‘COUNT’ transformation has completed.  The first value is 1,
because there is only one variable amoung v1, v2 and 3 which has a value
of 2 or less.  The second value is 2, because both v1 and v2 are 2 or
less.

 [image src="pspp-figures/count.png" text="      Data List
+--+--+--+----------+
|v1|v2|v3|low_counts|
+--+--+--+----------+
| 4| 2| 3|      1.00|
| 1| 1| 4|      2.00|
| 4| 2| 2|      2.00|
| 3| 1| 3|      1.00|
| 5| 3| 1|      1.00|
| 2| 2| 5|      2.00|
| 3| 2| 4|      1.00|
| 1| 4| 5|      1.00|
| 3| 2| 3|      1.00|
| 2| 5| 4|      1.00|
| 4| 2| 2|      2.00|
| 2| 1| 4|      2.00|
| 1| 2| 5|      2.00|
| 2| 3| 3|      1.00|
| 4| 1| 1|      2.00|
| 1| 1| 5|      2.00|
| 1| 5| 5|      1.00|
+--+--+--+----------+" ]


Result 12.2: The values of v1, v2, v3 and low_counts after the ‘COUNT’
transformation has run


File: pspp.info,  Node: FLIP,  Next: IF,  Prev: COUNT,  Up: Data Manipulation

12.5 FLIP
=========

     FLIP /VARIABLES=VAR_LIST /NEWNAMES=VAR_NAME.

   ‘FLIP’ transposes rows and columns in the active dataset.  It causes
cases to be swapped with variables, and vice versa.

   All variables in the transposed active dataset are numeric.  String
variables take on the system-missing value in the transposed file.

   ‘N’ subcommands are required.  If specified, the ‘VARIABLES’
subcommand selects variables to be transformed into cases, and variables
not specified are discarded.  If the ‘VARIABLES’ subcommand is omitted,
all variables are selected for transposition.

   The variables specified by ‘NEWNAMES’, which must be a string
variable, is used to give names to the variables created by ‘FLIP’.
Only the first 8 characters of the variable are used.  If ‘NEWNAMES’ is
not specified then the default is a variable named CASE_LBL, if it
exists.  If it does not then the variables created by ‘FLIP’ are named
VAR000 through VAR999, then VAR1000, VAR1001, and so on.

   When a ‘NEWNAMES’ variable is available, the names must be
canonicalized before becoming variable names.  Invalid characters are
replaced by letter ‘V’ in the first position, or by ‘_’ in subsequent
positions.  If the name thus generated is not unique, then numeric
extensions are added, starting with 1, until a unique name is found or
there are no remaining possibilities.  If the latter occurs then the
‘FLIP’ operation aborts.

   The resultant dictionary contains a CASE_LBL variable, a string
variable of width 8, which stores the names of the variables in the
dictionary before the transposition.  Variables names longer than 8
characters are truncated.  If ‘FLIP’ is called again on this dataset,
the CASE_LBL variable can be passed to the ‘NEWNAMES’ subcommand to
recreate the original variable names.

   ‘FLIP’ honors ‘N OF CASES’ (*note N OF CASES::).  It ignores
‘TEMPORARY’ (*note TEMPORARY::), so that "temporary" transformations
become permanent.

12.5.1 Flip Examples
--------------------

In *note Example 12.5: flip:ex, data has been entered using ‘DATA LIST’
(*note DATA LIST::) such that the first variable in the dataset is a
string variable containing a description of the other data for the case.
Clearly this is not a convenient arrangement for performing statistical
analyses, so it would have been better to think a little more carefully
about how the data should have been arranged.  However often the data is
provided by some third party source, and you have no control over the
form.  Fortunately, we can use ‘FLIP’ to exchange the variables and
cases in the active dataset.

     data list notable list /heading (a16) v1 v2 v3 v4 v5 v6
     begin data.
     date-of-birth 1970 1989 2001 1966 1976 1982
     sex 1 0 0 1 0 1
     score 10 10 9 3 8 9
     end data.
     
     echo 'Before FLIP:'.
     display variables.
     list.
     
     flip /variables = all /newnames = heading.
     
     echo 'After FLIP:'.
     display variables.
     list.

Example 12.5: Using ‘FLIP’ to exchange variables and cases in a dataset

   As you can see in *note Results 12.3: flip:res. before the ‘FLIP’
command has run there are seven variables (six containing data and one
for the heading) and three cases.  Afterwards there are four variables
(one per case, plus the CASE_LBL variable) and six cases.  You can
delete the CASE_LBL variable (*note DELETE VARIABLES::) if you don't
need it.

 [image src="pspp-figures/flip.png" text="Before FLIP:

                  Variables
+-------+--------+------------+------------+
|Name   |Position|Print Format|Write Format|
+-------+--------+------------+------------+
|heading|       1|A16         |A16         |
|v1     |       2|F8.2        |F8.2        |
|v2     |       3|F8.2        |F8.2        |
|v3     |       4|F8.2        |F8.2        |
|v4     |       5|F8.2        |F8.2        |
|v5     |       6|F8.2        |F8.2        |
|v6     |       7|F8.2        |F8.2        |
+-------+--------+------------+------------+

                           Data List
+-------------+-------+-------+-------+-------+-------+-------+
|   heading   |   v1  |   v2  |   v3  |   v4  |   v5  |   v6  |
+-------------+-------+-------+-------+-------+-------+-------+
|date-of-birth|1970.00|1989.00|2001.00|1966.00|1976.00|1982.00|
|sex          |   1.00|    .00|    .00|   1.00|    .00|   1.00|
|score        |  10.00|  10.00|   9.00|   3.00|   8.00|   9.00|
+-------------+-------+-------+-------+-------+-------+-------+

After FLIP:

                     Variables
+-------------+--------+------------+------------+
|Name         |Position|Print Format|Write Format|
+-------------+--------+------------+------------+
|CASE_LBL     |       1|A8          |A8          |
|date_of_birth|       2|F8.2        |F8.2        |
|sex          |       3|F8.2        |F8.2        |
|score        |       4|F8.2        |F8.2        |
+-------------+--------+------------+------------+

             Data List
+--------+-------------+----+-----+
|CASE_LBL|date_of_birth| sex|score|
+--------+-------------+----+-----+
|v1      |      1970.00|1.00|10.00|
|v2      |      1989.00| .00|10.00|
|v3      |      2001.00| .00| 9.00|
|v4      |      1966.00|1.00| 3.00|
|v5      |      1976.00| .00| 8.00|
|v6      |      1982.00|1.00| 9.00|
+--------+-------------+----+-----+" ]


Results 12.3: The results of using ‘FLIP’ to exchange variables and
cases in a dataset


File: pspp.info,  Node: IF,  Next: RECODE,  Prev: FLIP,  Up: Data Manipulation

12.6 IF
=======

     IF CONDITION VARIABLE=EXPRESSION.
   or
     IF CONDITION vector(INDEX)=EXPRESSION.

   The ‘IF’ transformation conditionally assigns the value of a target
expression to a target variable, based on the truth of a test
expression.

   Specify a boolean-valued expression (*note Expressions::) to be
tested following the ‘IF’ keyword.  This expression is evaluated for
each case.  If the value is true, then the value of the expression is
computed and assigned to the specified variable.  If the value is false
or missing, nothing is done.  Numeric and string variables may be
assigned.  When a string expression's width differs from the target
variable's width, the string result of the expression is truncated or
padded with spaces on the right as necessary.  The expression and
variable types must match.

   The target variable may be specified as an element of a vector (*note
VECTOR::).  In this case, a vector index expression must be specified in
parentheses following the vector name.  The index expression must
evaluate to a numeric value that, after rounding down to the nearest
integer, is a valid index for the named vector.

   Using ‘IF’ to assign to a variable specified on ‘LEAVE’ (*note
LEAVE::) resets the variable's left state.  Therefore, ‘LEAVE’ should be
specified following ‘IF’, not before.

   When ‘IF’ is specified following ‘TEMPORARY’ (*note TEMPORARY::), the
‘LAG’ function may not be used (*note LAG::).


File: pspp.info,  Node: RECODE,  Next: SORT CASES,  Prev: IF,  Up: Data Manipulation

12.7 RECODE
===========

The ‘RECODE’ command is used to transform existing values into other,
user specified values.  The general form is:

     RECODE SRC_VARS
             (SRC_VALUE SRC_VALUE ... = DEST_VALUE)
             (SRC_VALUE SRC_VALUE ... = DEST_VALUE)
             (SRC_VALUE SRC_VALUE ... = DEST_VALUE) ...
              [INTO DEST_VARS].

   Following the ‘RECODE’ keyword itself comes SRC_VARS which is a list
of variables whose values are to be transformed.  These variables may be
string variables or they may be numeric.  However the list must be
homogeneous; you may not mix string variables and numeric variables in
the same recoding.

   After the list of source variables, there should be one or more
“mappings”.  Each mapping is enclosed in parentheses, and contains the
source values and a destination value separated by a single ‘=’.  The
source values are used to specify the values in the dataset which need
to change, and the destination value specifies the new value to which
they should be changed.  Each SRC_VALUE may take one of the following
forms:
NUMBER
     If the source variables are numeric then SRC_VALUE may be a literal
     number.
STRING
     If the source variables are string variables then SRC_VALUE may be
     a literal string (like all strings, enclosed in single or double
     quotes).
NUM1 THRU NUM2
     This form is valid only when the source variables are numeric.  It
     specifies all values in the range between NUM1 and NUM2, including
     both endpoints of the range.  By convention, NUM1 should be less
     than NUM2.  Open-ended ranges may be specified using ‘LO’ or
     ‘LOWEST’ for NUM1 or ‘HI’ or ‘HIGHEST’ for NUM2.
‘MISSING’
     The literal keyword ‘MISSING’ matches both system missing and user
     missing values.  It is valid for both numeric and string variables.
‘SYSMIS’
     The literal keyword ‘SYSMIS’ matches system missing values.  It is
     valid for both numeric variables only.
‘ELSE’
     The ‘ELSE’ keyword may be used to match any values which are not
     matched by any other SRC_VALUE appearing in the command.  If this
     keyword appears, it should be used in the last mapping of the
     command.

   After the source variables comes an ‘=’ and then the DEST_VALUE.  The
DEST_VALUE may take any of the following forms:
NUMBER
     A literal numeric value to which the source values should be
     changed.  This implies the destination variable must be numeric.
STRING
     A literal string value (enclosed in quotation marks) to which the
     source values should be changed.  This implies the destination
     variable must be a string variable.
‘SYSMIS’
     The keyword ‘SYSMIS’ changes the value to the system missing value.
     This implies the destination variable must be numeric.
‘COPY’
     The special keyword ‘COPY’ means that the source value should not
     be modified, but copied directly to the destination value.  This is
     meaningful only if ‘INTO DEST_VARS’ is specified.

   Mappings are considered from left to right.  Therefore, if a value is
matched by a SRC_VALUE from more than one mapping, the first (leftmost)
mapping which matches is considered.  Any subsequent matches are
ignored.

   The clause ‘INTO DEST_VARS’ is optional.  The behaviour of the
command is slightly different depending on whether it appears or not.

   If ‘INTO DEST_VARS’ does not appear, then values are recoded "in
place".  This means that the recoded values are written back to the
source variables from whence the original values came.  In this case,
the DEST_VALUE for every mapping must imply a value which has the same
type as the SRC_VALUE.  For example, if the source value is a string
value, it is not permissible for DEST_VALUE to be ‘SYSMIS’ or another
forms which implies a numeric result.  It is also not permissible for
DEST_VALUE to be longer than the width of the source variable.

   The following example two numeric variables X and Y are recoded in
place.  Zero is recoded to 99, the values 1 to 10 inclusive are
unchanged, values 1000 and higher are recoded to the system-missing
value and all other values are changed to 999:
     recode X Y
             (0 = 99)
             (1 THRU 10 = COPY)
             (1000 THRU HIGHEST = SYSMIS)
             (ELSE = 999).

   If ‘INTO DEST_VARS’ is given, then recoded values are written into
the variables specified in DEST_VARS, which must therefore contain a
list of valid variable names.  The number of variables in DEST_VARS must
be the same as the number of variables in SRC_VARS and the respective
order of the variables in DEST_VARS corresponds to the order of
SRC_VARS.  That is to say, the recoded value whose original value came
from the Nth variable in SRC_VARS is placed into the Nth variable in
DEST_VARS.  The source variables are unchanged.  If any mapping implies
a string as its destination value, then the respective destination
variable must already exist, or have been declared using ‘STRING’ or
another transformation.  Numeric variables however are automatically
created if they don't already exist.  The following example deals with
two source variables, A and B which contain string values.  Hence there
are two destination variables V1 and V2.  Any cases where A or B contain
the values ‘apple’, ‘pear’ or ‘pomegranate’ result in V1 or V2 being
filled with the string ‘fruit’ whilst cases with ‘tomato’, ‘lettuce’ or
‘carrot’ result in ‘vegetable’.  Any other values produce the result
‘unknown’:
     string V1 (a20).
     string V2 (a20).

     recode A B
             ("apple" "pear" "pomegranate" = "fruit")
             ("tomato" "lettuce" "carrot" = "vegetable")
             (ELSE = "unknown")
             into V1 V2.

   There is one very special mapping, not mentioned above.  If the
source variable is a string variable then a mapping may be specified as
‘(CONVERT)’.  This mapping, if it appears must be the last mapping given
and the ‘INTO DEST_VARS’ clause must also be given and must not refer to
a string variable.  ‘CONVERT’ causes a number specified as a string to
be converted to a numeric value.  For example it converts the string
‘"3"’ into the numeric value 3 (note that it does not convert ‘three’
into 3).  If the string cannot be parsed as a number, then the
system-missing value is assigned instead.  In the following example,
cases where the value of X (a string variable) is the empty string, are
recoded to 999 and all others are converted to the numeric equivalent of
the input value.  The results are placed into the numeric variable Y:
     recode X
            ("" = 999)
             (convert)
             into Y.

   It is possible to specify multiple recodings on a single command.
Introduce additional recodings with a slash (‘/’) to separate them from
the previous recodings:
     recode
             A  (2 = 22) (else = 99)
             /B (1 = 3) into Z
             .
Here we have two recodings.  The first affects the source variable A and
recodes in-place the value 2 into 22 and all other values to 99.  The
second recoding copies the values of B into the variable Z, changing any
instances of 1 into 3.


File: pspp.info,  Node: SORT CASES,  Prev: RECODE,  Up: Data Manipulation

12.8 SORT CASES
===============

     SORT CASES BY VAR_LIST[({D|A}] [ VAR_LIST[({D|A}] ] ...

   ‘SORT CASES’ sorts the active dataset by the values of one or more
variables.

   Specify ‘BY’ and a list of variables to sort by.  By default,
variables are sorted in ascending order.  To override sort order,
specify ‘(D)’ or ‘(DOWN)’ after a list of variables to get descending
order, or ‘(A)’ or ‘(UP)’ for ascending order.  These apply to all the
listed variables up until the preceding ‘(A)’, ‘(D)’, ‘(UP)’ or
‘(DOWN)’.

   The sort algorithms used by ‘SORT CASES’ are stable.  This means
records which have equal values of the sort variables have the same
relative order before and after sorting.  Thus, re-sorting an already
sorted file does not affect the ordering of cases.

   ‘SORT CASES’ is a procedure.  It causes the data to be read.

   ‘SORT CASES’ attempts to sort the entire active dataset in main
memory.  If workspace is exhausted, it falls back to a merge sort
algorithm which creates numerous temporary files.

   ‘SORT CASES’ may not be specified following ‘TEMPORARY’.

12.8.1 Sorting Example
----------------------

In *note Example 12.6: sort-cases:ex. the data from the file
‘physiology.sav’ is sorted by two variables, viz sex in descending order
and temperature in ascending order.

     get file='physiology.sav'.
     sort cases by sex (D) temperature(A).
     list.

Example 12.6: Sorting cases by two variables.

   In *note Results 12.4: sort-cases:res. you can see that all the cases
with a sex of ‘1’ (female) appear before those with a sex of ‘0’ (male).
This is because they have been sorted in descending order.  Within each
sex, the data is sorted on the temperature variable, this time in
ascending order.

 [image src="pspp-figures/sort-cases.png" text="           Data List
+---+------+------+-----------+
|sex|height|weight|temperature|
+---+------+------+-----------+
|  1|  1606|  56.1|      34.56|
|  1|   179|  56.3|      35.15|
|  1|  1609|  55.4|      35.46|
|  1|  1606|  56.0|      36.06|
|  1|  1607|  56.3|      36.26|
|  1|  1604|  56.0|      36.57|
|  1|  1604|  56.6|      36.81|
|  1|  1606|  56.3|      36.88|
|  1|  1604|  57.8|      37.32|
|  1|  1598|  55.6|      37.37|
|  1|  1607|  55.9|      37.84|
|  1|  1605|  54.5|      37.86|
|  1|  1603|  56.1|      38.80|
|  1|  1604|  58.1|      38.85|
|  1|  1605|  57.7|      38.98|
|  1|  1709|  55.6|      39.45|
|  1|  1604| -55.6|      39.72|
|  1|  1601|  55.9|      39.90|
|  0|  1799|  90.3|      32.59|
|  0|  1799|  89.0|      33.61|
|  0|  1799|  90.6|      34.04|
|  0|  1801|  90.5|      34.42|
|  0|  1802|  87.7|      35.03|
|  0|  1793|  90.1|      35.11|
|  0|  1801|  92.1|      35.98|
|  0|  1800|  89.5|      36.10|
|  0|  1645|  92.1|      36.68|
|  0|  1698|  90.2|      36.94|
|  0|  1800|  89.6|      37.02|
|  0|  1800|  88.9|      37.03|
|  0|  1801|  88.9|      37.12|
|  0|  1799|  90.4|      37.33|
|  0|  1903|  91.5|      37.52|
|  0|  1799|  90.9|      37.53|
|  0|  1800|  91.0|      37.60|
|  0|  1799|  90.4|      37.68|
|  0|  1801|  91.7|      38.98|
|  0|  1801|  90.9|      39.03|
|  0|  1799|  89.3|      39.77|
|  0|  1884|  88.6|      39.97|
+---+------+------+-----------+" ]


Results 12.4: The ‘physiology.sav’ file after sorting.

   Note that ‘SORT CASES’, like all other transformations, affects only
the active file.  It does not have any effect upon the ‘physiology.sav’
file itself.  For that, you would have to rewrite the file using the
‘SAVE’ command (*note SAVE::).

   When using the graphic user interface, it is often simpler to perform
a sort directly from the data view.  To do this, switch to the data
view.  Select the column corresponding to the variable by which you want
to sort and click button 1 and then click button 3.  A popup menu will
appear like that shown in *note Screenshot 12.5: sort-simple:scr.
Select either "Sort Ascending" or "Sort Descending" from this menu.

 [image src="screenshots/sort-simple-ad.png" ]

Screenshot 12.5: Sorting the data on a single variable height

   However, sometimes you will want to sort on two or more variables,
and that is not possible using this method.  In this case, you must
either use some code or the "Sort Cases" dialog from the Data menu.
*note Screenshot 12.6: sort:scr. shows the dialog box set up to perform
a sort on both sex and height.  Note that the order in which you enter
the variables is important.  In this case, the data will be first sorted
on sex, and then all cases for which sex is the same will then be sorted
by height.

 [image src="screenshots/sort-ad.png" ]

Screenshot 12.6: Sorting the data on two variables sex and height


File: pspp.info,  Node: Data Selection,  Next: Conditionals and Looping,  Prev: Data Manipulation,  Up: Top

13 Selecting data for analysis
******************************

This chapter documents PSPP commands that temporarily or permanently
select data records from the active dataset for analysis.

* Menu:

* FILTER::                      Exclude cases based on a variable.
* N OF CASES::                  Limit the size of the active dataset.
* SAMPLE::                      Select a specified proportion of cases.
* SELECT IF::                   Permanently delete selected cases.
* SPLIT FILE::                  Do multiple analyses with one command.
* TEMPORARY::                   Make transformations' effects temporary.
* WEIGHT::                      Weight cases by a variable.


File: pspp.info,  Node: FILTER,  Next: N OF CASES,  Up: Data Selection

13.1 FILTER
===========

     FILTER BY VAR_NAME.
     FILTER OFF.

   ‘FILTER’ allows a boolean-valued variable to be used to select cases
from the data stream for processing.

   To set up filtering, specify ‘BY’ and a variable name.  Keyword BY is
optional but recommended.  Cases which have a zero or system- or
user-missing value are excluded from analysis, but not deleted from the
data stream.  Cases with other values are analyzed.  To filter based on
a different condition, use transformations such as ‘COMPUTE’ or ‘RECODE’
to compute a filter variable of the required form, then specify that
variable on ‘FILTER’.

   ‘FILTER OFF’ turns off case filtering.

   Filtering takes place immediately before cases pass to a procedure
for analysis.  Only one filter variable may be active at a time.
Normally, case filtering continues until it is explicitly turned off
with ‘FILTER OFF’.  However, if ‘FILTER’ is placed after ‘TEMPORARY’, it
filters only the next procedure or procedure-like command.


File: pspp.info,  Node: N OF CASES,  Next: SAMPLE,  Prev: FILTER,  Up: Data Selection

13.2 N OF CASES
===============

     N [OF CASES] NUM_OF_CASES [ESTIMATED].

   ‘N OF CASES’ limits the number of cases processed by any procedures
that follow it in the command stream.  ‘N OF CASES 100’, for example,
tells PSPP to disregard all cases after the first 100.

   When ‘N OF CASES’ is specified after ‘TEMPORARY’, it affects only the
next procedure (*note TEMPORARY::).  Otherwise, cases beyond the limit
specified are not processed by any later procedure.

   If the limit specified on ‘N OF CASES’ is greater than the number of
cases in the active dataset, it has no effect.

   When ‘N OF CASES’ is used along with ‘SAMPLE’ or ‘SELECT IF’, the
case limit is applied to the cases obtained after sampling or case
selection, regardless of how ‘N OF CASES’ is placed relative to ‘SAMPLE’
or ‘SELECT IF’ in the command file.  Thus, the commands ‘N OF CASES 100’
and ‘SAMPLE .5’ both randomly sample approximately half of the active
dataset's cases, then select the first 100 of those sampled, regardless
of their order in the command file.

   ‘N OF CASES’ with the ‘ESTIMATED’ keyword gives an estimated number
of cases before ‘DATA LIST’ or another command to read in data.
‘ESTIMATED’ never limits the number of cases processed by procedures.
PSPP currently does not make use of case count estimates.


File: pspp.info,  Node: SAMPLE,  Next: SELECT IF,  Prev: N OF CASES,  Up: Data Selection

13.3 SAMPLE
===========

     SAMPLE NUM1 [FROM NUM2].

   ‘SAMPLE’ randomly samples a proportion of the cases in the active
file.  Unless it follows ‘TEMPORARY’, it operates as a transformation,
permanently removing cases from the active dataset.

   The proportion to sample can be expressed as a single number between
0 and 1.  If K is the number specified, and N is the number of
currently-selected cases in the active dataset, then after ‘SAMPLE K.’,
approximately K*N cases are selected.

   The proportion to sample can also be specified in the style ‘SAMPLE M
FROM N’.  With this style, cases are selected as follows:

  1. If N is equal to the number of currently-selected cases in the
     active dataset, exactly M cases are selected.

  2. If N is greater than the number of currently-selected cases in the
     active dataset, an equivalent proportion of cases are selected.

  3. If N is less than the number of currently-selected cases in the
     active, exactly M cases are selected _from the first N cases in the
     active dataset._

   ‘SAMPLE’ and ‘SELECT IF’ are performed in the order specified by the
syntax file.

   ‘SAMPLE’ is always performed before ‘N OF CASES’, regardless of
ordering in the syntax file (*note N OF CASES::).

   The same values for ‘SAMPLE’ may result in different samples.  To
obtain the same sample, use the ‘SET’ command to set the random number
seed to the same value before each ‘SAMPLE’.  Different samples may
still result when the file is processed on systems with differing
endianness or floating-point formats.  By default, the random number
seed is based on the system time.


File: pspp.info,  Node: SELECT IF,  Next: SPLIT FILE,  Prev: SAMPLE,  Up: Data Selection

13.4 SELECT IF
==============

     SELECT IF EXPRESSION.

   ‘SELECT IF’ selects cases for analysis based on the value of
EXPRESSION.  Cases not selected are permanently eliminated from the
active dataset, unless ‘TEMPORARY’ is in effect (*note TEMPORARY::).

   Specify a boolean expression (*note Expressions::).  If the value of
the expression is true for a particular case, the case is analyzed.  If
the expression has a false or missing value, then the case is deleted
from the data stream.

   Place ‘SELECT IF’ as early in the command file as possible.  Cases
that are deleted early can be processed more efficiently in time and
space.  Once cases have been deleted from the active dataset using
‘SELECT IF’ they cannot be re-instated.  If you want to be able to
re-instate cases, then use ‘FILTER’ (*note FILTER::) instead.

   When ‘SELECT IF’ is specified following ‘TEMPORARY’ (*note
TEMPORARY::), the ‘LAG’ function may not be used (*note LAG::).

13.4.1 Example Select-If
------------------------

A shop steward is interested in the salaries of younger personnel in a
firm.  The file ‘personnel.sav’ provides the salaries of all the workers
and their dates of birth.  The syntax in *note Example 13.1:
select-if:ex. shows how ‘SELECT IF’ can be used to limit analysis only
to those persons born after December 31, 1999.

     get file = 'personnel.sav'.
     
     echo 'Salaries of all personnel'.
     descriptives salary.
     
     echo 'Salaries of personnel born after December 31 1999'.
     select if dob > date.dmy (31,12,1999).
     descriptives salary.

Example 13.1: Using ‘SELECT IF’ to select persons born on or after a
certain date.

   From *note Result 13.1: select-if:res. one can see that there are 56
persons listed in the dataset, and 17 of them were born after December
31, 1999.

 [image src="pspp-figures/select-if.png" text="Salaries of all personnel

                    Descriptive Statistics
+------------------------+--+--------+-------+-------+-------+
|                        | N|  Mean  |Std Dev|Minimum|Maximum|
+------------------------+--+--------+-------+-------+-------+
|Annual salary before tax|56|40028.97|8721.17|$23,451|$57,044|
|Valid N (listwise)      |56|        |       |       |       |
|Missing N (listwise)    | 0|        |       |       |       |
+------------------------+--+--------+-------+-------+-------+

Salaries of personnel born after December 31 1999

                    Descriptive Statistics
+------------------------+--+--------+-------+-------+-------+
|                        | N|  Mean  |Std Dev|Minimum|Maximum|
+------------------------+--+--------+-------+-------+-------+
|Annual salary before tax|17|31828.59|4454.80|$23,451|$39,504|
|Valid N (listwise)      |17|        |       |       |       |
|Missing N (listwise)    | 0|        |       |       |       |
+------------------------+--+--------+-------+-------+-------+" ]


Result 13.1: Salary descriptives before and after the ‘SELECT IF’
transformation.

   Note that the ‘personnel.sav’ file from which the data were read is
unaffected.  The transformation affects only the active file.


File: pspp.info,  Node: SPLIT FILE,  Next: TEMPORARY,  Prev: SELECT IF,  Up: Data Selection

13.5 SPLIT FILE
===============

     SPLIT FILE [{LAYERED, SEPARATE}] BY VAR_LIST.
     SPLIT FILE OFF.

   ‘SPLIT FILE’ allows multiple sets of data present in one data file to
be analyzed separately using single statistical procedure commands.

   Specify a list of variable names to analyze multiple sets of data
separately.  Groups of adjacent cases having the same values for these
variables are analyzed by statistical procedure commands as one group.
An independent analysis is carried out for each group of cases, and the
variable values for the group are printed along with the analysis.

   When a list of variable names is specified, one of the keywords
‘LAYERED’ or ‘SEPARATE’ may also be specified.  With ‘LAYERED’, which is
the default, the separate analyses for each group are presented together
in a single table.  With ‘SEPARATE’, each analysis is presented in a
separate table.  Not all procedures honor the distinction.

   Groups are formed only by _adjacent_ cases.  To create a split using
a variable where like values are not adjacent in the working file, first
sort the data by that variable (*note SORT CASES::).

   Specify ‘OFF’ to disable ‘SPLIT FILE’ and resume analysis of the
entire active dataset as a single group of data.

   When ‘SPLIT FILE’ is specified after ‘TEMPORARY’, it affects only the
next procedure (*note TEMPORARY::).

13.5.1 Example Split
--------------------

The file ‘horticulture.sav’ contains data describing the yield of a
number of horticultural specimens which have been subjected to various
treatments.  If we wanted to investigate linear statistics of the yeild,
one way to do this is using the ‘DESCRIPTIVES’ (*note DESCRIPTIVES::).
However, it is reasonable to expect the mean to be different depending
on the treatment.  So we might want to perform three separate procedures
-- one for each treatment.  (1)  *note Example 13.2: split:ex. shows how
this can be done automatically using the ‘SPLIT FILE’ command.

     get file='horticulture.sav'.
     
     * Ensure cases are sorted before splitting.
     sort cases by treatment.
     
     split file by treatment.
     
     * Run descriptives on the yield variable
     descriptives /variable = yield.

Example 13.2: Running ‘DESCRIPTIVES’ on each value of treatment

   In *note Example 13.3: split:res. you can see that the table of
descriptive statistics appears 3 times -- once for each value of
treatment.  In this example ‘N’, the number of observations are
identical in all splits.  This is because that experiment was
deliberately designed that way.  However in general one can expect a
different ‘N’ for each split.

 [image src="pspp-figures/split.png" text="    Split Values
+---------+-------+
|Variable | Value |
+---------+-------+
|treatment|control|
+---------+-------+

                 Descriptive Statistics
+--------------------+--+-----+-------+-------+-------+
|                    | N| Mean|Std Dev|Minimum|Maximum|
+--------------------+--+-----+-------+-------+-------+
|yield               |30|51.23|   8.28|  37.86|  68.59|
|Valid N (listwise)  |30|     |       |       |       |
|Missing N (listwise)| 0|     |       |       |       |
+--------------------+--+-----+-------+-------+-------+

      Split Values
+---------+------------+
|Variable |    Value   |
+---------+------------+
|treatment|conventional|
+---------+------------+

                 Descriptive Statistics
+--------------------+--+-----+-------+-------+-------+
|                    | N| Mean|Std Dev|Minimum|Maximum|
+--------------------+--+-----+-------+-------+-------+
|yield               |30|53.57|   8.92|  36.30|  70.66|
|Valid N (listwise)  |30|     |       |       |       |
|Missing N (listwise)| 0|     |       |       |       |
+--------------------+--+-----+-------+-------+-------+

      Split Values
+---------+-----------+
|Variable |   Value   |
+---------+-----------+
|treatment|traditional|
+---------+-----------+

                 Descriptive Statistics
+--------------------+--+-----+-------+-------+-------+
|                    | N| Mean|Std Dev|Minimum|Maximum|
+--------------------+--+-----+-------+-------+-------+
|yield               |30|56.87|   8.88|  39.08|  75.93|
|Valid N (listwise)  |30|     |       |       |       |
|Missing N (listwise)| 0|     |       |       |       |
+--------------------+--+-----+-------+-------+-------+" ]


Example 13.3: The results of running ‘DESCRIPTIVES’ with an active split

   Unless ‘TEMPORARY’ was used, after a split has been defined for a
dataset it remains active until explicitly disabled.  In the graphical
user interface, the active split variable (if any) is displayed in the
status bar (*note Screenshot 13.1: split-status-bar:scr.  If a dataset
is saved to a system file (*note SAVE::) whilst a split is active, the
split stastus is stored in the file and will be automatically loaded
when that file is loaded.

 [image src="screenshots/split-status-bar-ad.png" ]

Screenshot 13.1: The status bar indicating that the data set is split
using the treatment variable

   ---------- Footnotes ----------

   (1) There are other, possibly better, ways to achieve a similar
result using the ‘MEANS’ or ‘EXAMINE’ commands.


File: pspp.info,  Node: TEMPORARY,  Next: WEIGHT,  Prev: SPLIT FILE,  Up: Data Selection

13.6 TEMPORARY
==============

     TEMPORARY.

   ‘TEMPORARY’ is used to make the effects of transformations following
its execution temporary.  These transformations affect only the
execution of the next procedure or procedure-like command.  Their
effects are not be saved to the active dataset.

   The only specification on ‘TEMPORARY’ is the command name.

   ‘TEMPORARY’ may not appear within a ‘DO IF’ or ‘LOOP’ construct.  It
may appear only once between procedures and procedure-like commands.

   Scratch variables cannot be used following ‘TEMPORARY’.

13.6.1 Example Temporary
------------------------

In *note Example 13.4: temporary:ex. there are two ‘COMPUTE’
transformation.  One of them immediatly follows a ‘TEMPORARY’ command,
and therefore has effect only for the next procedure, which in this case
is the first ‘DESCRIPTIVES’ command.

     data list notable /x 1-2.
     begin data.
      2
      4
     10
     15
     20
     24
     end data.
     
     compute x=x/2.
     
     temporary.
     compute x=x+3.
     
     descriptives x.
     descriptives x.

Example 13.4: Running a ‘COMPUTE’ transformation after ‘TEMPORARY’

   The data read by the first ‘DESCRIPTIVES’ procedure are 4, 5, 8,
10.5, 13, 15.  The data read by the second ‘DESCRIPTIVES’ procedure are
1, 2, 5, 7.5, 10, 12.  This is because the second ‘COMPUTE’
transformation has no effect on the second ‘DESCRIPTIVES’ procedure.
You can check these figures in *note Result 13.2: temporary:res.

 [image src="pspp-figures/temporary.png" text="                Descriptive Statistics
+--------------------+-+----+-------+-------+-------+
|                    |N|Mean|Std Dev|Minimum|Maximum|
+--------------------+-+----+-------+-------+-------+
|x                   |6|9.25|   4.38|      4|     15|
|Valid N (listwise)  |6|    |       |       |       |
|Missing N (listwise)|0|    |       |       |       |
+--------------------+-+----+-------+-------+-------+

                Descriptive Statistics
+--------------------+-+----+-------+-------+-------+
|                    |N|Mean|Std Dev|Minimum|Maximum|
+--------------------+-+----+-------+-------+-------+
|x                   |6|6.25|   4.38|      1|     12|
|Valid N (listwise)  |6|    |       |       |       |
|Missing N (listwise)|0|    |       |       |       |
+--------------------+-+----+-------+-------+-------+" ]


Result 13.2: The results of running two consecutive ‘DESCRIPTIVES’
commands after a temporary transformation


File: pspp.info,  Node: WEIGHT,  Prev: TEMPORARY,  Up: Data Selection

13.7 WEIGHT
===========

     WEIGHT BY VAR_NAME.
     WEIGHT OFF.

   ‘WEIGHT’ assigns cases varying weights, changing the frequency
distribution of the active dataset.  Execution of ‘WEIGHT’ is delayed
until data have been read.

   If a variable name is specified, ‘WEIGHT’ causes the values of that
variable to be used as weighting factors for subsequent statistical
procedures.  Use of keyword ‘BY’ is optional but recommended.  Weighting
variables must be numeric.  Scratch variables may not be used for
weighting (*note Scratch Variables::).

   When ‘OFF’ is specified, subsequent statistical procedures weight all
cases equally.

   A positive integer weighting factor W on a case yields the same
statistical output as would replicating the case W times.  A weighting
factor of 0 is treated for statistical purposes as if the case did not
exist in the input.  Weighting values need not be integers, but negative
and system-missing values for the weighting variable are interpreted as
weighting factors of 0.  User-missing values are not treated specially.

   When ‘WEIGHT’ is specified after ‘TEMPORARY’, it affects only the
next procedure (*note TEMPORARY::).

   ‘WEIGHT’ does not cause cases in the active dataset to be replicated
in memory.

13.7.1 Example Weights
----------------------

One could define a dataset containing an inventory of stock items.  It
would be reasonable to use a string variable for a description of the
item, and a numeric variable for the number in stock, like in *note
Example 13.5: weight:ex.

     data list notable list /item (a16) quantity (f8.0).
     begin   data
     nuts    345
     screws  10034
     washers 32012
     bolts   876
     end data.
     
     echo 'Unweighted frequency table'.
     frequencies /variables = item /format=dfreq.
     
     weight by quantity.
     
     echo 'Weighted frequency table'.
     frequencies /variables = item /format=dfreq.

Example 13.5: Setting the weight on the variable quantity

   One analysis which most surely would be of interest is the relative
amounts or each item in stock.  However without setting a weight
variable, ‘FREQUENCIES’ (*note FREQUENCIES::) does not tell us what we
want to know, since there is only one case for each stock item.  *note
Example 13.6: weight:res. shows the difference between the weighted and
unweighted frequency tables.

 [image src="pspp-figures/weight.png" text="Unweighted frequency table

                               item
+-------------+---------+-------+-------------+------------------+
|             |Frequency|Percent|Valid Percent|Cumulative Percent|
+-------------+---------+-------+-------------+------------------+
|Valid bolts  |        1|  25.0%|        25.0%|             25.0%|
|      nuts   |        1|  25.0%|        25.0%|             50.0%|
|      screws |        1|  25.0%|        25.0%|             75.0%|
|      washers|        1|  25.0%|        25.0%|            100.0%|
+-------------+---------+-------+-------------+------------------+
|Total        |        4| 100.0%|             |                  |
+-------------+---------+-------+-------------+------------------+

Weighted frequency table

                               item
+-------------+---------+-------+-------------+------------------+
|             |Frequency|Percent|Valid Percent|Cumulative Percent|
+-------------+---------+-------+-------------+------------------+
|Valid washers|    32012|  74.0%|        74.0%|             74.0%|
|      screws |    10034|  23.2%|        23.2%|             97.2%|
|      bolts  |      876|   2.0%|         2.0%|             99.2%|
|      nuts   |      345|    .8%|          .8%|            100.0%|
+-------------+---------+-------+-------------+------------------+
|Total        |    43267| 100.0%|             |                  |
+-------------+---------+-------+-------------+------------------+" ]


Example 13.6: Weighted and unweighted frequency tables of items


File: pspp.info,  Node: Conditionals and Looping,  Next: Statistics,  Prev: Data Selection,  Up: Top

14 Conditional and Looping Constructs
*************************************

This chapter documents PSPP commands used for conditional execution,
looping, and flow of control.

* Menu:

* BREAK::                       Exit a loop.
* DEFINE::                      Define a macro.
* DO IF::                       Conditionally execute a block of code.
* DO REPEAT::                   Textually repeat a code block.
* LOOP::                        Repeat a block of code.


File: pspp.info,  Node: BREAK,  Next: DEFINE,  Up: Conditionals and Looping

14.1 BREAK
==========

     BREAK.

   ‘BREAK’ terminates execution of the innermost currently executing
‘LOOP’ construct.

   ‘BREAK’ is allowed only inside ‘LOOP’...‘END LOOP’.  *Note LOOP::,
for more details.


File: pspp.info,  Node: DEFINE,  Next: DO IF,  Prev: BREAK,  Up: Conditionals and Looping

14.2 DEFINE
===========

* Menu:

* Macro Overview::
* Macro Introduction::
* Macro Bodies::
* Macro Arguments::
* Controlling Macro Expansion::
* Macro Functions::
* Macro Expressions::
* Macro Conditional Expansion::
* Macro Loops::
* Macro Variable Assignment::
* Macro Settings::
* Macro Notes::


File: pspp.info,  Node: Macro Overview,  Next: Macro Introduction,  Up: DEFINE

14.2.1 Overview
---------------

     DEFINE macro_name([argument[/argument]...])
     ...body...
     !ENDDEFINE.

Each argument takes the following form:
     {!arg_name= | !POSITIONAL}
     [!DEFAULT(default)]
     [!NOEXPAND]
     {!TOKENS(count) | !CHAREND('token') | !ENCLOSE('start' | 'end') | !CMDEND}

The following directives may be used within body:
     !OFFEXPAND
     !ONEXPAND

The following functions may be used within the body:
     !BLANKS(count)
     !CONCAT(arg...)
     !EVAL(arg)
     !HEAD(arg)
     !INDEX(haystack, needle)
     !LENGTH(arg)
     !NULL
     !QUOTE(arg)
     !SUBSTR(arg, start[, count])
     !TAIL(arg)
     !UNQUOTE(arg)
     !UPCASE(arg)

The body may also include the following constructs:
     !IF (condition) !THEN true-expansion !ENDIF
     !IF (condition) !THEN true-expansion !ELSE false-expansion !ENDIF

     !DO !var = start !TO end [!BY step]
       body
     !DOEND
     !DO !var !IN (expression)
       body
     !DOEND

     !LET !var = expression


File: pspp.info,  Node: Macro Introduction,  Next: Macro Bodies,  Prev: Macro Overview,  Up: DEFINE

14.2.2 Introduction
-------------------

The DEFINE command creates a “macro”, which is a name for a fragment of
PSPP syntax called the macro's “body”.  Following the DEFINE command,
syntax may “call” the macro by name any number of times.  Each call
substitutes, or “expands”, the macro's body in place of the call, as if
the body had been written in its place.

   The following syntax defines a macro named ‘!vars’ that expands to
the variable names ‘v1 v2 v3’.  The macro's name begins with ‘!’, which
is optional for macro names.  The ‘()’ following the macro name are
required:

     DEFINE !vars()
     v1 v2 v3
     !ENDDEFINE.

   Here are two ways that ‘!vars’ might be called given the preceding
definition:

     DESCRIPTIVES !vars.
     FREQUENCIES /VARIABLES=!vars.

   With macro expansion, the above calls are equivalent to the
following:

     DESCRIPTIVES v1 v2 v3.
     FREQUENCIES /VARIABLES=v1 v2 v3.

   The ‘!vars’ macro expands to a fixed body.  Macros may have more
sophisticated contents:

   • Macro “arguments” that are substituted into the body whenever they
     are named.  The values of a macro's arguments are specified each
     time it is called.  *Note Macro Arguments::.

   • Macro “functions”, expanded when the macro is called.  *Note Macro
     Functions::.

   • ‘!IF’ constructs, for conditional expansion.  *Note Macro
     Conditional Expansion::.

   • Two forms of ‘!DO’ construct, for looping over a numerical range or
     a collection of tokens.  *Note Macro Loops::.

   • ‘!LET’ constructs, for assigning to macro variables.  *Note Macro
     Variable Assignment::.

   Many identifiers associated with macros begin with ‘!’, a character
not normally allowed in identifiers.  These identifiers are reserved
only for use with macros, which helps keep them from being confused with
other kinds of identifiers.

   The following sections provide more details on macro syntax and
semantics.


File: pspp.info,  Node: Macro Bodies,  Next: Macro Arguments,  Prev: Macro Introduction,  Up: DEFINE

14.2.3 Macro Bodies
-------------------

As previously shown, a macro body may contain a fragment of a PSPP
command (such as a variable name).  A macro body may also contain full
PSPP commands.  In the latter case, the macro body should also contain
the command terminators.

   Most PSPP commands may occur within a macro.  The ‘DEFINE’ command
itself is one exception, because the inner ‘!ENDDEFINE’ ends the outer
macro definition.  For compatibility, ‘BEGIN DATA’...‘END DATA.’ should
not be used within a macro.

   The body of a macro may call another macro.  The following shows one
way that could work:

     DEFINE !commands()
     DESCRIPTIVES !vars.
     FREQUENCIES /VARIABLES=!vars.
     !ENDDEFINE.

     * Initially define the 'vars' macro to analyze v1...v3.
     DEFINE !vars() v1 v2 v3 !ENDDEFINE.
     !commands

     * Redefine 'vars' macro to analyze different variables.
     DEFINE !vars() v4 v5 !ENDDEFINE.
     !commands

   The ‘!commands’ macro would be easier to use if it took the variables
to analyze as an argument rather than through another macro.  The
following section shows how to do that.


File: pspp.info,  Node: Macro Arguments,  Next: Controlling Macro Expansion,  Prev: Macro Bodies,  Up: DEFINE

14.2.4 Macro Arguments
----------------------

This section explains how to use macro arguments.  As an initial
example, the following syntax defines a macro named ‘!analyze’ that
takes all the syntax up to the first command terminator as an argument:

     DEFINE !analyze(!POSITIONAL !CMDEND)
     DESCRIPTIVES !1.
     FREQUENCIES /VARIABLES=!1.
     !ENDDEFINE.

When ‘!analyze’ is called, it expands to a pair of analysis commands
with each ‘!1’ in the body replaced by the argument.  That is, these
calls:

     !analyze v1 v2 v3.
     !analyze v4 v5.

act like the following:

     DESCRIPTIVES v1 v2 v3.
     FREQUENCIES /VARIABLES=v1 v2 v3.
     DESCRIPTIVES v4 v5.
     FREQUENCIES /VARIABLES=v4 v5.

   Macros may take any number of arguments, described within the
parentheses in the DEFINE command.  Arguments come in two varieties
based on how their values are specified when the macro is called:

   • A “positional” argument has a required value that follows the
     macro's name.  Use the ‘!POSITIONAL’ keyword to declare a
     positional argument.

     When a macro is called, the positional argument values appear in
     the same order as their definitions, before any keyword argument
     values.

     References to a positional argument in a macro body are numbered:
     ‘!1’ is the first positional argument, ‘!2’ the second, and so on.
     In addition, ‘!*’ expands to all of the positional arguments'
     values, separated by spaces.

     The following example uses a positional argument:

          DEFINE !analyze(!POSITIONAL !CMDEND)
          DESCRIPTIVES !1.
          FREQUENCIES /VARIABLES=!1.
          !ENDDEFINE.

          !analyze v1 v2 v3.
          !analyze v4 v5.

   • A “keyword” argument has a name.  In the macro call, its value is
     specified with the syntax ‘name=value’.  The names allow keyword
     argument values to take any order in the call.

     In declaration and calls, a keyword argument's name may not begin
     with ‘!’, but references to it in the macro body do start with a
     leading ‘!’.

     The following example uses a keyword argument that defaults to ALL
     if the argument is not assigned a value:

          DEFINE !analyze_kw(vars=!DEFAULT(ALL) !CMDEND)
          DESCRIPTIVES !vars.
          FREQUENCIES /VARIABLES=!vars.
          !ENDDEFINE.

          !analyze_kw vars=v1 v2 v3.  /* Analyze specified variables.
          !analyze_kw.                /* Analyze all variables.

   If a macro has both positional and keyword arguments, then the
positional arguments must come first in the DEFINE command, and their
values also come first in macro calls.  A keyword argument may be
omitted by leaving its keyword out of the call, and a positional
argument may be omitted by putting a command terminator where it would
appear.  (The latter case also omits any following positional arguments
and all keyword arguments, if there are any.)  When an argument is
omitted, a default value is used: either the value specified in
‘!DEFAULT(value)’, or an empty value otherwise.

   Each argument declaration specifies the form of its value:

‘!TOKENS(count)’
     Exactly COUNT tokens, e.g. ‘!TOKENS(1)’ for a single token.  Each
     identifier, number, quoted string, operator, or punctuator is a
     token.  *Note Tokens::, for a complete definition.

     The following variant of ‘!analyze_kw’ accepts only a single
     variable name (or ‘ALL’) as its argument:

          DEFINE !analyze_one_var(!POSITIONAL !TOKENS(1))
          DESCRIPTIVES !1.
          FREQUENCIES /VARIABLES=!1.
          !ENDDEFINE.

          !analyze_one_var v1.

‘!CHAREND('TOKEN')’
     Any number of tokens up to TOKEN, which should be an operator or
     punctuator token such as ‘/’ or ‘+’.  The TOKEN does not become
     part of the value.

     With the following variant of ‘!analyze_kw’, the variables must be
     following by ‘/’:

          DEFINE !analyze_parens(vars=!CHARNED('/'))
          DESCRIPTIVES !vars.
          FREQUENCIES /VARIABLES=!vars.
          !ENDDEFINE.

          !analyze_parens vars=v1 v2 v3/.

‘!ENCLOSE('START','END')’
     Any number of tokens enclosed between START and END, which should
     each be operator or punctuator tokens.  For example, use
     ‘!ENCLOSE('(',')')’ for a value enclosed within parentheses.  (Such
     a value could never have right parentheses inside it, even paired
     with left parentheses.)  The start and end tokens are not part of
     the value.

     With the following variant of ‘!analyze_kw’, the variables must be
     specified within parentheses:

          DEFINE !analyze_parens(vars=!ENCLOSE('(',')'))
          DESCRIPTIVES !vars.
          FREQUENCIES /VARIABLES=!vars.
          !ENDDEFINE.

          !analyze_parens vars=(v1 v2 v3).

‘!CMDEND’
     Any number of tokens up to the end of the command.  This should be
     used only for the last positional parameter, since it consumes all
     of the tokens in the command calling the macro.

     The following variant of ‘!analyze_kw’ takes all the variable names
     up to the end of the command as its argument:

          DEFINE !analyze_kw(vars=!CMDEND)
          DESCRIPTIVES !vars.
          FREQUENCIES /VARIABLES=!vars.
          !ENDDEFINE.

          !analyze_kw vars=v1 v2 v3.

   By default, when an argument's value contains a macro call, the call
is expanded each time the argument appears in the macro's body.  The
‘!NOEXPAND’ keyword in an argument declaration suppresses this
expansion.  *Note Controlling Macro Expansion::.


File: pspp.info,  Node: Controlling Macro Expansion,  Next: Macro Functions,  Prev: Macro Arguments,  Up: DEFINE

14.2.5 Controlling Macro Expansion
----------------------------------

Multiple factors control whether macro calls are expanded in different
situations.  At the highest level, ‘SET MEXPAND’ controls whether macro
calls are expanded.  By default, it is enabled.  *Note SET MEXPAND::,
for details.

   A macro body may contain macro calls.  By default, these are
expanded.  If a macro body contains ‘!OFFEXPAND’ or ‘!ONEXPAND’
directives, then ‘!OFFEXPAND’ disables expansion of macro calls until
the following ‘!ONEXPAND’.

   A macro argument's value may contain a macro call.  These macro calls
are expanded, unless the argument was declared with the ‘!NOEXPAND’
keyword.

   The argument to a macro function is a special context that does not
expand macro calls.  For example, if ‘!vars’ is the name of a macro,
then ‘!LENGTH(!vars)’ expands to 5, as does ‘!LENGTH(!1)’ if positional
argument 1 has value ‘!vars’.  To expand macros in these cases, use the
‘!EVAL’ macro function, e.g. ‘!LENGTH(!EVAL(!vars))’ or
‘!LENGTH(!EVAL(!1))’.  *Note Macro Functions::, for details.

   These rules apply to macro calls, not to uses within a macro body of
macro functions, macro arguments, and macro variables created by ‘!DO’
or ‘!LET’, which are always expanded.

   ‘SET MEXPAND’ may appear within the body of a macro, but it will not
affect expansion of the macro that it appears in.  Use ‘!OFFEXPAND’ and
‘!ONEXPAND’ instead.


File: pspp.info,  Node: Macro Functions,  Next: Macro Expressions,  Prev: Controlling Macro Expansion,  Up: DEFINE

14.2.6 Macro Functions
----------------------

Macro bodies may manipulate syntax using macro functions.  Macro
functions accept tokens as arguments and expand to sequences of
characters.

   The arguments to macro functions have a restricted form.  They may
only be a single token (such as an identifier or a string), a macro
argument, or a call to a macro function.  Thus, the following are valid
macro arguments:
     x    5.0    x    !1    "5 + 6"    !CONCAT(x,y)
and the following are not:
     x y    5+6

   Macro functions expand to sequences of characters.  When these
character strings are processed further as character strings, e.g. with
‘!LENGTH’, any character string is valid.  When they are interpreted as
PSPP syntax, e.g. when the expansion becomes part of a command, they
need to be valid for that purpose.  For example, ‘!UNQUOTE("It's")’ will
yield an error if the expansion ‘It's’ becomes part of a PSPP command,
because it contains unbalanced single quotes, but
‘!LENGTH(!UNQUOTE("It's"))’ expands to 4.

   The following macro functions are available.  Each function's
documentation includes examples in the form ‘CALL ↦ EXPANSION’.

 -- Macro Function: !BLANKS (count)
     Expands to COUNT unquoted spaces, where COUNT is a nonnegative
     integer.  Outside quotes, any positive number of spaces are
     equivalent; for a quoted string of spaces, use
     ‘!QUOTE(!BLANKS(COUNT))’.

     In the examples below, ‘_’ stands in for a space to make the
     results visible.

          !BLANKS(0)                  ↦ empty
          !BLANKS(1)                  ↦ _
          !BLANKS(2)                  ↦ __
          !QUOTE(!BLANKS(5))          ↦ '_____'

 -- Macro Function: !CONCAT (arg...)
     Expands to the concatenation of all of the arguments.  Before
     concatenation, each quoted string argument is unquoted, as if
     ‘!UNQUOTE’ were applied.  This allows for "token pasting",
     combining two (or more) tokens into a single one:

          !CONCAT(x, y)                ↦ xy
          !CONCAT('x', 'y')            ↦ xy
          !CONCAT(12, 34)              ↦ 1234
          !CONCAT(!NULL, 123)          ↦ 123

     ‘!CONCAT’ is often used for constructing a series of similar
     variable names from a prefix followed by a number and perhaps a
     suffix.  For example:

          !CONCAT(x, 0)                ↦ x0
          !CONCAT(x, 0, y)             ↦ x0y

     An identifier token must begin with a letter (or ‘#’ or ‘@’), which
     means that attempting to use a number as the first part of an
     identifier will produce a pair of distinct tokens rather than a
     single one.  For example:

          !CONCAT(0, x)                ↦ 0 x
          !CONCAT(0, x, y)             ↦ 0 xy

 -- Macro Function: !EVAL (arg)
     Expands macro calls in ARG.  This is especially useful if ARG is
     the name of a macro or a macro argument that expands to one,
     because arguments to macro functions are not expanded by default
     (*note Controlling Macro Expansion::).

     The following examples assume that ‘!vars’ is a macro that expands
     to ‘a b c’:

          !vars                        ↦ a b c
          !QUOTE(!vars)                ↦ '!vars'
          !EVAL(!vars)                 ↦ a b c
          !QUOTE(!EVAL(!vars))         ↦ 'a b c'

     These examples additionally assume that argument ‘!1’ has value
     ‘!vars’:

          !1                           ↦ a b c
          !QUOTE(!1)                   ↦ '!vars'
          !EVAL(!1)                    ↦ a b c
          !QUOTE(!EVAL(!1))            ↦ 'a b c'

 -- Macro Function: !HEAD (arg)
 -- Macro Function: !TAIL (arg)
     ‘!HEAD’ expands to just the first token in an unquoted version of
     ARG, and ‘!TAIL’ to all the tokens after the first.

          !HEAD('a b c')               ↦ a
          !HEAD('a')                   ↦ a
          !HEAD(!NULL)                 ↦ empty
          !HEAD('')                    ↦ empty

          !TAIL('a b c')               ↦ b c
          !TAIL('a')                   ↦ empty
          !TAIL(!NULL)                 ↦ empty
          !TAIL('')                    ↦ empty

 -- Macro Function: !INDEX (haystack, needle)
     Looks for NEEDLE in HAYSTACK.  If it is present, expands to the
     1-based index of its first occurrence; if not, expands to 0.

          !INDEX(banana, an)           ↦ 2
          !INDEX(banana, nan)          ↦ 3
          !INDEX(banana, apple)        ↦ 0
          !INDEX("banana", nan)        ↦ 4
          !INDEX("banana", "nan")      ↦ 0
          !INDEX(!UNQUOTE("banana"), !UNQUOTE("nan")) ↦ 3

 -- Macro Function: !LENGTH (arg)
     Expands to a number token representing the number of characters in
     ARG.

          !LENGTH(123)                 ↦ 3
          !LENGTH(123.00)              ↦ 6
          !LENGTH( 123 )               ↦ 3
          !LENGTH("123")               ↦ 5
          !LENGTH(xyzzy)               ↦ 5
          !LENGTH("xyzzy")             ↦ 7
          !LENGTH("xy""zzy")           ↦ 9
          !LENGTH(!UNQUOTE("xyzzy"))   ↦ 5
          !LENGTH(!UNQUOTE("xy""zzy")) ↦ 6
          !LENGTH(!1)                  ↦ 5 if !1 is a b c
          !LENGTH(!1)                  ↦ 0 if !1 is empty
          !LENGTH(!NULL)               ↦ 0

 -- Macro Function: !NULL
     Expands to an empty character sequence.

          !NULL                        ↦ empty
          !QUOTE(!NULL)                ↦ ''

 -- Macro Function: !QUOTE (arg)
 -- Macro Function: !UNQUOTE (arg)
     The ‘!QUOTE’ function expands to its argument surrounded by
     apostrophes, doubling any apostrophes inside the argument to make
     sure that it is valid PSPP syntax for a string.  If the argument
     was already a quoted string, ‘!QUOTE’ expands to it unchanged.

     Given a quoted string argument, the ‘!UNQUOTED’ function expands to
     the string's contents, with the quotes removed and any doubled
     quote marks reduced to singletons.  If the argument was not a
     quoted string, ‘!UNQUOTE’ expands to the argument unchanged.

          !QUOTE(123.0)                ↦ '123.0'
          !QUOTE( 123 )                ↦ '123'
          !QUOTE('a b c')              ↦ 'a b c'
          !QUOTE("a b c")              ↦ "a b c"
          !QUOTE(!1)                   ↦ 'a ''b'' c' if !1 is a 'b' c

          !UNQUOTE(123.0)              ↦ 123.0
          !UNQUOTE( 123 )              ↦ 123
          !UNQUOTE('a b c')            ↦ a b c
          !UNQUOTE("a b c")            ↦ a b c
          !UNQUOTE(!1)                 ↦ a 'b' c if !1 is a 'b' c

          !QUOTE(!UNQUOTE(123.0))      ↦ '123.0'
          !QUOTE(!UNQUOTE( 123 ))      ↦ '123'
          !QUOTE(!UNQUOTE('a b c'))    ↦ 'a b c'
          !QUOTE(!UNQUOTE("a b c"))    ↦ 'a b c'
          !QUOTE(!UNQUOTE(!1))         ↦ 'a ''b'' c' if !1 is a 'b' c

 -- Macro Function: !SUBSTR (arg, start[, count])
     Expands to a substring of ARG starting from 1-based position START.
     If COUNT is given, it limits the number of characters in the
     expansion; if it is omitted, then the expansion extends to the end
     of ARG.

          !SUBSTR(banana, 3)           ↦ nana
          !SUBSTR(banana, 3, 3)        ↦ nan
          !SUBSTR("banana", 1, 3)         ↦ error (‘"ba’ is not a valid token)
          !SUBSTR(!UNQUOTE("banana"), 3) ↦ nana
          !SUBSTR("banana", 3, 3)      ↦ ana

          !SUBSTR(banana, 3, 0)        ↦ empty
          !SUBSTR(banana, 3, 10)       ↦ nana
          !SUBSTR(banana, 10, 3)       ↦ empty

 -- Macro Function: !UPCASE (arg)
     Expands to an unquoted version of ARG with all letters converted to
     uppercase.

          !UPCASE(freckle)             ↦ FRECKLE
          !UPCASE('freckle')           ↦ FRECKLE
          !UPCASE('a b c')             ↦ A B C
          !UPCASE('A B C')             ↦ A B C


File: pspp.info,  Node: Macro Expressions,  Next: Macro Conditional Expansion,  Prev: Macro Functions,  Up: DEFINE

14.2.7 Macro Expressions
------------------------

Macro expressions are used in conditional expansion and loops, which are
described in the following sections.  A macro expression may use the
following operators, listed in descending order of operator precedence:

‘()’
     Parentheses override the default operator precedence.

‘!EQ !NE !GT !LT !GE !LE = ~= <> > < >= <=’
     Relational operators compare their operands and yield a Boolean
     result, either ‘0’ for false or ‘1’ for true.

     These operators always compare their operands as strings.  This can
     be surprising when the strings are numbers because, e.g., ‘1 < 1.0’
     and ‘10 < 2’ both evaluate to ‘1’ (true).

     Comparisons are case sensitive, so that ‘a = A’ evaluates to ‘0’
     (false).

‘!NOT ~’
‘!AND &’
‘!OR |’
     Logical operators interpret their operands as Boolean values, where
     quoted or unquoted ‘0’ is false and anything else is true, and
     yield a Boolean result, either ‘0’ for false or ‘1’ for true.

   Macro expressions do not include any arithmetic operators.

   An operand in an expression may be a single token (including a macro
argument name) or a macro function invocation.  Either way, the
expression evaluator unquotes the operand, so that ‘1 = '1'’ is true.


File: pspp.info,  Node: Macro Conditional Expansion,  Next: Macro Loops,  Prev: Macro Expressions,  Up: DEFINE

14.2.8 Macro Conditional Expansion
----------------------------------

The ‘!IF’ construct may be used inside a macro body to allow for
conditional expansion.  It takes the following forms:

     !IF (EXPRESSION) !THEN TRUE-EXPANSION !IFEND
     !IF (EXPRESSION) !THEN TRUE-EXPANSION !ELSE FALSE-EXPANSION !IFEND

   When EXPRESSION evaluates to true, the macro processor expands
TRUE-EXPANSION; otherwise, it expands FALSE-EXPANSION, if it is present.
The macro processor considers quoted or unquoted ‘0’ to be false, and
anything else to be true.


File: pspp.info,  Node: Macro Loops,  Next: Macro Variable Assignment,  Prev: Macro Conditional Expansion,  Up: DEFINE

14.2.9 Macro Loops
------------------

The body of a macro may include two forms of loops: loops over numerical
ranges and loops over tokens.  Both forms expand a “loop body” multiple
times, each time setting a named “loop variable” to a different value.
The loop body typically expands the loop variable at least once.

   The MITERATE setting (*note SET MITERATE::) limits the number of
iterations in a loop.  This is a safety measure to ensure that macro
expansion terminates.  PSPP issues a warning when the MITERATE limit is
exceeded.

Loops Over Ranges
.................

     !DO !VAR = START !TO END [!BY STEP]
       BODY
     !DOEND

   A loop over a numerical range has the form shown above.  START, END,
and STEP (if included) must be expressions with numeric values.  The
macro processor accepts both integers and real numbers.  The macro
processor expands BODY for each numeric value from START to END,
inclusive.

   The default value for STEP is 1.  If STEP is positive and FIRST >
LAST, or if STEP is negative and FIRST < LAST, then the macro processor
doesn't expand the body at all.  STEP may not be zero.

Loops Over Tokens
.................

     !DO !VAR !IN (EXPRESSION)
       BODY
     !DOEND

   A loop over tokens takes the form shown above.  The macro processor
evaluates EXPRESSION and expands BODY once per token in the result,
substituting the token for !VAR each time it appears.


File: pspp.info,  Node: Macro Variable Assignment,  Next: Macro Settings,  Prev: Macro Loops,  Up: DEFINE

14.2.10 Macro Variable Assignment
---------------------------------

The ‘!LET’ construct evaluates an expression and assigns the result to a
macro variable.  It may create a new macro variable or change the value
of one created by a previous ‘!LET’ or ‘!DO’, but it may not change the
value of a macro argument.  ‘!LET’ has the following form:

     !LET !VAR = EXPRESSION

   If EXPRESSION is more than one token, it must be enclosed in
parentheses.


File: pspp.info,  Node: Macro Settings,  Next: Macro Notes,  Prev: Macro Variable Assignment,  Up: DEFINE

14.2.11 Macro Settings
----------------------

Some macro behavior is controlled through the SET command (*note SET::).
This section describes these settings.

   Any SET command that changes these settings within a macro body only
takes effect following the macro.  This is because PSPP expands a
macro's entire body at once, so that the SET command inside the body
only executes afterwards.

   The MEXPAND setting (*note SET MEXPAND::) controls whether macros
will be expanded at all.  By default, macro expansion is on.  To avoid
expansion of macros called within a macro body, use ‘!OFFEXPAND’ and
‘!ONEXPAND’ (*note Controlling Macro Expansion::).

   When MPRINT (*note SET MPRINT::) is turned on, PSPP outputs an
expansion of each macro called.  This feature can be useful for
debugging macro definitions.  For reading the expanded version, note
that macro expansion removes comments and standardizes white space.

   MNEST (*note SET MNEST::) limits the depth of expansion of macro
calls, that is, the nesting level of macro expansion.  The default is
50.  This is mainly useful to avoid infinite expansion in the case of a
macro that calls itself.

   MITERATE (*note SET MITERATE::) limits the number of iterations in a
‘!DO’ construct.  The default is 1000.


File: pspp.info,  Node: Macro Notes,  Prev: Macro Settings,  Up: DEFINE

14.2.12 Additional Notes
------------------------

14.2.12.1 Calling Macros from Macros
....................................

If the body of macro A includes a call to macro B, the call can use
macro arguments (including ‘!*’) and macro variables as part of
arguments to B. For ‘!TOKENS’ arguments, the argument or variable name
counts as one token regardless of the number that it expands into; for
‘!CHAREND’ and ‘!ENCLOSE’ arguments, the delimiters come only from the
call, not the expansions; and ‘!CMDEND’ ends at the calling command, not
any end of command within an argument or variable.

   Macro functions are not supported as part of the arguments in a macro
call.  To get the same effect, use ‘!LET’ to define a macro variable,
then pass the macro variable to the macro.

   When macro A calls macro B, the order of their ‘DEFINE’ commands
doesn't matter, as long as macro B has been defined when A is called.

14.2.12.2 Command Terminators
.............................

Macros and command terminators require care.  Macros honor the syntax
differences between interactive and batch syntax (*note Syntax
Variants::), which means that the interpretation of a macro can vary
depending on the syntax mode in use.  We assume here that interactive
mode is in use, in which ‘.’ at the end of a line is the primary way to
end a command.

   The ‘DEFINE’ command needs to end with ‘.’ following the
‘!ENDDEFINE’.  The macro body may contain ‘.’ if it is intended to
expand to whole commands, but using ‘.’ within a macro body that expands
to just syntax fragments (such as a list of variables) will cause syntax
errors.

   Macro directives such as ‘!IF’ and ‘!DO’ do not end with ‘.’.

14.2.12.3 Expansion Contexts
............................

Macros do not expand within comments, whether introduced within a line
by ‘/*’ or as a separate COMMENT or ‘*’ commands (*note COMMENT::).
(SPSS does expand macros in COMMENT and ‘*’.)

   Macros do not expand within quoted strings.

   Macros are expanded in the ‘TITLE’ and ‘SUBTITLE’ commands as long as
their arguments are not quoted strings.

14.2.12.4 PRESERVE and RESTORE
..............................

Some macro bodies might use the SET command to change certain settings.
When this is the case, consider using the PRESERVE and RESTORE commands
to save and then restore these settings.  *Note PRESERVE and RESTORE::.


File: pspp.info,  Node: DO IF,  Next: DO REPEAT,  Prev: DEFINE,  Up: Conditionals and Looping

14.3 DO IF
==========

     DO IF condition.
             ...
     [ELSE IF condition.
             ...
     ]...
     [ELSE.
             ...]
     END IF.

   ‘DO IF’ allows one of several sets of transformations to be executed,
depending on user-specified conditions.

   If the specified boolean expression evaluates as true, then the block
of code following ‘DO IF’ is executed.  If it evaluates as missing, then
none of the code blocks is executed.  If it is false, then the boolean
expression on the first ‘ELSE IF’, if present, is tested in turn, with
the same rules applied.  If all expressions evaluate to false, then the
‘ELSE’ code block is executed, if it is present.

   When ‘DO IF’ or ‘ELSE IF’ is specified following ‘TEMPORARY’ (*note
TEMPORARY::), the ‘LAG’ function may not be used (*note LAG::).


File: pspp.info,  Node: DO REPEAT,  Next: LOOP,  Prev: DO IF,  Up: Conditionals and Looping

14.4 DO REPEAT
==============

     DO REPEAT dummy_name=expansion....
             ...
     END REPEAT [PRINT].

     expansion takes one of the following forms:
             var_list
             num_or_range...
             'string'...
             ALL

     num_or_range takes one of the following forms:
             number
             num1 TO num2

   ‘DO REPEAT’ repeats a block of code, textually substituting different
variables, numbers, or strings into the block with each repetition.

   Specify a dummy variable name followed by an equals sign (‘=’) and
the list of replacements.  Replacements can be a list of existing or new
variables, numbers, strings, or ‘ALL’ to specify all existing variables.
When numbers are specified, runs of increasing integers may be indicated
as ‘NUM1 TO NUM2’, so that ‘1 TO 5’ is short for ‘1 2 3 4 5’.

   Multiple dummy variables can be specified.  Each variable must have
the same number of replacements.

   The code within ‘DO REPEAT’ is repeated as many times as there are
replacements for each variable.  The first time, the first value for
each dummy variable is substituted; the second time, the second value
for each dummy variable is substituted; and so on.

   Dummy variable substitutions work like macros.  They take place
anywhere in a line that the dummy variable name occurs.  This includes
command and subcommand names, so command and subcommand names that
appear in the code block should not be used as dummy variable
identifiers.  Dummy variable substitutions do not occur inside quoted
strings, comments, unquoted strings (such as the text on the ‘TITLE’ or
‘DOCUMENT’ command), or inside ‘BEGIN DATA’...‘END DATA’.

   Substitution occurs only on whole words, so that, for example, a
dummy variable PRINT would not be substituted into the word PRINTOUT.

   New variable names used as replacements are not automatically created
as variables, but only if used in the code block in a context that would
create them, e.g. on a ‘NUMERIC’ or ‘STRING’ command or on the left side
of a ‘COMPUTE’ assignment.

   Any command may appear within ‘DO REPEAT’, including nested ‘DO
REPEAT’ commands.  If ‘INCLUDE’ or ‘INSERT’ appears within ‘DO REPEAT’,
the substitutions do not apply to the included file.

   If ‘PRINT’ is specified on ‘END REPEAT’, the commands after
substitutions are made should be printed to the listing file, prefixed
by a plus sign (‘+’).  This feature is not yet implemented.


File: pspp.info,  Node: LOOP,  Prev: DO REPEAT,  Up: Conditionals and Looping

14.5 LOOP
=========

     LOOP [INDEX_VAR=START TO END [BY INCR]] [IF CONDITION].
             ...
     END LOOP [IF CONDITION].

   ‘LOOP’ iterates a group of commands.  A number of termination options
are offered.

   Specify index_var to make that variable count from one value to
another by a particular increment.  INDEX_VAR must be a pre-existing
numeric variable.  START, END, and INCR are numeric expressions (*note
Expressions::.)

   During the first iteration, INDEX_VAR is set to the value of START.
During each successive iteration, INDEX_VAR is increased by the value of
INCR.  If END > START, then the loop terminates when INDEX_VAR > END;
otherwise it terminates when INDEX_VAR < END.  If INCR is not specified
then it defaults to +1 or -1 as appropriate.

   If END > START and INCR < 0, or if END < START and INCR > 0, then the
loop is never executed.  INDEX_VAR is nevertheless set to the value of
start.

   Modifying INDEX_VAR within the loop is allowed, but it has no effect
on the value of INDEX_VAR in the next iteration.

   Specify a boolean expression for the condition on ‘LOOP’ to cause the
loop to be executed only if the condition is true.  If the condition is
false or missing before the loop contents are executed the first time,
the loop contents are not executed at all.

   If index and condition clauses are both present on ‘LOOP’, the index
variable is always set before the condition is evaluated.  Thus, a
condition that makes use of the index variable will always see the index
value to be used in the next execution of the body.

   Specify a boolean expression for the condition on ‘END LOOP’ to cause
the loop to terminate if the condition is true after the enclosed code
block is executed.  The condition is evaluated at the end of the loop,
not at the beginning, so that the body of a loop with only a condition
on ‘END LOOP’ will always execute at least once.

   If the index clause is not present, then the global ‘MXLOOPS’
setting, which defaults to 40, limits the number of iterations (*note
SET MXLOOPS::).

   ‘BREAK’ also terminates ‘LOOP’ execution (*note BREAK::).

   Loop index variables are by default reset to system-missing from one
case to another, not left, unless a scratch variable is used as index.
When loops are nested, this is usually undesired behavior, which can be
corrected with ‘LEAVE’ (*note LEAVE::) or by using a scratch variable as
the loop index.

   When ‘LOOP’ or ‘END LOOP’ is specified following ‘TEMPORARY’ (*note
TEMPORARY::), the ‘LAG’ function may not be used (*note LAG::).


File: pspp.info,  Node: Statistics,  Next: Matrices,  Prev: Conditionals and Looping,  Up: Top

15 Statistics
*************

This chapter documents the statistical procedures that PSPP supports so
far.

* Menu:

* DESCRIPTIVES::                Descriptive statistics.
* FREQUENCIES::                 Frequency tables.
* EXAMINE::                     Testing data for normality.
* GRAPH::                       Plot data.
* CORRELATIONS::                Correlation tables.
* CROSSTABS::                   Crosstabulation tables.
* CTABLES::                     Custom tables.
* FACTOR::                      Factor analysis and Principal Components analysis.
* GLM::                         Univariate Linear Models.
* LOGISTIC REGRESSION::         Bivariate Logistic Regression.
* MEANS::                       Average values and other statistics.
* NPAR TESTS::                  Nonparametric tests.
* T-TEST::                      Test hypotheses about means.
* ONEWAY::                      One way analysis of variance.
* QUICK CLUSTER::               K-Means clustering.
* RANK::                        Compute rank scores.
* REGRESSION::                  Linear regression.
* RELIABILITY::                 Reliability analysis.
* ROC::                         Receiver Operating Characteristic.


File: pspp.info,  Node: DESCRIPTIVES,  Next: FREQUENCIES,  Up: Statistics

15.1 DESCRIPTIVES
=================

     DESCRIPTIVES
             /VARIABLES=VAR_LIST
             /MISSING={VARIABLE,LISTWISE} {INCLUDE,NOINCLUDE}
             /FORMAT={LABELS,NOLABELS} {NOINDEX,INDEX} {LINE,SERIAL}
             /SAVE
             /STATISTICS={ALL,MEAN,SEMEAN,STDDEV,VARIANCE,KURTOSIS,
                          SKEWNESS,RANGE,MINIMUM,MAXIMUM,SUM,DEFAULT,
                          SESKEWNESS,SEKURTOSIS}
             /SORT={NONE,MEAN,SEMEAN,STDDEV,VARIANCE,KURTOSIS,SKEWNESS,
                    RANGE,MINIMUM,MAXIMUM,SUM,SESKEWNESS,SEKURTOSIS,NAME}
                   {A,D}

   The ‘DESCRIPTIVES’ procedure reads the active dataset and outputs
linear descriptive statistics requested by the user.  In addition, it
can optionally compute Z-scores.

   The ‘VARIABLES’ subcommand, which is required, specifies the list of
variables to be analyzed.  Keyword ‘VARIABLES’ is optional.

   All other subcommands are optional:

   The ‘MISSING’ subcommand determines the handling of missing
variables.  If ‘INCLUDE’ is set, then user-missing values are included
in the calculations.  If ‘NOINCLUDE’ is set, which is the default,
user-missing values are excluded.  If ‘VARIABLE’ is set, then missing
values are excluded on a variable by variable basis; if ‘LISTWISE’ is
set, then the entire case is excluded whenever any value in that case
has a system-missing or, if ‘INCLUDE’ is set, user-missing value.

   The ‘FORMAT’ subcommand has no effect.  It is accepted for backward
compatibility.

   The ‘SAVE’ subcommand causes ‘DESCRIPTIVES’ to calculate Z scores for
all the specified variables.  The Z scores are saved to new variables.
Variable names are generated by trying first the original variable name
with Z prepended and truncated to a maximum of 8 characters, then the
names ZSC000 through ZSC999, STDZ00 through STDZ09, ZZZZ00 through
ZZZZ09, ZQZQ00 through ZQZQ09, in that sequence.  In addition, Z score
variable names can be specified explicitly on ‘VARIABLES’ in the
variable list by enclosing them in parentheses after each variable.
When Z scores are calculated, PSPP ignores ‘TEMPORARY’, treating
temporary transformations as permanent.

   The ‘STATISTICS’ subcommand specifies the statistics to be displayed:

‘ALL’
     All of the statistics below.
‘MEAN’
     Arithmetic mean.
‘SEMEAN’
     Standard error of the mean.
‘STDDEV’
     Standard deviation.
‘VARIANCE’
     Variance.
‘KURTOSIS’
     Kurtosis and standard error of the kurtosis.
‘SKEWNESS’
     Skewness and standard error of the skewness.
‘RANGE’
     Range.
‘MINIMUM’
     Minimum value.
‘MAXIMUM’
     Maximum value.
‘SUM’
     Sum.
‘DEFAULT’
     Mean, standard deviation of the mean, minimum, maximum.
‘SEKURTOSIS’
     Standard error of the kurtosis.
‘SESKEWNESS’
     Standard error of the skewness.

   The ‘SORT’ subcommand specifies how the statistics should be sorted.
Most of the possible values should be self-explanatory.  ‘NAME’ causes
the statistics to be sorted by name.  By default, the statistics are
listed in the order that they are specified on the ‘VARIABLES’
subcommand.  The ‘A’ and ‘D’ settings request an ascending or descending
sort order, respectively.

15.1.1 Descriptives Example
---------------------------

The ‘physiology.sav’ file contains various physiological data for a
sample of persons.  Running the ‘DESCRIPTIVES’ command on the variables
height and temperature with the default options allows one to see simple
linear statistics for these two variables.  In *note Example 15.1:
descriptives:ex, these variables are specfied on the ‘VARIABLES’
subcommand and the ‘SAVE’ option has been used, to request that Z scores
be calculated.

   After the command has completed, this example runs ‘DESCRIPTIVES’
again, this time on the zheight and ztemperature variables, which are
the two normalized (Z-score) variables generated by the first
‘DESCRIPTIVES’ command.

     get file='physiology.sav'.
     
     descriptives
             /variables = height temperature
             /save.
     
     descriptives
             /variables = zheight ztemperature.

Example 15.1: Running two ‘DESCRIPTIVES’ commands, one with the ‘SAVE’
subcommand

 [image src="screenshots/descriptives-ad.png" ]

Screenshot 15.1: The Descriptives dialog box with two variables and
Z-Scores option selected

   In *note Result 15.1: descriptives:res, we can see that there are 40
valid data for each of the variables and no missing values.  The mean
average of the height and temperature is 16677.12 and 37.02
respectively.  The descriptive statistics for temperature seem
reasonable.  However there is a very high standard deviation for height
and a suspiciously low minimum.  This is due to a data entry error in
the data (*note Identifying incorrect data::).

   In the second Descriptive Statistics command, one can see that the
mean and standard deviation of both Z score variables is 0 and 1
respectively.  All Z score statistics should have these properties since
they are normalized versions of the original scores.

 [image src="pspp-figures/descriptives.png" text="              Mapping of Variables to Z-scores
+--------------------------------------------+------------+
|                   Source                   |   Target   |
+--------------------------------------------+------------+
|Height in millimeters                       |Zheight     |
|Internal body temperature in degrees Celcius|Ztemperature|
+--------------------------------------------+------------+

                             Descriptive Statistics
+------------------------------------------+--+-------+-------+-------+-------+
|                                          | N|  Mean |Std Dev|Minimum|Maximum|
+------------------------------------------+--+-------+-------+-------+-------+
|Height in millimeters                     |40|1677.12| 262.87|    179|   1903|
|Internal body temperature in degrees      |40|  37.02|   1.82|  32.59|  39.97|
|Celcius                                   |  |       |       |       |       |
|Valid N (listwise)                        |40|       |       |       |       |
|Missing N (listwise)                      | 0|       |       |       |       |
+------------------------------------------+--+-------+-------+-------+-------+

                             Descriptive Statistics
+-----------------------------------------+--+---------+------+-------+-------+
|                                         |  |         |  Std |       |       |
|                                         | N|   Mean  |  Dev |Minimum|Maximum|
+-----------------------------------------+--+---------+------+-------+-------+
|Z-score of Height in millimeters         |40|1.93E-015|  1.00|  -5.70|    .86|
|Z-score of Internal body temperature in  |40|1.37E-015|  1.00|  -2.44|   1.62|
|degrees Celcius                          |  |         |      |       |       |
|Valid N (listwise)                       |40|         |      |       |       |
|Missing N (listwise)                     | 0|         |      |       |       |
+-----------------------------------------+--+---------+------+-------+-------+" ]


Result 15.1: Descriptives statistics including two normalized variables
(Z-scores)


File: pspp.info,  Node: FREQUENCIES,  Next: EXAMINE,  Prev: DESCRIPTIVES,  Up: Statistics

15.2 FREQUENCIES
================

     FREQUENCIES
             /VARIABLES=VAR_LIST
             /FORMAT={TABLE,NOTABLE,LIMIT(LIMIT)}
                     {AVALUE,DVALUE,AFREQ,DFREQ}
             /MISSING={EXCLUDE,INCLUDE}
             /STATISTICS={DEFAULT,MEAN,SEMEAN,MEDIAN,MODE,STDDEV,VARIANCE,
                          KURTOSIS,SKEWNESS,RANGE,MINIMUM,MAXIMUM,SUM,
                          SESKEWNESS,SEKURTOSIS,ALL,NONE}
             /NTILES=NTILES
             /PERCENTILES=percent...
             /HISTOGRAM=[MINIMUM(X_MIN)] [MAXIMUM(X_MAX)]
                        [{FREQ[(Y_MAX)],PERCENT[(Y_MAX)]}] [{NONORMAL,NORMAL}]
             /PIECHART=[MINIMUM(X_MIN)] [MAXIMUM(X_MAX)]
                       [{FREQ,PERCENT}] [{NOMISSING,MISSING}]
             /BARCHART=[MINIMUM(X_MIN)] [MAXIMUM(X_MAX)]
                       [{FREQ,PERCENT}]
             /ORDER={ANALYSIS,VARIABLE}


     (These options are not currently implemented.)
             /HBAR=...
             /GROUPED=...

   The ‘FREQUENCIES’ procedure outputs frequency tables for specified
variables.  ‘FREQUENCIES’ can also calculate and display descriptive
statistics (including median and mode) and percentiles, and various
graphical representations of the frequency distribution.

   The ‘VARIABLES’ subcommand is the only required subcommand.  Specify
the variables to be analyzed.

   The ‘FORMAT’ subcommand controls the output format.  It has several
possible settings:

   ‘’ ‘TABLE’, the default, causes a frequency table to be output for
     every variable specified.  ‘NOTABLE’ prevents them from being
     output.  ‘LIMIT’ with a numeric argument causes them to be output
     except when there are more than the specified number of values in
     the table.

   ‘’ Normally frequency tables are sorted in ascending order by value.
     This is ‘AVALUE’.  ‘DVALUE’ tables are sorted in descending order
     by value.  ‘AFREQ’ and ‘DFREQ’ tables are sorted in ascending and
     descending order, respectively, by frequency count.

   The ‘MISSING’ subcommand controls the handling of user-missing
values.  When ‘EXCLUDE’, the default, is set, user-missing values are
not included in frequency tables or statistics.  When ‘INCLUDE’ is set,
user-missing are included.  System-missing values are never included in
statistics, but are listed in frequency tables.

   The available ‘STATISTICS’ are the same as available in
‘DESCRIPTIVES’ (*note DESCRIPTIVES::), with the addition of ‘MEDIAN’,
the data's median value, and MODE, the mode.  (If there are multiple
modes, the smallest value is reported.)  By default, the mean, standard
deviation of the mean, minimum, and maximum are reported for each
variable.

   ‘PERCENTILES’ causes the specified percentiles to be reported.  The
percentiles should be presented at a list of numbers between 0 and 100
inclusive.  The ‘NTILES’ subcommand causes the percentiles to be
reported at the boundaries of the data set divided into the specified
number of ranges.  For instance, ‘/NTILES=4’ would cause quartiles to be
reported.

   The ‘HISTOGRAM’ subcommand causes the output to include a histogram
for each specified numeric variable.  The X axis by default ranges from
the minimum to the maximum value observed in the data, but the ‘MINIMUM’
and ‘MAXIMUM’ keywords can set an explicit range.  (1)  Histograms are
not created for string variables.

   Specify ‘NORMAL’ to superimpose a normal curve on the histogram.

   The ‘PIECHART’ subcommand adds a pie chart for each variable to the
data.  Each slice represents one value, with the size of the slice
proportional to the value's frequency.  By default, all non-missing
values are given slices.  The ‘MINIMUM’ and ‘MAXIMUM’ keywords can be
used to limit the displayed slices to a given range of values.  The
keyword ‘NOMISSING’ causes missing values to be omitted from the
piechart.  This is the default.  If instead, ‘MISSING’ is specified,
then the pie chart includes a single slice representing all system
missing and user-missing cases.

   The ‘BARCHART’ subcommand produces a bar chart for each variable.
The ‘MINIMUM’ and ‘MAXIMUM’ keywords can be used to omit categories
whose counts which lie outside the specified limits.  The ‘FREQ’ option
(default) causes the ordinate to display the frequency of each category,
whereas the ‘PERCENT’ option displays relative percentages.

   The ‘FREQ’ and ‘PERCENT’ options on ‘HISTOGRAM’ and ‘PIECHART’ are
accepted but not currently honoured.

   The ‘ORDER’ subcommand is accepted but ignored.

15.2.1 Frequencies Example
--------------------------

*note Example 15.2: frequencies:ex. runs a frequency analysis on the sex
and occupation variables from the ‘personnel.sav’ file.  This is useful
to get a general idea of the way in which these nominal variables are
distributed.

     get file='personnel.sav'.
     
     frequencies /variables = sex occupation
                 /statistics = none.

Example 15.2: Running frequencies on the sex and occupation variables

   If you are using the graphic user interface, the dialog box is set up
such that by default, several statistics are calculated.  Some are not
particularly useful for categorical variables, so you may want to
disable those.

 [image src="screenshots/frequencies-ad.png" ]

Screenshot 15.2: The frequencies dialog box with the sex and occupation
variables selected

   From *note Result 15.2: frequencies:res. it is evident that there are
33 males, 21 females and 2 persons for whom their sex has not been
entered.

   One can also see how many of each occupation there are in the data.
When dealing with string variables used as nominal values, running a
frequency analysis is useful to detect data input entries.  Notice that
one occupation value has been mistyped as "Scrientist".  This entry
should be corrected, or marked as missing before using the data.

 [image src="pspp-figures/frequencies.png" text="                                sex
+--------------+---------+-------+-------------+------------------+
|              |Frequency|Percent|Valid Percent|Cumulative Percent|
+--------------+---------+-------+-------------+------------------+
|Valid   Male  |       33|  58.9%|        61.1%|             61.1%|
|        Female|       21|  37.5%|        38.9%|            100.0%|
+--------------+---------+-------+-------------+------------------+
|Missing .     |        2|   3.6%|             |                  |
+--------------+---------+-------+-------------+------------------+
|Total         |       56| 100.0%|             |                  |
+--------------+---------+-------+-------------+------------------+

                                  occupation
+------------------------+---------+-------+-------------+------------------+
|                        |Frequency|Percent|Valid Percent|Cumulative Percent|
+------------------------+---------+-------+-------------+------------------+
|Valid Artist            |        8|  14.3%|        14.3%|             14.3%|
|      Baker             |        2|   3.6%|         3.6%|             17.9%|
|      Barrister         |        1|   1.8%|         1.8%|             19.6%|
|      Carpenter         |        4|   7.1%|         7.1%|             26.8%|
|      Cleaner           |        4|   7.1%|         7.1%|             33.9%|
|      Cook              |        7|  12.5%|        12.5%|             46.4%|
|      Manager           |        8|  14.3%|        14.3%|             60.7%|
|      Mathematician     |        4|   7.1%|         7.1%|             67.9%|
|      Painter           |        2|   3.6%|         3.6%|             71.4%|
|      Payload Specialist|        1|   1.8%|         1.8%|             73.2%|
|      Plumber           |        5|   8.9%|         8.9%|             82.1%|
|      Scientist         |        7|  12.5%|        12.5%|             94.6%|
|      Scrientist        |        1|   1.8%|         1.8%|             96.4%|
|      Tailor            |        2|   3.6%|         3.6%|            100.0%|
+------------------------+---------+-------+-------------+------------------+
|Total                   |       56| 100.0%|             |                  |
+------------------------+---------+-------+-------------+------------------+" ]


Result 15.2: The relative frequencies of sex and occupation

   ---------- Footnotes ----------

   (1) The number of bins is chosen according to the Freedman-Diaconis
rule: 2 \times IQR(x)n^{-1/3}, where IQR(x) is the interquartile range
of x and n is the number of samples.  Note that ‘EXAMINE’ uses a
different algorithm to determine bin sizes.


File: pspp.info,  Node: EXAMINE,  Next: GRAPH,  Prev: FREQUENCIES,  Up: Statistics

15.3 EXAMINE
============

     EXAMINE
             VARIABLES= VAR1 [VAR2] ... [VARN]
                [BY FACTOR1 [BY SUBFACTOR1]
                  [ FACTOR2 [BY SUBFACTOR2]]
                  ...
                  [ FACTOR3 [BY SUBFACTOR3]]
                 ]
             /STATISTICS={DESCRIPTIVES, EXTREME[(N)], ALL, NONE}
             /PLOT={BOXPLOT, NPPLOT, HISTOGRAM, SPREADLEVEL[(T)], ALL, NONE}
             /CINTERVAL P
             /COMPARE={GROUPS,VARIABLES}
             /ID=IDENTITY_VARIABLE
             /{TOTAL,NOTOTAL}
             /PERCENTILE=[PERCENTILES]={HAVERAGE, WAVERAGE, ROUND, AEMPIRICAL, EMPIRICAL }
             /MISSING={LISTWISE, PAIRWISE} [{EXCLUDE, INCLUDE}]
     		[{NOREPORT,REPORT}]


   The ‘EXAMINE’ command is used to perform exploratory data analysis.
In particular, it is useful for testing how closely a distribution
follows a normal distribution, and for finding outliers and extreme
values.

   The ‘VARIABLES’ subcommand is mandatory.  It specifies the dependent
variables and optionally variables to use as factors for the analysis.
Variables listed before the first ‘BY’ keyword (if any) are the
dependent variables.  The dependent variables may optionally be followed
by a list of factors which tell PSPP how to break down the analysis for
each dependent variable.

   Following the dependent variables, factors may be specified.  The
factors (if desired) should be preceded by a single ‘BY’ keyword.  The
format for each factor is
     FACTORVAR [BY SUBFACTORVAR].
   Each unique combination of the values of FACTORVAR and SUBFACTORVAR
divide the dataset into “cells”.  Statistics are calculated for each
cell and for the entire dataset (unless ‘NOTOTAL’ is given).

   The ‘STATISTICS’ subcommand specifies which statistics to show.
‘DESCRIPTIVES’ produces a table showing some parametric and
non-parametrics statistics.  ‘EXTREME’ produces a table showing the
extremities of each cell.  A number in parentheses, N determines how
many upper and lower extremities to show.  The default number is 5.

   The subcommands ‘TOTAL’ and ‘NOTOTAL’ are mutually exclusive.  If
‘TOTAL’ appears, then statistics for the entire dataset as well as for
each cell are produced.  If ‘NOTOTAL’ appears, then statistics are
produced only for the cells (unless no factor variables have been
given).  These subcommands have no effect if there have been no factor
variables specified.

   The ‘PLOT’ subcommand specifies which plots are to be produced if
any.  Available plots are ‘HISTOGRAM’, ‘NPPLOT’, ‘BOXPLOT’ and
‘SPREADLEVEL’.  The first three can be used to visualise how closely
each cell conforms to a normal distribution, whilst the spread vs. level
plot can be useful to visualise how the variance differs between
factors.  Boxplots show you the outliers and extreme values.  (1)

   The ‘SPREADLEVEL’ plot displays the interquartile range versus the
median.  It takes an optional parameter T, which specifies how the data
should be transformed prior to plotting.  The given value T is a power
to which the data are raised.  For example, if T is given as 2, then the
square of the data is used.  Zero, however is a special value.  If T is
0 or is omitted, then data are transformed by taking its natural
logarithm instead of raising to the power of T.

   When one or more plots are requested, ‘EXAMINE’ also performs the
Shapiro-Wilk test for each category.  There are however a number of
provisos:
   • All weight values must be integer.
   • The cumulative weight value must be in the range [3, 5000]

   The ‘COMPARE’ subcommand is only relevant if producing boxplots, and
it is only useful there is more than one dependent variable and at least
one factor.  If ‘/COMPARE=GROUPS’ is specified, then one plot per
dependent variable is produced, each of which contain boxplots for all
the cells.  If ‘/COMPARE=VARIABLES’ is specified, then one plot per cell
is produced, each containing one boxplot per dependent variable.  If the
‘/COMPARE’ subcommand is omitted, then PSPP behaves as if
‘/COMPARE=GROUPS’ were given.

   The ‘ID’ subcommand is relevant only if ‘/PLOT=BOXPLOT’ or
‘/STATISTICS=EXTREME’ has been given.  If given, it should provide the
name of a variable which is to be used to labels extreme values and
outliers.  Numeric or string variables are permissible.  If the ‘ID’
subcommand is not given, then the case number is used for labelling.

   The ‘CINTERVAL’ subcommand specifies the confidence interval to use
in calculation of the descriptives command.  The default is 95%.

   The ‘PERCENTILES’ subcommand specifies which percentiles are to be
calculated, and which algorithm to use for calculating them.  The
default is to calculate the 5, 10, 25, 50, 75, 90, 95 percentiles using
the ‘HAVERAGE’ algorithm.

   The ‘TOTAL’ and ‘NOTOTAL’ subcommands are mutually exclusive.  If
‘NOTOTAL’ is given and factors have been specified in the ‘VARIABLES’
subcommand, then statistics for the unfactored dependent variables are
produced in addition to the factored variables.  If there are no factors
specified then ‘TOTAL’ and ‘NOTOTAL’ have no effect.

   The following example generates descriptive statistics and histograms
for two variables SCORE1 and SCORE2.  Two factors are given, viz: GENDER
and GENDER BY CULTURE.  Therefore, the descriptives and histograms are
generated for each distinct value of GENDER _and_ for each distinct
combination of the values of GENDER and RACE.  Since the ‘NOTOTAL’
keyword is given, statistics and histograms for SCORE1 and SCORE2
covering the whole dataset are not produced.
     EXAMINE SCORE1 SCORE2 BY
             GENDER
             GENDER BY CULTURE
             /STATISTICS = DESCRIPTIVES
             /PLOT = HISTOGRAM
             /NOTOTAL.

   Here is a second example showing how the ‘examine’ command can be
used to find extremities.
     EXAMINE HEIGHT WEIGHT BY
             GENDER
             /STATISTICS = EXTREME (3)
             /PLOT = BOXPLOT
             /COMPARE = GROUPS
             /ID = NAME.
   In this example, we look at the height and weight of a sample of
individuals and how they differ between male and female.  A table
showing the 3 largest and the 3 smallest values of height and weight for
each gender, and for the whole dataset as are shown.  In addition, the
‘/PLOT’ subcommand requests boxplots.  Because ‘/COMPARE = GROUPS’ was
specified, boxplots for male and female are shown in juxtaposed in the
same graphic, allowing us to easily see the difference between the
genders.  Since the variable NAME was specified on the ‘ID’ subcommand,
values of the NAME variable are used to label the extreme values.

   *Warning!*  If you specify many dependent variables or factor
variables for which there are many distinct values, then ‘EXAMINE’ will
produce a very large quantity of output.

   ---------- Footnotes ----------

   (1) ‘HISTOGRAM’ uses Sturges' rule to determine the number of bins,
as approximately 1 + \log2(n), where n is the number of samples.  Note
that ‘FREQUENCIES’ uses a different algorithm to find the bin size.


File: pspp.info,  Node: GRAPH,  Next: CORRELATIONS,  Prev: EXAMINE,  Up: Statistics

15.4 GRAPH
==========

     GRAPH
             /HISTOGRAM [(NORMAL)]= VAR
             /SCATTERPLOT [(BIVARIATE)] = VAR1 WITH VAR2 [BY VAR3]
             /BAR = {SUMMARY-FUNCTION(VAR1) | COUNT-FUNCTION} BY VAR2 [BY VAR3]
             [ /MISSING={LISTWISE, VARIABLE} [{EXCLUDE, INCLUDE}] ]
     		[{NOREPORT,REPORT}]


   The ‘GRAPH’ command produces graphical plots of data.  Only one of
the subcommands ‘HISTOGRAM’, ‘BAR’ or ‘SCATTERPLOT’ can be specified,
i.e.  only one plot can be produced per call of ‘GRAPH’.  The ‘MISSING’
is optional.

* Menu:

* SCATTERPLOT::             Cartesian Plots
* HISTOGRAM::               Histograms
* BAR CHART::               Bar Charts


File: pspp.info,  Node: SCATTERPLOT,  Next: HISTOGRAM,  Up: GRAPH

15.4.1 Scatterplot
------------------

The subcommand ‘SCATTERPLOT’ produces an xy plot of the data.  ‘GRAPH’
uses the third variable VAR3, if specified, to determine the colours
and/or markers for the plot.  The following is an example for producing
a scatterplot.

     GRAPH
             /SCATTERPLOT = HEIGHT WITH WEIGHT BY GENDER.

   This example produces a scatterplot where HEIGHT is plotted versus
WEIGHT.  Depending on the value of the GENDER variable, the colour of
the datapoint is different.  With this plot it is possible to analyze
gender differences for HEIGHT versus WEIGHT relation.


File: pspp.info,  Node: HISTOGRAM,  Next: BAR CHART,  Prev: SCATTERPLOT,  Up: GRAPH

15.4.2 Histogram
----------------

The subcommand ‘HISTOGRAM’ produces a histogram.  Only one variable is
allowed for the histogram plot.  The keyword ‘NORMAL’ may be specified
in parentheses, to indicate that the ideal normal curve should be
superimposed over the histogram.  For an alternative method to produce
histograms *note EXAMINE::.  The following example produces a histogram
plot for the variable WEIGHT.

     GRAPH
             /HISTOGRAM = WEIGHT.


File: pspp.info,  Node: BAR CHART,  Prev: HISTOGRAM,  Up: GRAPH

15.4.3 Bar Chart
----------------

The subcommand ‘BAR’ produces a bar chart.  This subcommand requires
that a COUNT-FUNCTION be specified (with no arguments) or a
SUMMARY-FUNCTION with a variable VAR1 in parentheses.  Following the
summary or count function, the keyword ‘BY’ should be specified and then
a catagorical variable, VAR2.  The values of the variable VAR2 determine
the labels of the bars to be plotted.  Optionally a second categorical
variable VAR3 may be specified in which case a clustered (grouped) bar
chart is produced.

   Valid count functions are
‘COUNT’
     The weighted counts of the cases in each category.
‘PCT’
     The weighted counts of the cases in each category expressed as a
     percentage of the total weights of the cases.
‘CUFREQ’
     The cumulative weighted counts of the cases in each category.
‘CUPCT’
     The cumulative weighted counts of the cases in each category
     expressed as a percentage of the total weights of the cases.

   The summary function is applied to VAR1 across all cases in each
category.  The recognised summary functions are:
‘SUM’
     The sum.
‘MEAN’
     The arithmetic mean.
‘MAXIMUM’
     The maximum value.
‘MINIMUM’
     The minimum value.

   The following examples assume a dataset which is the results of a
survey.  Each respondent has indicated annual income, their sex and city
of residence.  One could create a bar chart showing how the mean income
varies between of residents of different cities, thus:
     GRAPH  /BAR  = MEAN(INCOME) BY CITY.

   This can be extended to also indicate how income in each city differs
between the sexes.
     GRAPH  /BAR  = MEAN(INCOME) BY CITY BY SEX.

   One might also want to see how many respondents there are from each
city.  This can be achieved as follows:
     GRAPH  /BAR  = COUNT BY CITY.

   Bar charts can also be produced using the *note FREQUENCIES:: and
*note CROSSTABS:: commands.


File: pspp.info,  Node: CORRELATIONS,  Next: CROSSTABS,  Prev: GRAPH,  Up: Statistics

15.5 CORRELATIONS
=================

     CORRELATIONS
          /VARIABLES = VAR_LIST [ WITH VAR_LIST ]
          [
           .
           .
           .
           /VARIABLES = VAR_LIST [ WITH VAR_LIST ]
           /VARIABLES = VAR_LIST [ WITH VAR_LIST ]
          ]

          [ /PRINT={TWOTAIL, ONETAIL} {SIG, NOSIG} ]
          [ /STATISTICS=DESCRIPTIVES XPROD ALL]
          [ /MISSING={PAIRWISE, LISTWISE} {INCLUDE, EXCLUDE} ]

   The ‘CORRELATIONS’ procedure produces tables of the Pearson
correlation coefficient for a set of variables.  The significance of the
coefficients are also given.

   At least one ‘VARIABLES’ subcommand is required.  If you specify the
‘WITH’ keyword, then a non-square correlation table is produced.  The
variables preceding ‘WITH’, are used as the rows of the table, and the
variables following ‘WITH’ are used as the columns of the table.  If no
‘WITH’ subcommand is specified, then ‘CORRELATIONS’ produces a square,
symmetrical table using all variables.

   The ‘MISSING’ subcommand determines the handling of missing
variables.  If ‘INCLUDE’ is set, then user-missing values are included
in the calculations, but system-missing values are not.  If ‘EXCLUDE’ is
set, which is the default, user-missing values are excluded as well as
system-missing values.

   If ‘LISTWISE’ is set, then the entire case is excluded from analysis
whenever any variable specified in any ‘/VARIABLES’ subcommand contains
a missing value.  If ‘PAIRWISE’ is set, then a case is considered
missing only if either of the values for the particular coefficient are
missing.  The default is ‘PAIRWISE’.

   The ‘PRINT’ subcommand is used to control how the reported
significance values are printed.  If the ‘TWOTAIL’ option is used, then
a two-tailed test of significance is printed.  If the ‘ONETAIL’ option
is given, then a one-tailed test is used.  The default is ‘TWOTAIL’.

   If the ‘NOSIG’ option is specified, then correlation coefficients
with significance less than 0.05 are highlighted.  If ‘SIG’ is
specified, then no highlighting is performed.  This is the default.

   The ‘STATISTICS’ subcommand requests additional statistics to be
displayed.  The keyword ‘DESCRIPTIVES’ requests that the mean, number of
non-missing cases, and the non-biased estimator of the standard
deviation are displayed.  These statistics are displayed in a separated
table, for all the variables listed in any ‘/VARIABLES’ subcommand.  The
‘XPROD’ keyword requests cross-product deviations and covariance
estimators to be displayed for each pair of variables.  The keyword
‘ALL’ is the union of ‘DESCRIPTIVES’ and ‘XPROD’.


File: pspp.info,  Node: CROSSTABS,  Next: CTABLES,  Prev: CORRELATIONS,  Up: Statistics

15.6 CROSSTABS
==============

     CROSSTABS
             /TABLES=VAR_LIST BY VAR_LIST [BY VAR_LIST]...
             /MISSING={TABLE,INCLUDE,REPORT}
             /FORMAT={TABLES,NOTABLES}
                     {AVALUE,DVALUE}
             /CELLS={COUNT,ROW,COLUMN,TOTAL,EXPECTED,RESIDUAL,SRESIDUAL,
                     ASRESIDUAL,ALL,NONE}
             /COUNT={ASIS,CASE,CELL}
                    {ROUND,TRUNCATE}
             /STATISTICS={CHISQ,PHI,CC,LAMBDA,UC,BTAU,CTAU,RISK,GAMMA,D,
                          KAPPA,ETA,CORR,ALL,NONE}
             /BARCHART

     (Integer mode.)
             /VARIABLES=VAR_LIST (LOW,HIGH)...

   The ‘CROSSTABS’ procedure displays crosstabulation tables requested
by the user.  It can calculate several statistics for each cell in the
crosstabulation tables.  In addition, a number of statistics can be
calculated for each table itself.

   The ‘TABLES’ subcommand is used to specify the tables to be reported.
Any number of dimensions is permitted, and any number of variables per
dimension is allowed.  The ‘TABLES’ subcommand may be repeated as many
times as needed.  This is the only required subcommand in “general
mode”.

   Occasionally, one may want to invoke a special mode called “integer
mode”.  Normally, in general mode, PSPP automatically determines what
values occur in the data.  In integer mode, the user specifies the range
of values that the data assumes.  To invoke this mode, specify the
‘VARIABLES’ subcommand, giving a range of data values in parentheses for
each variable to be used on the ‘TABLES’ subcommand.  Data values inside
the range are truncated to the nearest integer, then assigned to that
value.  If values occur outside this range, they are discarded.  When it
is present, the ‘VARIABLES’ subcommand must precede the ‘TABLES’
subcommand.

   In general mode, numeric and string variables may be specified on
TABLES. In integer mode, only numeric variables are allowed.

   The ‘MISSING’ subcommand determines the handling of user-missing
values.  When set to ‘TABLE’, the default, missing values are dropped on
a table by table basis.  When set to ‘INCLUDE’, user-missing values are
included in tables and statistics.  When set to ‘REPORT’, which is
allowed only in integer mode, user-missing values are included in tables
but marked with a footnote and excluded from statistical calculations.

   The ‘FORMAT’ subcommand controls the characteristics of the
crosstabulation tables to be displayed.  It has a number of possible
settings:

     ‘TABLES’, the default, causes crosstabulation tables to be output.
     ‘NOTABLES’, which is equivalent to ‘CELLS=NONE’, suppresses them.

     ‘AVALUE’, the default, causes values to be sorted in ascending
     order.  ‘DVALUE’ asserts a descending sort order.

   The ‘CELLS’ subcommand controls the contents of each cell in the
displayed crosstabulation table.  The possible settings are:

COUNT
     Frequency count.
ROW
     Row percent.
COLUMN
     Column percent.
TOTAL
     Table percent.
EXPECTED
     Expected value.
RESIDUAL
     Residual.
SRESIDUAL
     Standardized residual.
ASRESIDUAL
     Adjusted standardized residual.
ALL
     All of the above.
NONE
     Suppress cells entirely.

   ‘/CELLS’ without any settings specified requests ‘COUNT’, ‘ROW’,
‘COLUMN’, and ‘TOTAL’.  If ‘CELLS’ is not specified at all then only
‘COUNT’ is selected.

   By default, crosstabulation and statistics use raw case weights,
without rounding.  Use the ‘/COUNT’ subcommand to perform rounding: CASE
rounds the weights of individual weights as cases are read, CELL rounds
the weights of cells within each crosstabulation table after it has been
constructed, and ASIS explicitly specifies the default non-rounding
behavior.  When rounding is requested, ROUND, the default, rounds to the
nearest integer and TRUNCATE rounds toward zero.

   The ‘STATISTICS’ subcommand selects statistics for computation:

CHISQ

     Pearson chi-square, likelihood ratio, Fisher's exact test,
     continuity correction, linear-by-linear association.
PHI
     Phi.
CC
     Contingency coefficient.
LAMBDA
     Lambda.
UC
     Uncertainty coefficient.
BTAU
     Tau-b.
CTAU
     Tau-c.
RISK
     Risk estimate.
GAMMA
     Gamma.
D
     Somers' D.
KAPPA
     Cohen's Kappa.
ETA
     Eta.
CORR
     Spearman correlation, Pearson's r.
ALL
     All of the above.
NONE
     No statistics.

   Selected statistics are only calculated when appropriate for the
statistic.  Certain statistics require tables of a particular size, and
some statistics are calculated only in integer mode.

   ‘/STATISTICS’ without any settings selects CHISQ. If the ‘STATISTICS’
subcommand is not given, no statistics are calculated.

   The ‘/BARCHART’ subcommand produces a clustered bar chart for the
first two variables on each table.  If a table has more than two
variables, the counts for the third and subsequent levels are aggregated
and the chart is produced as if there were only two variables.

   *Please note:* Currently the implementation of ‘CROSSTABS’ has the
following limitations:

   • Significance of some directional measures is not calculated.
   • Asymptotic standard error is not calculated for Goodman and
     Kruskal's tau or symmetric Somers' d.
   • Approximate T is not calculated for symmetric uncertainty
     coefficient.

   Fixes for any of these deficiencies would be welcomed.

15.6.1 Crosstabs Example
------------------------

A researcher wishes to know if, in an industry, a person's sex is
related to the person's occupation.  To investigate this, she has
determined that the ‘personnel.sav’ is a representative, randomly
selected sample of persons.  The researcher's null hypothesis is that a
person's sex has no relation to a person's occupation.  She uses a
chi-squared test of independence to investigate the hypothesis.

     get file="personnel.sav".
     
     crosstabs
     	/tables= occupation by sex
     	/cells = count expected
     	/statistics=chisq.
     
     

Example 15.3: Running crosstabs on the sex and occupation variables

   The syntax in *note Example 15.3: crosstabs:ex. conducts a
chi-squared test of independence.  The line ‘/tables = occupation by
sex’ indicates that occupation and sex are the variables to be
tabulated.  To do this using the graphic user interface you must place
these variable names respectively in the ‘Row’ and ‘Column’ fields as
shown in *note Screenshot 15.3: crosstabs:scr.

 [image src="screenshots/crosstabs-ad.png" ]

Screenshot 15.3: The Crosstabs dialog box with the sex and occupation
variables selected

   Similarly, the ‘Cells’ button shows a dialog box to select the
‘count’ and ‘expected’ options.  All other cell options can be
deselected for this test.

   You would use the ‘Format’ and ‘Statistics’ buttons to select options
for the ‘FORMAT’ and ‘STATISTICS’ subcommands.  In this example, the
‘Statistics’ requires only the ‘Chisq’ option to be checked.  All other
options should be unchecked.  No special settings are required from the
‘Format’ dialog.

   As shown in *note Results 15.1: crosstabs:res. ‘CROSSTABS’ generates
a contingency table containing the observed count and the expected count
of each sex and each occupation.  The expected count is the count which
would be observed if the null hypothesis were true.

   The significance of the Pearson Chi-Square value is very much larger
than the normally accepted value of 0.05 and so one cannot reject the
null hypothesis.  Thus the researcher must conclude that a person's sex
has no relation to the person's occupation.

 [image src="pspp-figures/crosstabs.png" text="                      Summary
+----------------+-------------------------------+
|                |             Cases             |
|                +----------+---------+----------+
|                |   Valid  | Missing |   Total  |
|                +--+-------+-+-------+--+-------+
|                | N|Percent|N|Percent| N|Percent|
+----------------+--+-------+-+-------+--+-------+
|occupation × sex|54|  96.4%|2|   3.6%|56| 100.0%|
+----------------+--+-------+-+-------+--+-------+

                     occupation × sex
+--------------------------------------+-----------+-----+
|                                      |    sex    |     |
|                                      +----+------+     |
|                                      |Male|Female|Total|
+--------------------------------------+----+------+-----+
|occupation Artist             Count   |   2|     6|    8|
|                              Expected|4.89|  3.11|  .15|
|          ----------------------------+----+------+-----+
|           Baker              Count   |   1|     1|    2|
|                              Expected|1.22|   .78|  .04|
|          ----------------------------+----+------+-----+
|           Barrister          Count   |   0|     1|    1|
|                              Expected| .61|   .39|  .02|
|          ----------------------------+----+------+-----+
|           Carpenter          Count   |   3|     1|    4|
|                              Expected|2.44|  1.56|  .07|
|          ----------------------------+----+------+-----+
|           Cleaner            Count   |   4|     0|    4|
|                              Expected|2.44|  1.56|  .07|
|          ----------------------------+----+------+-----+
|           Cook               Count   |   3|     2|    5|
|                              Expected|3.06|  1.94|  .09|
|          ----------------------------+----+------+-----+
|           Manager            Count   |   4|     4|    8|
|                              Expected|4.89|  3.11|  .15|
|          ----------------------------+----+------+-----+
|           Mathematician      Count   |   3|     1|    4|
|                              Expected|2.44|  1.56|  .07|
|          ----------------------------+----+------+-----+
|           Painter            Count   |   1|     1|    2|
|                              Expected|1.22|   .78|  .04|
|          ----------------------------+----+------+-----+
|           Payload Specialist Count   |   1|     0|    1|
|                              Expected| .61|   .39|  .02|
|          ----------------------------+----+------+-----+
|           Plumber            Count   |   5|     0|    5|
|                              Expected|3.06|  1.94|  .09|
|          ----------------------------+----+------+-----+
|           Scientist          Count   |   5|     2|    7|
|                              Expected|4.28|  2.72|  .13|
|          ----------------------------+----+------+-----+
|           Scrientist         Count   |   0|     1|    1|
|                              Expected| .61|   .39|  .02|
|          ----------------------------+----+------+-----+
|           Tailor             Count   |   1|     1|    2|
|                              Expected|1.22|   .78|  .04|
+--------------------------------------+----+------+-----+
|Total                         Count   |  33|    21|   54|
|                              Expected| .61|   .39| 1.00|
+--------------------------------------+----+------+-----+

                    Chi-Square Tests
+------------------+-----+--+--------------------------+
|                  |Value|df|Asymptotic Sig. (2-tailed)|
+------------------+-----+--+--------------------------+
|Pearson Chi-Square|15.59|13|                      .272|
|Likelihood Ratio  |19.66|13|                      .104|
|N of Valid Cases  |   54|  |                          |
+------------------+-----+--+--------------------------+" ]


Results 15.1: The results of a test of independence between sex and
occupation


File: pspp.info,  Node: CTABLES,  Next: FACTOR,  Prev: CROSSTABS,  Up: Statistics

15.7 CTABLES
============

‘CTABLES’ has the following overall syntax.  At least one ‘TABLE’
subcommand is required:

     CTABLES
       ...global subcommands...
       [/TABLE axis [BY axis [BY axis]]
        ...per-table subcommands...]...

where each axis may be empty or take one of the following forms:

     variable
     variable [{C | S}]
     axis + axis
     axis > axis
     (axis)
     axis [summary [string] [format]]

   The following subcommands precede the first ‘TABLE’ subcommand and
apply to all of the output tables.  All of these subcommands are
optional:

     /FORMAT
         [MINCOLWIDTH={DEFAULT | width}]
         [MAXCOLWIDTH={DEFAULT | width}]
         [UNITS={POINTS | INCHES | CM}]
         [EMPTY={ZERO | BLANK | string}]
         [MISSING=string]
     /VLABELS
         VARIABLES=variables
         DISPLAY={DEFAULT | NAME | LABEL | BOTH | NONE}
     /SMISSING {VARIABLE | LISTWISE}
     /PCOMPUTE &postcompute=EXPR(expression)
     /PPROPERTIES &postcompute...
         [LABEL=string]
         [FORMAT=[summary format]...]
         [HIDESOURCECATS={NO | YES}
     /WEIGHT VARIABLE=variable
     /HIDESMALLCOUNTS COUNT=count

   The following subcommands follow ‘TABLE’ and apply only to the
previous ‘TABLE’.  All of these subcommands are optional:

     /SLABELS
         [POSITION={COLUMN | ROW | LAYER}]
         [VISIBLE={YES | NO}]
     /CLABELS {AUTO | {ROWLABELS|COLLABELS}={OPPOSITE|LAYER}}
     /CATEGORIES VARIABLES=variables
         {[value, value...]
        | [ORDER={A | D}]
          [KEY={VALUE | LABEL | summary(variable)}]
          [MISSING={EXCLUDE | INCLUDE}]}
         [TOTAL={NO | YES} [LABEL=string] [POSITION={AFTER | BEFORE}]]
         [EMPTY={INCLUDE | EXCLUDE}]
     /TITLES
         [TITLE=string...]
         [CAPTION=string...]
         [CORNER=string...]

   The ‘CTABLES’ (aka "custom tables") command produces
multi-dimensional tables from categorical and scale data.  It offers
many options for data summarization and formatting.

   This section's examples use data from the 2008 (USA) National Survey
of Drinking and Driving Attitudes and Behaviors, a public domain data
set from the (USA) National Highway Traffic Administration and available
at <https://data.transportation.gov>.  PSPP includes this data set, with
a modified dictionary, as ‘examples/nhtsa.sav’.

* Menu:

* CTABLES Basics::
* CTABLES Data Summarization::
* CTABLES Statistics Positions and Labels::
* CTABLES Category Label Positions::
* CTABLES Per-Variable Category Options::
* CTABLES Titles::
* CTABLES Table Formatting::
* CTABLES Display of Variable Labels::
* CTABLES Missing Value Treatment::
* CTABLES Computed Categories::
* CTABLES Effective Weight::
* CTABLES Hiding Small Counts::


File: pspp.info,  Node: CTABLES Basics,  Next: CTABLES Data Summarization,  Up: CTABLES

15.7.1 Basics
-------------

The only required subcommand is ‘TABLE’, which specifies the variables
to include along each axis:
     /TABLE rows [BY columns [BY layers]]
In ‘TABLE’, each of ROWS, COLUMNS, and LAYERS is either empty or an axis
expression that specifies one or more variables.  At least one must
specify an axis expression.

* Menu:

* CTABLES Categorical Variable Basics::
* CTABLES Scalar Variable Basics::
* CTABLES Overriding Measurement Level::


File: pspp.info,  Node: CTABLES Categorical Variable Basics,  Next: CTABLES Scalar Variable Basics,  Up: CTABLES Basics

15.7.1.1 Categorical Variables
..............................

An axis expression that names a categorical variable divides the data
into cells according to the values of that variable.  When all the
variables named on ‘TABLE’ are categorical, by default each cell
displays the number of cases that it contains, so specifying a single
variable yields a frequency table, much like the output of the
‘FREQUENCIES’ command (*note FREQUENCIES::):

     CTABLES /TABLE=ageGroup.

 [image src="pspp-figures/ctables1.png" text="         Custom Tables
+-----------------------+-----+
|                       |Count|
+-----------------------+-----+
|Age group 15 or younger|    0|
|          16 to 25     | 1099|
|          26 to 35     |  967|
|          36 to 45     | 1037|
|          46 to 55     | 1175|
|          56 to 65     | 1247|
|          66 or older  | 1474|
+-----------------------+-----+" ]


Specifying a row and a column categorical variable yields a
crosstabulation, much like the output of the ‘CROSSTABS’ command (*note
CROSSTABS::):

     CTABLES /TABLE=ageGroup BY gender.

 [image src="pspp-figures/ctables2.png" text="             Custom Tables
+-----------------------+------------+
|                       |S3a. GENDER:|
|                       +-----+------+
|                       | Male|Female|
|                       +-----+------+
|                       |Count| Count|
+-----------------------+-----+------+
|Age group 15 or younger|    0|     0|
|          16 to 25     |  594|   505|
|          26 to 35     |  476|   491|
|          36 to 45     |  489|   548|
|          46 to 55     |  526|   649|
|          56 to 65     |  516|   731|
|          66 or older  |  531|   943|
+-----------------------+-----+------+" ]


The ‘>’ "nesting" operator nests multiple variables on a single axis,
e.g.:

     CTABLES /TABLE likelihoodOfBeingStoppedByPolice BY ageGroup > gender.

 [image src="pspp-figures/ctables3.png" text="                                 Custom Tables
+---------------------------------+-------------------------------------------+
|                                 |  86. In the past year, have you hosted a  |
|                                 |  social event or party where alcohol was  |
|                                 |             served to adults?             |
|                                 +---------------------+---------------------+
|                                 |         Yes         |          No         |
|                                 +---------------------+---------------------+
|                                 |        Count        |        Count        |
+---------------------------------+---------------------+---------------------+
|Age    15 or      S3a.     Male  |                    0|                    0|
|group  younger    GENDER:  Female|                    0|                    0|
|      ---------------------------+---------------------+---------------------+
|       16 to 25   S3a.     Male  |                  208|                  386|
|                  GENDER:  Female|                  202|                  303|
|      ---------------------------+---------------------+---------------------+
|       26 to 35   S3a.     Male  |                  225|                  251|
|                  GENDER:  Female|                  242|                  249|
|      ---------------------------+---------------------+---------------------+
|       36 to 45   S3a.     Male  |                  223|                  266|
|                  GENDER:  Female|                  240|                  307|
|      ---------------------------+---------------------+---------------------+
|       46 to 55   S3a.     Male  |                  201|                  325|
|                  GENDER:  Female|                  282|                  366|
|      ---------------------------+---------------------+---------------------+
|       56 to 65   S3a.     Male  |                  196|                  320|
|                  GENDER:  Female|                  279|                  452|
|      ---------------------------+---------------------+---------------------+
|       66 or      S3a.     Male  |                  162|                  367|
|       older      GENDER:  Female|                  243|                  700|
+---------------------------------+---------------------+---------------------+" ]


The ‘+’ "stacking" operator allows a single output table to include
multiple data analyses.  With ‘+’, ‘CTABLES’ divides the output table
into multiple “sections”, each of which includes an analysis of the full
data set.  For example, the following command separately tabulates age
group and driving frequency by gender:

     CTABLES /TABLE ageGroup + freqOfDriving BY gender.

 [image src="pspp-figures/ctables4.png" text="                                 Custom Tables
+----------------------------------------------------------------+------------+
|                                                                |S3a. GENDER:|
|                                                                +-----+------+
|                                                                | Male|Female|
|                                                                +-----+------+
|                                                                |Count| Count|
+----------------------------------------------------------------+-----+------+
|Age group                                    15 or younger      |    0|     0|
|                                             16 to 25           |  594|   505|
|                                             26 to 35           |  476|   491|
|                                             36 to 45           |  489|   548|
|                                             46 to 55           |  526|   649|
|                                             56 to 65           |  516|   731|
|                                             66 or older        |  531|   943|
+----------------------------------------------------------------+-----+------+
| 1. How often do you usually drive a car or  Every day          | 2305|  2362|
|other motor vehicle?                         Several days a week|  440|   834|
|                                             Once a week or less|  125|   236|
|                                             Only certain times |   58|    72|
|                                             a year             |     |      |
|                                             Never              |  192|   348|
+----------------------------------------------------------------+-----+------+" ]


When ‘+’ and ‘>’ are used together, ‘>’ binds more tightly.  Use
parentheses to override operator precedence.  Thus:

     CTABLES /TABLE hasConsideredReduction + hasBeenCriticized > gender.
     CTABLES /TABLE (hasConsideredReduction + hasBeenCriticized) > gender.

 [image src="pspp-figures/ctables5.png" text="                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
|26. During the last 12 months, has there been a    Yes                 |  513|
|time when you felt you should cut down on your    ---------------------+-----+
|drinking?                                          No                  | 3710|
+-----------------------------------------------------------------------+-----+
|27. During the last 12 months, has there been a    Yes S3a.      Male  |  135|
|time when people criticized your drinking?             GENDER:   Female|   49|
|                                                  ---------------------+-----+
|                                                   No  S3a.      Male  | 1916|
|                                                       GENDER:   Female| 2126|
+-----------------------------------------------------------------------+-----+

                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
|26. During the last 12 months, has there been a    Yes S3a.      Male  |  333|
|time when you felt you should cut down on your         GENDER:   Female|  180|
|drinking?                                         ---------------------+-----+
|                                                   No  S3a.      Male  | 1719|
|                                                       GENDER:   Female| 1991|
+-----------------------------------------------------------------------+-----+
|27. During the last 12 months, has there been a    Yes S3a.      Male  |  135|
|time when people criticized your drinking?             GENDER:   Female|   49|
|                                                  ---------------------+-----+
|                                                   No  S3a.      Male  | 1916|
|                                                       GENDER:   Female| 2126|
+-----------------------------------------------------------------------+-----+" ]



File: pspp.info,  Node: CTABLES Scalar Variable Basics,  Next: CTABLES Overriding Measurement Level,  Prev: CTABLES Categorical Variable Basics,  Up: CTABLES Basics

15.7.1.2 Scalar Variables
.........................

For a categorical variable, ‘CTABLES’ divides the table into a cell per
category.  For a scalar variable, ‘CTABLES’ instead calculates a summary
measure, by default the mean, of the values that fall into a cell.  For
example, if the only variable specified is a scalar variable, then the
output is a single cell that holds the mean of all of the data:

     CTABLES /TABLE age.

 [image src="pspp-figures/ctables6.png" text="          Custom Tables
+--------------------------+----+
|                          |Mean|
+--------------------------+----+
|D1. AGE: What is your age?|  48|
+--------------------------+----+" ]


   A scalar variable may nest with categorical variables.  The following
example shows the mean age of survey respondents across gender and
language groups:

     CTABLES /TABLE gender > age BY region.

 [image src="pspp-figures/ctables7.png" text="                                 Custom Tables
+-------------------------------------+---------------------------------------+
|                                     |Was this interview conducted in English|
|                                     |              or Spanish?              |
|                                     +-------------------+-------------------+
|                                     |      English      |      Spanish      |
|                                     +-------------------+-------------------+
|                                     |        Mean       |        Mean       |
+-------------------------------------+-------------------+-------------------+
|D1. AGE: What is   S3a.        Male  |                 46|                 37|
|your age?          GENDER:     Female|                 51|                 39|
+-------------------------------------+-------------------+-------------------+" ]


   The order of nesting of scalar and categorical variables affects
table labeling, but it does not affect the data displayed in the table.
The following example shows how the output changes when the nesting
order of the scalar and categorical variable are interchanged:

     CTABLES /TABLE age > gender BY region.

 [image src="pspp-figures/ctables8.png" text="                                 Custom Tables
+-------------------------------------+---------------------------------------+
|                                     |Was this interview conducted in English|
|                                     |              or Spanish?              |
|                                     +-------------------+-------------------+
|                                     |      English      |      Spanish      |
|                                     +-------------------+-------------------+
|                                     |        Mean       |        Mean       |
+-------------------------------------+-------------------+-------------------+
|S3a.       Male   D1. AGE: What is   |                 46|                 37|
|GENDER:           your age?          |                   |                   |
|          ---------------------------+-------------------+-------------------+
|           Female D1. AGE: What is   |                 51|                 39|
|                  your age?          |                   |                   |
+-------------------------------------+-------------------+-------------------+" ]


   Only a single scalar variable may appear in each section; that is, a
scalar variable may not nest inside a scalar variable directly or
indirectly.  Scalar variables may only appear on one axis within
‘TABLE’.


File: pspp.info,  Node: CTABLES Overriding Measurement Level,  Prev: CTABLES Scalar Variable Basics,  Up: CTABLES Basics

15.7.1.3 Overriding Measurement Level
.....................................

By default, ‘CTABLES’ uses a variable's measurement level to decide
whether to treat it as categorical or scalar.  Variables assigned the
nominal or ordinal measurement level are treated as categorical, and
scalar variables are treated as scalar.

   When PSPP reads data from a file in an external format, such as a
text file, variables' measurement levels are often unknown.  If
‘CTABLES’ runs when a variable has an unknown measurement level, it
makes an initial pass through the data to guess measurement levels using
the rules described in an earlier section (*note Measurement Level::).
Use the ‘VARIABLE LEVEL’ command to set or change a variable's
measurement level (*note VARIABLE LEVEL::).

   To treat a variable as categorical or scalar only for one use on
‘CTABLES’, add ‘[C]’ or ‘[S]’, respectively, after the variable name.
The following example shows the output when variable
‘monthDaysMin1drink’ is analyzed as scalar (the default for its
measurement level) and as categorical:

     CTABLES
         /TABLE monthDaysMin1drink BY gender
         /TABLE monthDaysMin1drink [C] BY gender.

 [image src="pspp-figures/ctables9.png" text="                                 Custom Tables
+----------------------------------------------------------------+------------+
|                                                                |S3a. GENDER:|
|                                                                +----+-------+
|                                                                |Male| Female|
|                                                                +----+-------+
|                                                                |Mean|  Mean |
+----------------------------------------------------------------+----+-------+
|20. On how many of the thirty days in this typical month did you|   7|      5|
|have one or more alcoholic beverages to drink?                  |    |       |
+----------------------------------------------------------------+----+-------+

                                 Custom Tables
+----------------------------------------------------------------+------------+
|                                                                |S3a. GENDER:|
|                                                                +-----+------+
|                                                                | Male|Female|
|                                                                +-----+------+
|                                                                |Count| Count|
+----------------------------------------------------------------+-----+------+
|20. On how many of the thirty days in this typical month None   |  152|   258|
|did you have one or more alcoholic beverages to drink?   1      |  403|   653|
|                                                         2      |  284|   324|
|                                                         3      |  169|   215|
|                                                         4      |  178|   143|
|                                                         5      |  107|   106|
|                                                         6      |   67|    59|
|                                                         7      |   31|    11|
|                                                         8      |  101|    74|
|                                                         9      |    6|     4|
|                                                         10     |   95|    75|
|                                                         11     |    4|     0|
|                                                         12     |   58|    33|
|                                                         13     |    3|     2|
|                                                         14     |   13|     3|
|                                                         15     |   79|    58|
|                                                         16     |   10|     6|
|                                                         17     |    4|     2|
|                                                         18     |    5|     4|
|                                                         19     |    2|     0|
|                                                         20     |  105|    47|
|                                                         21     |    2|     0|
|                                                         22     |    3|     3|
|                                                         23     |    0|     3|
|                                                         24     |    3|     0|
|                                                         25     |   35|    25|
|                                                         26     |    1|     1|
|                                                         27     |    3|     3|
|                                                         28     |   13|     8|
|                                                         29     |    3|     3|
|                                                         Every  |  104|    43|
|                                                         day    |     |      |
+----------------------------------------------------------------+-----+------+" ]



File: pspp.info,  Node: CTABLES Data Summarization,  Next: CTABLES Statistics Positions and Labels,  Prev: CTABLES Basics,  Up: CTABLES

15.7.2 Data Summarization
-------------------------

The ‘CTABLES’ command allows the user to control how the data are
summarized with “summary specifications”, syntax that lists one or more
summary function names, optionally separated by commas, and which are
enclosed in square brackets following a variable name on the ‘TABLE’
subcommand.  When all the variables are categorical, summary
specifications can be given for the innermost nested variables on any
one axis.  When a scalar variable is present, only the scalar variable
may have summary specifications.

   The following example includes a summary specification for column and
row percentages for categorical variables, and mean and median for a
scalar variable:

     CTABLES
         /TABLE=age [MEAN, MEDIAN] BY gender
         /TABLE=ageGroup [COLPCT, ROWPCT] BY gender.

 [image src="pspp-figures/ctables10.png" text="                    Custom Tables
+--------------------------+-----------------------+
|                          |      S3a. GENDER:     |
|                          +-----------+-----------+
|                          |    Male   |   Female  |
|                          +----+------+----+------+
|                          |Mean|Median|Mean|Median|
+--------------------------+----+------+----+------+
|D1. AGE: What is your age?|  46|    45|  50|    52|
+--------------------------+----+------+----+------+

                     Custom Tables
+-----------------------+-----------------------------+
|                       |         S3a. GENDER:        |
|                       +--------------+--------------+
|                       |     Male     |    Female    |
|                       +--------+-----+--------+-----+
|                       |Column %|Row %|Column %|Row %|
+-----------------------+--------+-----+--------+-----+
|Age group 15 or younger|     .0%|    .|     .0%|    .|
|          16 to 25     |   19.0%|54.0%|   13.1%|46.0%|
|          26 to 35     |   15.2%|49.2%|   12.7%|50.8%|
|          36 to 45     |   15.6%|47.2%|   14.2%|52.8%|
|          46 to 55     |   16.8%|44.8%|   16.8%|55.2%|
|          56 to 65     |   16.5%|41.4%|   18.9%|58.6%|
|          66 or older  |   17.0%|36.0%|   24.4%|64.0%|
+-----------------------+--------+-----+--------+-----+" ]


   A summary specification may override the default label and format by
appending a string or format specification or both (in that order) to
the summary function name.  For example:

     CTABLES /TABLE=ageGroup [COLPCT 'Gender %' PCT5.0,
                              ROWPCT 'Age Group %' PCT5.0]
                    BY gender.

 [image src="pspp-figures/ctables11.png" text="                           Custom Tables
+-----------------------+-----------------------------------------+
|                       |               S3a. GENDER:              |
|                       +--------------------+--------------------+
|                       |        Male        |       Female       |
|                       +--------+-----------+--------+-----------+
|                       |Gender %|Age Group %|Gender %|Age Group %|
+-----------------------+--------+-----------+--------+-----------+
|Age group 15 or younger|      0%|          .|      0%|          .|
|          16 to 25     |     19%|        54%|     13%|        46%|
|          26 to 35     |     15%|        49%|     13%|        51%|
|          36 to 45     |     16%|        47%|     14%|        53%|
|          46 to 55     |     17%|        45%|     17%|        55%|
|          56 to 65     |     16%|        41%|     19%|        59%|
|          66 or older  |     17%|        36%|     24%|        64%|
+-----------------------+--------+-----------+--------+-----------+" ]


   In addition to the standard formats, ‘CTABLES’ allows the user to
specify the following special formats:

‘NEGPARENw.d’   Encloses negative numbers in            42.96      (42.96)
                parentheses.                                      
‘NEQUALw.d’     Adds a ‘N=’ prefix.                     N=42.96    N=-42.96
                                                                  
‘PARENw.d’      Encloses all numbers in parentheses.    (42.96)    (-42.96)
                                                                  
‘PCTPARENw.d’   Encloses all numbers in parentheses     (42.96%)  (-42.96%)
                with a ‘%’ suffix.

   Parentheses provide a shorthand to apply summary specifications to
multiple variables.  For example, both of these commands:

     CTABLES /TABLE=ageGroup[COLPCT] + membersOver16[COLPCT] BY gender.
     CTABLES /TABLE=(ageGroup + membersOver16)[COLPCT] BY gender.

produce the same output shown below:

 [image src="pspp-figures/ctables12.png" text="                                 Custom Tables
+-------------------------------------------------------------+---------------+
|                                                             |  S3a. GENDER: |
|                                                             +-------+-------+
|                                                             |  Male | Female|
|                                                             +-------+-------+
|                                                             | Column| Column|
|                                                             |   %   |   %   |
+-------------------------------------------------------------+-------+-------+
|Age group                                         15 or      |    .0%|    .0%|
|                                                  younger    |       |       |
|                                                  16 to 25   |  19.0%|  13.1%|
|                                                  26 to 35   |  15.2%|  12.7%|
|                                                  36 to 45   |  15.6%|  14.2%|
|                                                  46 to 55   |  16.8%|  16.8%|
|                                                  56 to 65   |  16.5%|  18.9%|
|                                                  66 or older|  17.0%|  24.4%|
+-------------------------------------------------------------+-------+-------+
|S1. Including yourself, how many members of this  None       |    .0%|    .0%|
|household are age 16 or older?                    1          |  21.4%|  35.0%|
|                                                  2          |  61.9%|  52.3%|
|                                                  3          |  11.0%|   8.2%|
|                                                  4          |   4.2%|   3.2%|
|                                                  5          |   1.1%|    .9%|
|                                                  6 or more  |    .4%|    .4%|
+-------------------------------------------------------------+-------+-------+" ]


   The following sections list the available summary functions.  After
each function's name is given its default label and format.  If no
format is listed, then the default format is the print format for the
variable being summarized.

* Menu:

* CTABLES Summary Functions for Individual Cells::
* CTABLES Summary Functions for Groups of Cells::
* CTABLES Summary Functions for Adjusted Weights::
* CTABLES Unweighted Summary Functions::


File: pspp.info,  Node: CTABLES Summary Functions for Individual Cells,  Next: CTABLES Summary Functions for Groups of Cells,  Up: CTABLES Data Summarization

15.7.2.1 Summary Functions for Individual Cells
...............................................

This section lists the summary functions that consider only an
individual cell in ‘CTABLES’.  Only one such summary function, ‘COUNT’,
may be applied to both categorical and scale variables:

‘COUNT’ ("Count", F40.0)
     The sum of weights in a cell.

     If ‘CATEGORIES’ for one or more of the variables in a table include
     missing values (*note CTABLES Per-Variable Category Options::),
     then some or all of the categories for a cell might be missing
     values.  ‘COUNT’ counts data included in a cell regardless of
     whether its categories are missing.

   The following summary functions apply only to scale variables or
totals and subtotals for categorical variables.  Be cautious about
interpreting the summary value in the latter case, because it is not
necessarily meaningful; however, the mean of a Likert scale, etc. may
have a straightforward interpreation.

‘MAXIMUM’ ("Maximum")
     The largest value.

‘MEAN’ ("Mean")
     The mean.

‘MEDIAN’ ("Median")
     The median value.

‘MINIMUM’ ("Minimum")
     The smallest value.

‘MISSING’ ("Missing")
     Sum of weights of user- and system-missing values.

‘MODE’ ("Mode")
     The highest-frequency value.  Ties are broken by taking the
     smallest mode.

‘PTILE’ n ("Percentile n")
     The Nth percentile, where 0 ≤ N ≤ 100.

‘RANGE’ ("Range")
     The maximum minus the minimum.

‘SEMEAN’ ("Std Error of Mean")
     The standard error of the mean.

‘STDDEV’ ("Std Deviation")
     The standard deviation.

‘SUM’ ("Sum")
     The sum.

‘TOTALN’ ("Total N", F40.0)
     The sum of weights in a cell.

     For scale data, ‘COUNT’ and ‘TOTALN’ are the same.

     For categorical data, ‘TOTALN’ counts missing values in excluded
     categories, that is, user-missing values not in an explicit
     category list on ‘CATEGORIES’ (*note CTABLES Per-Variable Category
     Options::), or user-missing values excluded because
     ‘MISSING=EXCLUDE’ is in effect on ‘CATEGORIES’, or system-missing
     values.  ‘COUNT’ does not count these.

     *Note CTABLES Missing Values for Summary Variables::, for details
     of how ‘CTABLES’ summarizes missing values.

‘VALIDN’ ("Valid N", F40.0)
     The sum of valid count weights in included categories.

     For categorical variables, ‘VALIDN’ does not count missing values
     regardless of whether they are in included categories via
     ‘CATEGORIES’.  ‘VALIDN’ does not count valid values that are in
     excluded categories.  *Note CTABLES Missing Values for Summary
     Variables::, for details.

‘VARIANCE’ ("Variance")
     The variance.


File: pspp.info,  Node: CTABLES Summary Functions for Groups of Cells,  Next: CTABLES Summary Functions for Adjusted Weights,  Prev: CTABLES Summary Functions for Individual Cells,  Up: CTABLES Data Summarization

15.7.2.2 Summary Functions for Groups of Cells
..............................................

These summary functions summarize over multiple cells within an area of
the output chosen by the user and specified as part of the function
name.  The following basic AREAs are supported, in decreasing order of
size:

‘TABLE’
     A “section”.  Stacked variables divide sections of the output from
     each other.  sections may span multiple layers.

‘LAYER’
     A section within a single layer.

‘SUBTABLE’
     A “subtable”, whose contents are the cells that pair an innermost
     row variable and an innermost column variable within a single
     layer.

   The following shows how the output for the table expression
‘hasBeenPassengerOfDesignatedDriver > hasBeenPassengerOfDrunkDriver BY
isLicensedDriver > hasHostedEventWithAlcohol + hasBeenDesignatedDriver
BY gender’(1) is divided up into ‘TABLE’, ‘LAYER’, and ‘SUBTABLE’ areas.
Each unique value for Table ID is one section, and similarly for Layer
ID and Subtable ID. Thus, this output has two ‘TABLE’ areas (one for
‘isLicensedDriver’ and one for ‘hasBeenDesignatedDriver’), four ‘LAYER’
areas (for those two variables, per layer), and 12 ‘SUBTABLE’ areas.

 [image src="pspp-figures/ctables22.png" text="                        Custom Tables
Male
+---------------------------------+-----------------+------+
|                                 |     licensed    |desDrv|
|                                 +--------+--------+---+--+
|                                 |   Yes  |   No   |   |  |
|                                 +--------+--------+   |  |
|                                 | hostAlc| hostAlc|   |  |
|                                 +----+---+----+---+   |  |
|                                 | Yes| No| Yes| No|Yes|No|
+---------------------------------+----+---+----+---+---+--+
|desPas Yes druPas Yes Table ID   |   1|  1|   1|  1|  2| 2|
|                      Layer ID   |   1|  1|   1|  1|  2| 2|
|                      Subtable ID|   1|  1|   2|  2|  3| 3|
|                 ----------------+----+---+----+---+---+--+
|                  No  Table ID   |   1|  1|   1|  1|  2| 2|
|                      Layer ID   |   1|  1|   1|  1|  2| 2|
|                      Subtable ID|   1|  1|   2|  2|  3| 3|
|      ---------------------------+----+---+----+---+---+--+
|       No  druPas Yes Table ID   |   1|  1|   1|  1|  2| 2|
|                      Layer ID   |   1|  1|   1|  1|  2| 2|
|                      Subtable ID|   4|  4|   5|  5|  6| 6|
|                 ----------------+----+---+----+---+---+--+
|                  No  Table ID   |   1|  1|   1|  1|  2| 2|
|                      Layer ID   |   1|  1|   1|  1|  2| 2|
|                      Subtable ID|   4|  4|   5|  5|  6| 6|
+---------------------------------+----+---+----+---+---+--+" ]


   ‘CTABLES’ also supports the following AREAs that further divide a
subtable or a layer within a section:

‘LAYERROW’
‘LAYERCOL’
     A row or column, respectively, in one layer of a section.

‘ROW’
‘COL’
     A row or column, respectively, in a subtable.

   The following summary functions for groups of cells are available for
each AREA described above, for both categorical and scale variables:

‘areaPCT’ or ‘areaPCT.COUNT’ ("Area %", PCT40.1)
     A percentage of total counts within AREA.

‘areaPCT.VALIDN’ ("Area Valid N %", PCT40.1)
     A percentage of total counts for valid values within AREA.

‘areaPCT.TOTALN’ ("Area Total N %", PCT40.1)
     A percentage of total counts for all values within AREA.

   Scale variables and totals and subtotals for categorical variables
may use the following additional group cell summary function:

‘areaPCT.SUM’ ("Area Sum %", PCT40.1)
     Percentage of the sum of the values within AREA.

   ---------- Footnotes ----------

   (1) This is not necessarily a meaningful table.  To make it easier to
read, short variable labels are used.


File: pspp.info,  Node: CTABLES Summary Functions for Adjusted Weights,  Next: CTABLES Unweighted Summary Functions,  Prev: CTABLES Summary Functions for Groups of Cells,  Up: CTABLES Data Summarization

15.7.2.3 Summary Functions for Adjusted Weights
...............................................

If the ‘WEIGHT’ subcommand specified an effective weight variable (*note
CTABLES Effective Weight::), then the following summary functions use
its value instead of the dictionary weight variable.  Otherwise, they
are equivalent to the summary function without the ‘E’-prefix:

   • ‘ECOUNT’ ("Adjusted Count", F40.0)

   • ‘ETOTALN’ ("Adjusted Total N", F40.0)

   • ‘EVALIDN’ ("Adjusted Valid N", F40.0)


File: pspp.info,  Node: CTABLES Unweighted Summary Functions,  Prev: CTABLES Summary Functions for Adjusted Weights,  Up: CTABLES Data Summarization

15.7.2.4 Unweighted Summary Functions
.....................................

The following summary functions with a ‘U’-prefix are equivalent to the
same ones without the prefix, except that they use unweighted counts:

   • ‘UCOUNT’ ("Unweighted Count", F40.0)

   • ‘UareaPCT’ or ‘UareaPCT.COUNT’ ("Unweighted Area %", PCT40.1)

   • ‘UareaPCT.VALIDN’ ("Unweighted Area Valid N %", PCT40.1)

   • ‘UareaPCT.TOTALN’ ("Unweighted Area Total N %", PCT40.1)

   • ‘UMEAN’ ("Unweighted Mean")

   • ‘UMEDIAN’ ("Unweighted Median")

   • ‘UMISSING’ ("Unweighted Missing")

   • ‘UMODE’ ("Unweighted Mode")

   • ‘UareaPCT.SUM’ ("Unweighted Area Sum %", PCT40.1)

   • ‘UPTILE’ n ("Unweighted Percentile n")

   • ‘USEMEAN’ ("Unweighted Std Error of Mean")

   • ‘USTDDEV’ ("Unweighted Std Deviation")

   • ‘USUM’ ("Unweighted Sum")

   • ‘UTOTALN’ ("Unweighted Total N", F40.0)

   • ‘UVALIDN’ ("Unweighted Valid N", F40.0)

   • ‘UVARIANCE’ ("Unweighted Variance", F40.0)


File: pspp.info,  Node: CTABLES Statistics Positions and Labels,  Next: CTABLES Category Label Positions,  Prev: CTABLES Data Summarization,  Up: CTABLES

15.7.3 Statistics Positions and Labels
--------------------------------------

     /SLABELS
         [POSITION={COLUMN | ROW | LAYER}]
         [VISIBLE={YES | NO}]

   The ‘SLABELS’ subcommand controls the position and visibility of
summary statistics for the ‘TABLE’ subcommand that it follows.

   ‘POSITION’ sets the axis on which summary statistics appear.  With
POSITION=COLUMN, which is the default, each summary statistic appears in
a column.  For example:

     CTABLES /TABLE=age [MEAN, MEDIAN] BY gender.

 [image src="pspp-figures/ctables13.png" text="                    Custom Tables
+--------------------------+-----------------------+
|                          |      S3a. GENDER:     |
|                          +-----------+-----------+
|                          |    Male   |   Female  |
|                          +----+------+----+------+
|                          |Mean|Median|Mean|Median|
+--------------------------+----+------+----+------+
|D1. AGE: What is your age?|  46|    45|  50|    52|
+--------------------------+----+------+----+------+" ]


With POSITION=ROW, each summary statistic appears in a row, as shown
below:

     CTABLES /TABLE=age [MEAN, MEDIAN] BY gender /SLABELS POSITION=ROW.

 [image src="pspp-figures/ctables14.png" text="                  Custom Tables
+---------------------------------+-------------+
|                                 | S3a. GENDER:|
|                                 +-----+-------+
|                                 | Male| Female|
+---------------------------------+-----+-------+
|D1. AGE: What is your age? Mean  |   46|     50|
|                           Median|   45|     52|
+---------------------------------+-----+-------+" ]


POSITION=LAYER is also available to place each summary statistic in a
separate layer.

   Labels for summary statistics are shown by default.  Use VISIBLE=NO
to suppress them.  Because unlabeled data can cause confusion, it should
only be considered if the meaning of the data is evident, as in a simple
case like this:

     CTABLES /TABLE=ageGroup [TABLEPCT] /SLABELS VISIBLE=NO.

 [image src="pspp-figures/ctables15.png" text="         Custom Tables
+-----------------------+-----+
|Age group 15 or younger|  .0%|
|          16 to 25     |15.7%|
|          26 to 35     |13.8%|
|          36 to 45     |14.8%|
|          46 to 55     |16.8%|
|          56 to 65     |17.8%|
|          66 or older  |21.1%|
+-----------------------+-----+" ]



File: pspp.info,  Node: CTABLES Category Label Positions,  Next: CTABLES Per-Variable Category Options,  Prev: CTABLES Statistics Positions and Labels,  Up: CTABLES

15.7.4 Category Label Positions
-------------------------------

     /CLABELS {AUTO | {ROWLABELS|COLLABELS}={OPPOSITE|LAYER}}

   The ‘CLABELS’ subcommand controls the position of category labels for
the ‘TABLE’ subcommand that it follows.  By default, or if AUTO is
specified, category labels for a given variable nest inside the
variable's label on the same axis.  For example, the command below
results in age categories nesting within the age group variable on the
rows axis and gender categories within the gender variable on the
columns axis:

     CTABLES /TABLE ageGroup BY gender.

 [image src="pspp-figures/ctables16.png" text="             Custom Tables
+-----------------------+------------+
|                       |S3a. GENDER:|
|                       +-----+------+
|                       | Male|Female|
|                       +-----+------+
|                       |Count| Count|
+-----------------------+-----+------+
|Age group 15 or younger|    0|     0|
|          16 to 25     |  594|   505|
|          26 to 35     |  476|   491|
|          36 to 45     |  489|   548|
|          46 to 55     |  526|   649|
|          56 to 65     |  516|   731|
|          66 or older  |  531|   943|
+-----------------------+-----+------+" ]


   ROWLABELS=OPPOSITE or COLLABELS=OPPOSITE move row or column variable
category labels, respectively, to the opposite axis.  The setting
affects only the innermost variable or variables, which must be
categorical, on the given axis.  For example:

     CTABLES /TABLE ageGroup BY gender /CLABELS ROWLABELS=OPPOSITE.
     CTABLES /TABLE ageGroup BY gender /CLABELS COLLABELS=OPPOSITE.

 [image src="pspp-figures/ctables17.png" text="                                Custom Tables
+-----+----------------------------------------------------------------------
|     |                                      S3a. GENDER:
|     +-------------------------------------------+--------------------------
|     |                    Male                   |                   Female
|     +-------+-----+-----+-----+-----+-----+-----+-------+-----+-----+-----+
|     | 15 or |16 to|26 to|36 to|46 to|56 to|66 or| 15 or |16 to|26 to|36 to|
|     |younger|  25 |  35 |  45 |  55 |  65 |older|younger|  25 |  35 |  45 |
|     +-------+-----+-----+-----+-----+-----+-----+-------+-----+-----+-----+
|     | Count |Count|Count|Count|Count|Count|Count| Count |Count|Count|Count|
+-----+-------+-----+-----+-----+-----+-----+-----+-------+-----+-----+-----+
|Age  |      0|  594|  476|  489|  526|  516|  531|      0|  505|  491|  548|
|group|       |     |     |     |     |     |     |       |     |     |     |
+-----+-------+-----+-----+-----+-----+-----+-----+-------+-----+-----+-----+

+-----+-----------------+
|     |                 |
|     +-----------------+
|     |                 |
|     +-----+-----+-----+
|     |46 to|56 to|66 or|
|     |  55 |  65 |older|
|     +-----+-----+-----+
|     |Count|Count|Count|
+-----+-----+-----+-----+
|Age  |  649|  731|  943|
|group|     |     |     |
+-----+-----+-----+-----+

                Custom Tables
+------------------------------+------------+
|                              |S3a. GENDER:|
|                              +------------+
|                              |    Count   |
+------------------------------+------------+
|Age group 15 or younger Male  |           0|
|                        Female|           0|
|         ---------------------+------------+
|          16 to 25      Male  |         594|
|                        Female|         505|
|         ---------------------+------------+
|          26 to 35      Male  |         476|
|                        Female|         491|
|         ---------------------+------------+
|          36 to 45      Male  |         489|
|                        Female|         548|
|         ---------------------+------------+
|          46 to 55      Male  |         526|
|                        Female|         649|
|         ---------------------+------------+
|          56 to 65      Male  |         516|
|                        Female|         731|
|         ---------------------+------------+
|          66 or older   Male  |         531|
|                        Female|         943|
+------------------------------+------------+" ]


   ROWLABELS=LAYER or COLLABELS=LAYER move the innermost row or column
variable category labels, respectively, to the layer axis.

   Only one axis's labels may be moved, whether to the opposite axis or
to the layer axis.

Effect on Summary Statistics
............................

‘CLABELS’ primarily affects the appearance of tables, not the data
displayed in them.  However, ‘CTABLES’ can affect the values displayed
for statistics that summarize areas of a table, since it can change the
definitions of these areas.

   For example, consider the following syntax and output:

     CTABLES /TABLE ageGroup BY gender [ROWPCT, COLPCT].

 [image src="pspp-figures/ctables23.png" text="                     Custom Tables
+-----------------------+-----------------------------+
|                       |         S3a. GENDER:        |
|                       +--------------+--------------+
|                       |     Male     |    Female    |
|                       +-----+--------+-----+--------+
|                       |Row %|Column %|Row %|Column %|
+-----------------------+-----+--------+-----+--------+
|Age group 15 or younger|    .|     .0%|    .|     .0%|
|          16 to 25     |54.0%|   19.0%|46.0%|   13.1%|
|          26 to 35     |49.2%|   15.2%|50.8%|   12.7%|
|          36 to 45     |47.2%|   15.6%|52.8%|   14.2%|
|          46 to 55     |44.8%|   16.8%|55.2%|   16.8%|
|          56 to 65     |41.4%|   16.5%|58.6%|   18.9%|
|          66 or older  |36.0%|   17.0%|64.0%|   24.4%|
+-----------------------+-----+--------+-----+--------+" ]


Using ‘COLLABELS=OPPOSITE’ changes the definitions of rows and columns,
so that column percentages display what were previously row percentages
and the new row percentages become meaningless (because there is only
one cell per row):

     CTABLES
         /TABLE ageGroup BY gender [ROWPCT, COLPCT]
         /CLABELS COLLABELS=OPPOSITE.

 [image src="pspp-figures/ctables24.png" text="                  Custom Tables
+------------------------------+---------------+
|                              |  S3a. GENDER: |
|                              +------+--------+
|                              | Row %|Column %|
+------------------------------+------+--------+
|Age group 15 or younger Male  |     .|       .|
|                        Female|     .|       .|
|         ---------------------+------+--------+
|          16 to 25      Male  |100.0%|   54.0%|
|                        Female|100.0%|   46.0%|
|         ---------------------+------+--------+
|          26 to 35      Male  |100.0%|   49.2%|
|                        Female|100.0%|   50.8%|
|         ---------------------+------+--------+
|          36 to 45      Male  |100.0%|   47.2%|
|                        Female|100.0%|   52.8%|
|         ---------------------+------+--------+
|          46 to 55      Male  |100.0%|   44.8%|
|                        Female|100.0%|   55.2%|
|         ---------------------+------+--------+
|          56 to 65      Male  |100.0%|   41.4%|
|                        Female|100.0%|   58.6%|
|         ---------------------+------+--------+
|          66 or older   Male  |100.0%|   36.0%|
|                        Female|100.0%|   64.0%|
+------------------------------+------+--------+" ]


Moving Categories for Stacked Variables
.......................................

If ‘CLABELS’ moves category labels from an axis with stacked variables,
the variables that are moved must have the same category specifications
(*note CTABLES Per-Variable Category Options::) and the same value
labels.

   The following shows both moving stacked category variables and
adapting to the changing definitions of rows and columns:

     CTABLES /TABLE (likelihoodOfBeingStoppedByPolice
                     + likelihoodOfHavingAnAccident) [COLPCT].
     CTABLES /TABLE (likelihoodOfBeingStoppedByPolice
                     + likelihoodOfHavingAnAccident) [ROWPCT]
       /CLABELS ROW=OPPOSITE.

 [image src="pspp-figures/ctables25.png" text="                                 Custom Tables
+---------------------------------------------------------------------+-------+
|                                                                     | Column|
|                                                                     |   %   |
+---------------------------------------------------------------------+-------+
|105b. How likely is it that drivers who have had too     Almost      |  10.2%|
|much to drink to drive safely will A. Get stopped by the certain     |       |
|police?                                                  Very likely |  21.8%|
|                                                         Somewhat    |  40.2%|
|                                                         likely      |       |
|                                                         Somewhat    |  19.0%|
|                                                         unlikely    |       |
|                                                         Very        |   8.9%|
|                                                         unlikely    |       |
+---------------------------------------------------------------------+-------+
|105b. How likely is it that drivers who have had too     Almost      |  15.9%|
|much to drink to drive safely will B. Have an accident?  certain     |       |
|                                                         Very likely |  40.8%|
|                                                         Somewhat    |  35.0%|
|                                                         likely      |       |
|                                                         Somewhat    |   6.2%|
|                                                         unlikely    |       |
|                                                         Very        |   2.0%|
|                                                         unlikely    |       |
+---------------------------------------------------------------------+-------+

                                 Custom Tables
+-----------------------------+--------+-------+---------+----------+---------+
|                             | Almost |  Very | Somewhat| Somewhat |   Very  |
|                             | certain| likely|  likely | unlikely | unlikely|
|                             +--------+-------+---------+----------+---------+
|                             |  Row % | Row % |  Row %  |   Row %  |  Row %  |
+-----------------------------+--------+-------+---------+----------+---------+
|105b. How likely is it that  |   10.2%|  21.8%|    40.2%|     19.0%|     8.9%|
|drivers who have had too much|        |       |         |          |         |
|to drink to drive safely will|        |       |         |          |         |
|A. Get stopped by the police?|        |       |         |          |         |
|105b. How likely is it that  |   15.9%|  40.8%|    35.0%|      6.2%|     2.0%|
|drivers who have had too much|        |       |         |          |         |
|to drink to drive safely will|        |       |         |          |         |
|B. Have an accident?         |        |       |         |          |         |
+-----------------------------+--------+-------+---------+----------+---------+" ]



File: pspp.info,  Node: CTABLES Per-Variable Category Options,  Next: CTABLES Titles,  Prev: CTABLES Category Label Positions,  Up: CTABLES

15.7.5 Per-Variable Category Options
------------------------------------

     /CATEGORIES VARIABLES=variables
         {[value, value...]
        | [ORDER={A | D}]
          [KEY={VALUE | LABEL | summary(variable)}]
          [MISSING={EXCLUDE | INCLUDE}]}
         [TOTAL={NO | YES} [LABEL=string] [POSITION={AFTER | BEFORE}]]
         [EMPTY={INCLUDE | EXCLUDE}]

   The ‘CATEGORIES’ subcommand specifies, for one or more categorical
variables, the categories to include and exclude, the sort order for
included categories, and treatment of missing values.  It also controls
the totals and subtotals to display.  It may be specified any number of
times, each time for a different set of variables.  ‘CATEGORIES’ applies
to the table produced by the ‘TABLE’ subcommand that it follows.

   ‘CATEGORIES’ does not apply to scalar variables.

   VARIABLES is required and must list the variables for the subcommand
to affect.

   The syntax may specify the categories to include and their sort order
either explicitly or implicitly.  The following sections give the
details of each form of syntax, followed by information on totals and
subtotals and the ‘EMPTY’ setting.

* Menu:

* CTABLES Explicit Categories::
* CTABLES Implicit Categories::
* CTABLES Totals and Subtotals::
* CTABLES Categories Without Values::


File: pspp.info,  Node: CTABLES Explicit Categories,  Next: CTABLES Implicit Categories,  Up: CTABLES Per-Variable Category Options

15.7.5.1 Explicit Categories
............................

To use ‘CTABLES’ to explicitly specify categories to include, list the
categories within square brackets in the desired sort order.  Use spaces
or commas to separate values.  Categories not covered by the list are
excluded from analysis.

   Each element of the list takes one of the following forms:

number
'string'
     A numeric or string category value, for variables that have the
     corresponding type.

'date'
'time'
     A date or time category value, for variables that have a date or
     time print format.

min THRU max
LO THRU max
min THRU HI
     A range of category values, where MIN and MAX each takes one of the
     forms above, in increasing order.

MISSING
     All user-missing values.  (To match individual user-missing values,
     specify their category values.)

OTHERNM
     Any non-missing value not covered by any other element of the list
     (regardless of where OTHERNM is placed in the list).

&postcompute
     A computed category name (*note CTABLES Computed Categories::).

SUBTOTAL
HSUBTOTAL
     A subtotal (*note CTABLES Totals and Subtotals::).

   If multiple elements of the list cover a given category, the last one
in the list takes precedence.

   The following example syntax and output show how an explicit category
can limit the displayed categories:

     CTABLES /TABLE freqOfDriving.
     CTABLES /TABLE freqOfDriving /CATEGORIES VARIABLES=freqOfDriving [1, 2, 3].

 [image src="pspp-figures/ctables27.png" text="                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
| 1. How often do you usually drive a car or other  Every day           | 4667|
|motor vehicle?                                     Several days a week | 1274|
|                                                   Once a week or less |  361|
|                                                   Only certain times a|  130|
|                                                   year                |     |
|                                                   Never               |  540|
+-----------------------------------------------------------------------+-----+

                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
| 1. How often do you usually drive a car or other     Every day        | 4667|
|motor vehicle?                                        Several days a   | 1274|
|                                                      week             |     |
|                                                      Once a week or   |  361|
|                                                      less             |     |
+-----------------------------------------------------------------------+-----+" ]



File: pspp.info,  Node: CTABLES Implicit Categories,  Next: CTABLES Totals and Subtotals,  Prev: CTABLES Explicit Categories,  Up: CTABLES Per-Variable Category Options

15.7.5.2 Implicit Categories
............................

In the absence of an explicit list of categories, ‘CATEGORIES’ allows
‘KEY’, ‘ORDER’, and ‘MISSING’ to specify how to select and sort
categories.

   The ‘KEY’ setting specifies the sort key.  By default, or with
‘KEY=VALUE’, categories are sorted by default.  Categories may also be
sorted by value label, with ‘KEY=LABEL’, or by the value of a summary
function, e.g. ‘KEY=COUNT’.

   By default, or with ‘ORDER=A’, categories are sorted in ascending
order.  Specify ‘ORDER=D’ to sort in descending order.

   User-missing values are excluded by default, or with
‘MISSING=EXCLUDE’.  Specify ‘MISSING=INCLUDE’ to include user-missing
values.  The system-missing value is always excluded.

   The following example syntax and output show how ‘MISSING=INCLUDE’
causes missing values to be included in a category list.

     CTABLES /TABLE freqOfDriving.
     CTABLES /TABLE freqOfDriving
             /CATEGORIES VARIABLES=freqOfDriving MISSING=INCLUDE.

 [image src="pspp-figures/ctables28.png" text="                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
| 1. How often do you usually drive a car or other  Every day           | 4667|
|motor vehicle?                                     Several days a week | 1274|
|                                                   Once a week or less |  361|
|                                                   Only certain times a|  130|
|                                                   year                |     |
|                                                   Never               |  540|
+-----------------------------------------------------------------------+-----+

                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
| 1. How often do you usually drive a car or other  Every day           | 4667|
|motor vehicle?                                     Several days a week | 1274|
|                                                   Once a week or less |  361|
|                                                   Only certain times a|  130|
|                                                   year                |     |
|                                                   Never               |  540|
|                                                   Don't know          |    8|
|                                                   Refused             |   19|
+-----------------------------------------------------------------------+-----+" ]



File: pspp.info,  Node: CTABLES Totals and Subtotals,  Next: CTABLES Categories Without Values,  Prev: CTABLES Implicit Categories,  Up: CTABLES Per-Variable Category Options

15.7.5.3 Totals and Subtotals
.............................

‘CATEGORIES’ also controls display of totals and subtotals.  By default,
or with ‘TOTAL=NO’, totals are not displayed.  Use ‘TOTAL=YES’ to
display a total.  By default, the total is labeled "Total"; use
‘LABEL="label"’ to override it.

   Subtotals are also not displayed by default.  To add one or more
subtotals, use an explicit category list and insert ‘SUBTOTAL’ or
‘HSUBTOTAL’ in the position or positions where the subtotal should
appear.  The subtotal becomes an extra row or column or layer.
‘HSUBTOTAL’ additionally hides the categories that make up the subtotal.
Either way, the default label is "Subtotal", use ‘SUBTOTAL="label"’ or
‘HSUBTOTAL="label"’ to specify a custom label.

   The following example syntax and output show how to use ‘TOTAL=YES’
and ‘SUBTOTAL’:

     CTABLES
         /TABLE freqOfDriving
         /CATEGORIES VARIABLES=freqOfDriving [OTHERNM, SUBTOTAL='Valid Total',
                                              MISSING, SUBTOTAL='Missing Total']
                                             TOTAL=YES LABEL='Overall Total'.

 [image src="pspp-figures/ctables29.png" text="                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
| 1. How often do you usually drive a car or other  Every day           | 4667|
|motor vehicle?                                     Several days a week | 1274|
|                                                   Once a week or less |  361|
|                                                   Only certain times a|  130|
|                                                   year                |     |
|                                                   Never               |  540|
|                                                   Valid Total         | 6972|
|                                                   Don't know          |    8|
|                                                   Refused             |   19|
|                                                   Missing Total       |   27|
|                                                   Overall Total       | 6999|
+-----------------------------------------------------------------------+-----+" ]


   By default, or with ‘POSITION=AFTER’, totals are displayed in the
output after the last category and subtotals apply to categories that
precede them.  With ‘POSITION=BEFORE’, totals come before the first
category and subtotals apply to categories that follow them.

   Only categorical variables may have totals and subtotals.  Scalar
variables may be "totaled" indirectly by enabling totals and subtotals
on a categorical variable within which the scalar variable is
summarized.  For example, the following syntax produces a mean, count,
and valid count across all data by adding a total on the categorical
‘region’ variable, as shown:

     CTABLES /TABLE=region > monthDaysMin1drink [MEAN, VALIDN]
         /CATEGORIES VARIABLES=region TOTAL=YES LABEL='All regions'.

 [image src="pspp-figures/ctables30.png" text="                                 Custom Tables
+-----------------------------------------------------------+----+-----+------+
|                                                           |    |     | Valid|
|                                                           |Mean|Count|   N  |
+-----------------------------------------------------------+----+-----+------+
|20. On how many of the thirty days in this  Region NE      | 5.6| 1409|   945|
|typical month did you have one or more             MW      | 5.0| 1654|  1026|
|alcoholic beverages to drink?                      S       | 6.0| 2390|  1285|
|                                                   W       | 6.5| 1546|   953|
|                                                   All     | 5.8| 6999|  4209|
|                                                   regions |    |     |      |
+-----------------------------------------------------------+----+-----+------+" ]


   By default, PSPP uses the same summary functions for totals and
subtotals as other categories.  To summarize totals and subtotals
differently, specify the summary functions for totals and subtotals
after the ordinary summary functions inside a nested set of ‘[]’
following ‘TOTALS’.  For example, the following syntax displays ‘COUNT’
for individual categories and totals and ‘VALIDN’ for totals, as shown:

     CTABLES
         /TABLE isLicensedDriver [COUNT, TOTALS[COUNT, VALIDN]]
         /CATEGORIES VARIABLES=isLicensedDriver TOTAL=YES MISSING=INCLUDE.

 [image src="pspp-figures/ctables26.png" text="                                 Custom Tables
+----------------------------------------------------------------+-----+------+
|                                                                |     | Valid|
|                                                                |Count|   N  |
+----------------------------------------------------------------+-----+------+
|D7a. Are you a licensed driver; that is, do you have a Yes      | 6379|      |
|valid driver's license?                                No       |  572|      |
|                                                       Don't    |    4|      |
|                                                       know     |     |      |
|                                                       Refused  |   44|      |
|                                                       Total    | 6999|  6951|
+----------------------------------------------------------------+-----+------+" ]



File: pspp.info,  Node: CTABLES Categories Without Values,  Prev: CTABLES Totals and Subtotals,  Up: CTABLES Per-Variable Category Options

15.7.5.4 Categories Without Values
..................................

Some categories might not be included in the data set being analyzed.
For example, our example data set has no cases in the "15 or younger"
age group.  By default, or with ‘EMPTY=INCLUDE’, PSPP includes these
empty categories in output tables.  To exclude them, specify
‘EMPTY=EXCLUDE’.

   For implicit categories, empty categories potentially include all the
values with value labels for a given variable; for explicit categories,
they include all the values listed individually and all values with
value labels that are covered by ranges or ‘MISSING’ or ‘OTHERNM’.

   The following example syntax and output show the effect of
‘EMPTY=EXCLUDE’ for the ‘membersOver16’ variable, in which 0 is labeled
"None" but no cases exist with that value:

     CTABLES /TABLE=membersOver16.
     CTABLES /TABLE=membersOver16 /CATEGORIES VARIABLES=membersOver16 EMPTY=EXCLUDE.

 [image src="pspp-figures/ctables31.png" text="                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
|S1. Including yourself, how many members of this household are None    |    0|
|age 16 or older?                                               1       | 1586|
|                                                               2       | 3031|
|                                                               3       |  505|
|                                                               4       |  194|
|                                                               5       |   55|
|                                                               6 or    |   21|
|                                                               more    |     |
+-----------------------------------------------------------------------+-----+

                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
|S1. Including yourself, how many members of this household are 1       | 1586|
|age 16 or older?                                               2       | 3031|
|                                                               3       |  505|
|                                                               4       |  194|
|                                                               5       |   55|
|                                                               6 or    |   21|
|                                                               more    |     |
+-----------------------------------------------------------------------+-----+" ]



File: pspp.info,  Node: CTABLES Titles,  Next: CTABLES Table Formatting,  Prev: CTABLES Per-Variable Category Options,  Up: CTABLES

15.7.6 Titles
-------------

     /TITLES
         [TITLE=string...]
         [CAPTION=string...]
         [CORNER=string...]

   The ‘TITLES’ subcommand sets the title, caption, and corner text for
the table output for the previous ‘TABLE’ subcommand.  Any number of
strings may be specified for each kind of text, with each string
appearing on a separate line in the output.  The title appears above the
table, the caption below the table, and the corner text appears in the
table's upper left corner.  By default, the title is "Custom Tables" and
the caption and corner text are empty.  With some table output styles,
the corner text is not displayed.

   The strings provided in this subcommand may contain the following
macro-like keywords that PSPP substitutes at the time that it runs the
command:

‘)DATE’
     The current date, e.g. MM/DD/YY. The format is locale-dependent.

‘)TIME’
     The current time, e.g. HH:MM:SS. The format is locale-dependent.

‘)TABLE’
     The expression specified on the ‘TABLE’ command.  Summary and
     measurement level specifications are omitted, and variable labels
     are used in place of variable names.


File: pspp.info,  Node: CTABLES Table Formatting,  Next: CTABLES Display of Variable Labels,  Prev: CTABLES Titles,  Up: CTABLES

15.7.7 Table Formatting
-----------------------

     /FORMAT
         [MINCOLWIDTH={DEFAULT | width}]
         [MAXCOLWIDTH={DEFAULT | width}]
         [UNITS={POINTS | INCHES | CM}]
         [EMPTY={ZERO | BLANK | string}]
         [MISSING=string]

   The ‘FORMAT’ subcommand, which must precede the first ‘TABLE’
subcommand, controls formatting for all the output tables.  ‘FORMAT’ and
all of its settings are optional.

   Use ‘MINCOLWIDTH’ and ‘MAXCOLWIDTH’ to control the minimum or maximum
width of columns in output tables.  By default, with ‘DEFAULT’, column
width varies based on content.  Otherwise, specify a number for either
or both of these settings.  If both are specified, ‘MAXCOLWIDTH’ must be
greater than or equal to ‘MINCOLWIDTH’.  The default unit, or with
‘UNITS=POINTS’, is points (1/72 inch), or specify ‘UNITS=INCHES’ to use
inches or ‘UNITS=CM’ for centimeters.  PSPP does not currently honor any
of these settings.

   By default, or with ‘EMPTY=ZERO’, zero values are displayed in their
usual format.  Use ‘EMPTY=BLANK’ to use an empty cell instead, or
‘EMPTY="string"’ to use the specified string.

   By default, missing values are displayed as ‘.’, the same as in other
tables.  Specify ‘MISSING="string"’ to instead use a custom string.


File: pspp.info,  Node: CTABLES Display of Variable Labels,  Next: CTABLES Missing Value Treatment,  Prev: CTABLES Table Formatting,  Up: CTABLES

15.7.8 Display of Variable Labels
---------------------------------

     /VLABELS
         VARIABLES=variables
         DISPLAY={DEFAULT | NAME | LABEL | BOTH | NONE}

   The ‘VLABELS’ subcommand, which must precede the first ‘TABLE’
subcommand, controls display of variable labels in all the output
tables.  ‘VLABELS’ is optional.  It may appear multiple times to adjust
settings for different variables.

   ‘VARIABLES’ and ‘DISPLAY’ are required.  The value of ‘DISPLAY’
controls how variable labels are displayed for the variables listed on
‘VARIABLES’.  The supported values are:

‘DEFAULT’
     Use the setting from ‘SET TVARS’ (*note SET TVARS::).

‘NAME’
     Show only a variable name.

‘LABEL’
     Show only a variable label.

‘BOTH’
     Show variable name and label.

‘NONE’
     Show nothing.


File: pspp.info,  Node: CTABLES Missing Value Treatment,  Next: CTABLES Computed Categories,  Prev: CTABLES Display of Variable Labels,  Up: CTABLES

15.7.9 Missing Value Treatment
------------------------------

The ‘TABLE’ subcommand on ‘CTABLES’ specifies two different kinds of
variables: variables that divide tables into cells (which are always
categorical) and variables being summarized (which may be categorical or
scale).  PSPP treats missing values differently in each kind of
variable, as described in the sections below.

* Menu:

* CTABLES Missing Values for Cell-Defining Variables::
* CTABLES Missing Values for Summary Variables::
* CTABLES Scale Missing Values::


File: pspp.info,  Node: CTABLES Missing Values for Cell-Defining Variables,  Next: CTABLES Missing Values for Summary Variables,  Up: CTABLES Missing Value Treatment

15.7.9.1 Missing Values for Cell-Defining Variables
...................................................

For variables that divide tables into cells, per-variable category
options, as described in *note CTABLES Per-Variable Category Options::,
determine which data is analyzed.  If any of the categories for such a
variable would exclude a case, then that case is not included.

   As an example, consider the following entirely artificial dataset, in
which ‘x’ and ‘y’ are categorical variables with missing value 9, and
‘z’ is scale:

 [image src="pspp-figures/ctables32.png" text="   Data List
+-+-+---------+
|x|y|    z    |
+-+-+---------+
|1|1|        1|
|1|2|       10|
|1|9|      100|
|2|1|     1000|
|2|2|    10000|
|2|9|   100000|
|9|1|  1000000|
|9|2| 10000000|
|9|9|100000000|
+-+-+---------+" ]


   Using ‘x’ and ‘y’ to define cells, and summarizing ‘z’, by default
PSPP omits all the cases that have ‘x’ or ‘y’ (or both) missing:

     CTABLES /TABLE x > y > z [SUM].

 [image src="pspp-figures/ctables33.png" text="  Custom Tables
+---------+-----+
|         | Sum |
+---------+-----+
|x 1 y 1 z|    1|
|     ----+-----+
|      2 z|   10|
| --------+-----+
|  2 y 1 z| 1000|
|     ----+-----+
|      2 z|10000|
+---------+-----+" ]


   If, however, we add ‘CATEGORIES’ specifications to include missing
values for ‘y’ or for ‘x’ and ‘y’, the output table includes them, like
so:

     CTABLES /TABLE x > y > z [SUM] /CATEGORIES VARIABLES=y MISSING=INCLUDE.
     CTABLES /TABLE x > y > z [SUM] /CATEGORIES VARIABLES=x y MISSING=INCLUDE.

 [image src="pspp-figures/ctables34.png" text="   Custom Tables
+---------+------+
|         |  Sum |
+---------+------+
|x 1 y 1 z|     1|
|     ----+------+
|      2 z|    10|
|     ----+------+
|      9 z|   100|
| --------+------+
|  2 y 1 z|  1000|
|     ----+------+
|      2 z| 10000|
|     ----+------+
|      9 z|100000|
+---------+------+

    Custom Tables
+---------+---------+
|         |   Sum   |
+---------+---------+
|x 1 y 1 z|        1|
|     ----+---------+
|      2 z|       10|
|     ----+---------+
|      9 z|      100|
| --------+---------+
|  2 y 1 z|     1000|
|     ----+---------+
|      2 z|    10000|
|     ----+---------+
|      9 z|   100000|
| --------+---------+
|  9 y 1 z|  1000000|
|     ----+---------+
|      2 z| 10000000|
|     ----+---------+
|      9 z|100000000|
+---------+---------+" ]



File: pspp.info,  Node: CTABLES Missing Values for Summary Variables,  Next: CTABLES Scale Missing Values,  Prev: CTABLES Missing Values for Cell-Defining Variables,  Up: CTABLES Missing Value Treatment

15.7.9.2 Missing Values for Summary Variables
.............................................

For summary variables, values that are valid and in included categories
are analyzed, and values that are missing or in excluded categories are
not analyzed, with the following exceptions:

   • The "VALIDN" summary functions (‘VALIDN’, ‘EVALIDN’, ‘UVALIDN’,
     ‘areaPCT.VALIDN’, and ‘UareaPCT.VALIDN’) only count valid values in
     included categories (not missing values in included categories).

   • The "TOTALN" summary functions (‘TOTALN’, ‘ETOTALN’, ‘UTOTALN’,
     ‘areaPCT.TOTALN’), and ‘UareaPCT.TOTALN’ count all values (valid
     and missing) in included categories and missing (but not valid)
     values in excluded categories.

For categorical variables, system-missing values are never in included
categories.  For scale variables, there is no notion of included and
excluded categories, so all values are effectively included.

   The following table provides another view of the above rules:

                                         VALIDN   other   TOTALN
-------------------------------------------------------------------
Categorical variables:
 Valid values in included categories     yes      yes     yes
 Missing values in included categories   --       yes     yes
 Missing values in excluded categories   --       --      yes
 Valid values in excluded categories     --       --      --
Scale variables:
 Valid values                            yes      yes     yes
 User- or system-missing values          --       yes     yes


File: pspp.info,  Node: CTABLES Scale Missing Values,  Prev: CTABLES Missing Values for Summary Variables,  Up: CTABLES Missing Value Treatment

15.7.9.3 Scale Missing Values
.............................

     /SMISSING {VARIABLE | LISTWISE}

   The ‘SMISSING’ subcommand, which must precede the first ‘TABLE’
subcommand, controls treatment of missing values for scalar variables in
producing all the output tables.  ‘SMISSING’ is optional.

   With ‘SMISSING=VARIABLE’, which is the default, missing values are
excluded on a variable-by-variable basis.  With ‘SMISSING=LISTWISE’,
when stacked scalar variables are nested together with a categorical
variable, a missing value for any of the scalar variables causes the
case to be excluded for all of them.

   As an example, consider the following dataset, in which ‘x’ is a
categorical variable and ‘y’ and ‘z’ are scale:

 [image src="pspp-figures/ctables18.png" text="   Data List
+-+-----+-----+
|x|  y  |  z  |
+-+-----+-----+
|1|    .|40.00|
|1|10.00|50.00|
|1|20.00|60.00|
|1|30.00|    .|
+-+-----+-----+" ]


With the default missing-value treatment, ‘x’'s mean is 20, based on the
values 10, 20, and 30, and ‘y’'s mean is 50, based on 40, 50, and 60:

     CTABLES /TABLE (y + z) > x.

 [image src="pspp-figures/ctables19.png" text="Custom Tables
+-----+-----+
|     | Mean|
+-----+-----+
|y x 1|20.00|
+-----+-----+
|z x 1|50.00|
+-----+-----+" ]


By adding ‘SMISSING=LISTWISE’, only cases where ‘y’ and ‘z’ are both
non-missing are considered, so ‘x’'s mean becomes 15, as the average of
10 and 20, and ‘y’'s mean becomes 55, the average of 50 and 60:

     CTABLES /SMISSING LISTWISE /TABLE (y + z) > x.

 [image src="pspp-figures/ctables20.png" text="Custom Tables
+-----+-----+
|     | Mean|
+-----+-----+
|y x 1|15.00|
+-----+-----+
|z x 1|55.00|
+-----+-----+" ]


Even with ‘SMISSING=LISTWISE’, if ‘y’ and ‘z’ are separately nested with
‘x’, instead of using a single ‘>’ operator, missing values revert to
being considered on a variable-by-variable basis:

     CTABLES /SMISSING LISTWISE /TABLE (y > x) + (z > x).

 [image src="pspp-figures/ctables21.png" text="Custom Tables
+-----+-----+
|     | Mean|
+-----+-----+
|y x 1|20.00|
+-----+-----+
|z x 1|50.00|
+-----+-----+" ]



File: pspp.info,  Node: CTABLES Computed Categories,  Next: CTABLES Effective Weight,  Prev: CTABLES Missing Value Treatment,  Up: CTABLES

15.7.10 Computed Categories
---------------------------

     /PCOMPUTE &postcompute=EXPR(expression)
     /PPROPERTIES &postcompute...
         [LABEL=string]
         [FORMAT=[summary format]...]
         [HIDESOURCECATS={NO | YES}

   “Computed categories”, also called “postcomputes”, are categories
created using arithmetic on categories obtained from the data.  The
‘PCOMPUTE’ subcommand creates a postcompute, which may then be used on
‘CATEGORIES’ within an explicit category list (*note CTABLES Explicit
Category List::).  Optionally, ‘PPROPERTIES’ refines how a postcompute
is displayed.  The following sections provide the details.

* Menu:

* CTABLES PCOMPUTE::
* CTABLES PPROPERTIES::


File: pspp.info,  Node: CTABLES PCOMPUTE,  Next: CTABLES PPROPERTIES,  Up: CTABLES Computed Categories

15.7.10.1 PCOMPUTE
..................

     /PCOMPUTE &postcompute=EXPR(expression)

   The ‘PCOMPUTE’ subcommand, which must precede the first ‘TABLE’
command, defines computed categories.  It is optional and may be used
any number of times to define multiple postcomputes.

   Each ‘PCOMPUTE’ defines one postcompute.  Its syntax consists of a
name to identify the postcompute as a PSPP identifier prefixed by ‘&’,
followed by ‘=’ and a postcompute expression enclosed in ‘EXPR(...)’.  A
postcompute expression consists of:

[category]
     This form evaluates to the summary statistic for category, e.g.
     ‘[1]’ evaluates to the value of the summary statistic associated
     with category 1.  The category may be a number, a quoted string, or
     a quoted time or date value.  All of the categories for a given
     postcompute must have the same form.  The category must appear in
     all the ‘CATEGORIES’ list in which the postcompute is used.

[min THRU max]
[LO THRU max]
[min THRU HI]
MISSING
OTHERNM
     These forms evaluate to the summary statistics for a category
     specified with the same syntax, as described in previous section
     (*note CTABLES Explicit Category List::).  The category must appear
     in all the ‘CATEGORIES’ list in which the postcompute is used.

SUBTOTAL
     The summary statistic for the subtotal category.  This form is
     allowed only if the ‘CATEGORIES’ lists that include this
     postcompute have exactly one subtotal.

SUBTOTAL[index]
     The summary statistic for subtotal category index, where 1 is the
     first subtotal, 2 is the second, and so on.  This form may be used
     for ‘CATEGORIES’ lists with any number of subtotals.

TOTAL
     The summary statistic for the total.  The ‘CATEGORIES’ lsits that
     include this postcompute must have a total enabled.

a + b
a - b
a * b
a / b
a ** b
     These forms perform arithmetic on the values of postcompute
     expressions a and b.  The usual operator precedence rules apply.

number
     Numeric constants may be used in postcompute expressions.

(a)
     Parentheses override operator precedence.

   A postcompute is not associated with any particular variable.
Instead, it may be referenced within ‘CATEGORIES’ for any suitable
variable (e.g. only a string variable is suitable for a postcompute
expression that refers to a string category, only a variable with
subtotals for an expression that refers to subtotals, ...).

   Normally a named postcompute is defined only once, but if a later
‘PCOMPUTE’ redefines a postcompute with the same name as an earlier one,
the later one take precedence.

   The following syntax and output shows how ‘PCOMPUTE’ can compute a
total over subtotals, summing the "Frequent Drivers" and "Infrequent
Drivers" subtotals to form an "All Drivers" postcompute.  It also shows
how to calculate and display a percentage, in this case the percentage
of valid responses that report never driving.  It uses ‘PPROPERTIES’
(*note CTABLES PPROPERTIES::) to display the latter in ‘PCT’ format.

     CTABLES
         /PCOMPUTE &all_drivers=EXPR([1 THRU 2] + [3 THRU 4])
         /PPROPERTIES &all_drivers LABEL='All Drivers'
         /PCOMPUTE &pct_never=EXPR([5] / ([1 THRU 2] + [3 THRU 4] + [5]) * 100)
         /PPROPERTIES &pct_never LABEL='% Not Drivers' FORMAT=COUNT PCT40.1
         /TABLE=freqOfDriving BY gender
         /CATEGORIES VARIABLES=freqOfDriving
                                  [1 THRU 2, SUBTOTAL='Frequent Drivers',
                                   3 THRU 4, SUBTOTAL='Infrequent Drivers',
                                   &all_drivers, 5, &pct_never,
                                   MISSING, SUBTOTAL='Not Drivers or Missing'].

 [image src="pspp-figures/ctables35.png" text="                                 Custom Tables
+----------------------------------------------------------------+------------+
|                                                                |S3a. GENDER:|
|                                                                +-----+------+
|                                                                | Male|Female|
|                                                                +-----+------+
|                                                                |Count| Count|
+----------------------------------------------------------------+-----+------+
| 1. How often do you usually drive a car or Every day           | 2305|  2362|
|other motor vehicle?                        Several days a week |  440|   834|
|                                            Frequent Drivers    | 2745|  3196|
|                                            Once a week or less |  125|   236|
|                                            Only certain times a|   58|    72|
|                                            year                |     |      |
|                                            Infrequent Drivers  |  183|   308|
|                                            All Drivers         | 2928|  3504|
|                                            Never               |  192|   348|
|                                            % Not Drivers       | 6.2%|  9.0%|
|                                            Don't know          |    3|     5|
|                                            Refused             |    9|    10|
|                                            Not Drivers or      |  204|   363|
|                                            Missing             |     |      |
+----------------------------------------------------------------+-----+------+" ]



File: pspp.info,  Node: CTABLES PPROPERTIES,  Prev: CTABLES PCOMPUTE,  Up: CTABLES Computed Categories

15.7.10.2 PPROPERTIES
.....................

     /PPROPERTIES &postcompute...
         [LABEL=string]
         [FORMAT=[summary format]...]
         [HIDESOURCECATS={NO | YES}

   The ‘PPROPERTIES’ subcommand, which must appear before ‘TABLE’, sets
properties for one or more postcomputes defined on prior ‘PCOMPUTE’
subcommands.  The subcommand syntax begins with the list of
postcomputes, each prefixed with ‘&’ as specified on ‘PCOMPUTE’.

   All of the settings on ‘PPROPERTIES’ are optional.  Use ‘LABEL’ to
set the label shown for the postcomputes in table output.  The default
label for a postcompute is the expression used to define it.

   A postcompute always uses same summary functions as the variable
whose categories contain it, but ‘FORMAT’ allows control over the format
used to display their values.  It takes a list of summary function names
and format specifiers.

   By default, or with ‘HIDESOURCECATS=NO’, categories referred to by
computed categories are displayed like other categories.  Use
‘HIDESOURCECATS=YES’ to hide them.

   The previous section provides an example for ‘PPROPERTIES’.


File: pspp.info,  Node: CTABLES Effective Weight,  Next: CTABLES Hiding Small Counts,  Prev: CTABLES Computed Categories,  Up: CTABLES

15.7.11 Effective Weight
------------------------

     /WEIGHT VARIABLE=variable

   The ‘WEIGHT’ subcommand is optional and must appear before ‘TABLE’.
If it appears, it must name a numeric variable, known as the “effective
weight” or “adjustment weight”.  The effective weight variable stands in
for the dictionary's weight variable (*note WEIGHT::), if any, in most
calculations in ‘CTABLES’.  The only exceptions are the ‘COUNT’,
‘TOTALN’, and ‘VALIDN’ summary functions, which use the dictionary
weight instead.

   Weights obtained from the PSPP dictionary are rounded to the nearest
integer at the case level.  Effective weights are not rounded.
Regardless of the weighting source, PSPP does not analyze cases with
zero, missing, or negative effective weights.


File: pspp.info,  Node: CTABLES Hiding Small Counts,  Prev: CTABLES Effective Weight,  Up: CTABLES

15.7.12 Hiding Small Counts
---------------------------

     /HIDESMALLCOUNTS COUNT=count

   The ‘HIDESMALLCOUNTS’ subcommand is optional.  If it specified, then
‘COUNT’, ‘ECOUNT’, and ‘UCOUNT’ values in output tables less than the
value of count are shown as ‘<count’ instead of their true values.  The
value of count must be an integer and must be at least 2.

   The following syntax and example shows how to use ‘HIDESMALLCOUNTS’:

     CTABLES /HIDESMALLCOUNTS COUNT=10 /TABLE placeOfLastDrinkBeforeDrive.

 [image src="pspp-figures/ctables36.png" text="                                 Custom Tables
+-----------------------------------------------------------------------+-----+
|                                                                       |Count|
+-----------------------------------------------------------------------+-----+
|37. Please think about the most recent occasion that   Other (list)    |<10  |
|you drove within two hours of drinking alcoholic       Your home       |  182|
|beverages. Where did you drink on that occasion?       Friend's home   |  264|
|                                                       Bar/Tavern/Club |  279|
|                                                       Restaurant      |  495|
|                                                       Work            |   21|
|                                                       Bowling alley   |<10  |
|                                                       Hotel/Motel     |<10  |
|                                                       Country Club/   |   17|
|                                                       Golf course     |     |
|                                                       Drank in the    |<10  |
|                                                       car/On the road |     |
|                                                       Sporting event  |   15|
|                                                       Movie theater   |<10  |
|                                                       Shopping/Store/ |<10  |
|                                                       Grocery store   |     |
|                                                       Wedding         |   15|
|                                                       Party at someone|   81|
|                                                       else's home     |     |
|                                                       Park/picnic     |   14|
|                                                       Party at your   |<10  |
|                                                       house           |     |
+-----------------------------------------------------------------------+-----+" ]



File: pspp.info,  Node: FACTOR,  Next: GLM,  Prev: CTABLES,  Up: Statistics

15.8 FACTOR
===========

     FACTOR  {
              VARIABLES=VAR_LIST,
              MATRIX IN ({CORR,COV}={*,FILE_SPEC})
             }

             [ /METHOD = {CORRELATION, COVARIANCE} ]

             [ /ANALYSIS=VAR_LIST ]

             [ /EXTRACTION={PC, PAF}]

             [ /ROTATION={VARIMAX, EQUAMAX, QUARTIMAX, PROMAX[(K)], NOROTATE}]

             [ /PRINT=[INITIAL] [EXTRACTION] [ROTATION] [UNIVARIATE] [CORRELATION] [COVARIANCE] [DET] [KMO] [AIC] [SIG] [ALL] [DEFAULT] ]

             [ /PLOT=[EIGEN] ]

             [ /FORMAT=[SORT] [BLANK(N)] [DEFAULT] ]

             [ /CRITERIA=[FACTORS(N)] [MINEIGEN(L)] [ITERATE(M)] [ECONVERGE (DELTA)] [DEFAULT] ]

             [ /MISSING=[{LISTWISE, PAIRWISE}] [{INCLUDE, EXCLUDE}] ]

   The ‘FACTOR’ command performs Factor Analysis or Principal Axis
Factoring on a dataset.  It may be used to find common factors in the
data or for data reduction purposes.

   The ‘VARIABLES’ subcommand is required (unless the ‘MATRIX IN’
subcommand is used).  It lists the variables which are to partake in the
analysis.  (The ‘ANALYSIS’ subcommand may optionally further limit the
variables that participate; it is useful primarily in conjunction with
‘MATRIX IN’.)

   If ‘MATRIX IN’ instead of ‘VARIABLES’ is specified, then the analysis
is performed on a pre-prepared correlation or covariance matrix file
instead of on individual data cases.  Typically the matrix file will
have been generated by ‘MATRIX DATA’ (*note MATRIX DATA::) or provided
by a third party.  If specified, ‘MATRIX IN’ must be followed by ‘COV’
or ‘CORR’, then by ‘=’ and FILE_SPEC all in parentheses.  FILE_SPEC may
either be an asterisk, which indicates the currently loaded dataset, or
it may be a file name to be loaded.  *Note MATRIX DATA::, for the
expected format of the file.

   The ‘/EXTRACTION’ subcommand is used to specify the way in which
factors (components) are extracted from the data.  If ‘PC’ is specified,
then Principal Components Analysis is used.  If ‘PAF’ is specified, then
Principal Axis Factoring is used.  By default Principal Components
Analysis is used.

   The ‘/ROTATION’ subcommand is used to specify the method by which the
extracted solution is rotated.  Three orthogonal rotation methods are
available: ‘VARIMAX’ (which is the default), ‘EQUAMAX’, and ‘QUARTIMAX’.
There is one oblique rotation method, viz: ‘PROMAX’.  Optionally you may
enter the power of the promax rotation K, which must be enclosed in
parentheses.  The default value of K is 5.  If you don't want any
rotation to be performed, the word ‘NOROTATE’ prevents the command from
performing any rotation on the data.

   The ‘/METHOD’ subcommand should be used to determine whether the
covariance matrix or the correlation matrix of the data is to be
analysed.  By default, the correlation matrix is analysed.

   The ‘/PRINT’ subcommand may be used to select which features of the
analysis are reported:

   • ‘UNIVARIATE’ A table of mean values, standard deviations and total
     weights are printed.
   • ‘INITIAL’ Initial communalities and eigenvalues are printed.
   • ‘EXTRACTION’ Extracted communalities and eigenvalues are printed.
   • ‘ROTATION’ Rotated communalities and eigenvalues are printed.
   • ‘CORRELATION’ The correlation matrix is printed.
   • ‘COVARIANCE’ The covariance matrix is printed.
   • ‘DET’ The determinant of the correlation or covariance matrix is
     printed.
   • ‘AIC’ The anti-image covariance and anti-image correlation matrices
     are printed.
   • ‘KMO’ The Kaiser-Meyer-Olkin measure of sampling adequacy and the
     Bartlett test of sphericity is printed.
   • ‘SIG’ The significance of the elements of correlation matrix is
     printed.
   • ‘ALL’ All of the above are printed.
   • ‘DEFAULT’ Identical to ‘INITIAL’ and ‘EXTRACTION’.

   If ‘/PLOT=EIGEN’ is given, then a "Scree" plot of the eigenvalues is
printed.  This can be useful for visualizing the factors and deciding
which factors (components) should be retained.

   The ‘/FORMAT’ subcommand determined how data are to be displayed in
loading matrices.  If ‘SORT’ is specified, then the variables are sorted
in descending order of significance.  If ‘BLANK(N)’ is specified, then
coefficients whose absolute value is less than N are not printed.  If
the keyword ‘DEFAULT’ is specified, or if no ‘/FORMAT’ subcommand is
specified, then no sorting is performed, and all coefficients are
printed.

   You can use the ‘/CRITERIA’ subcommand to specify how the number of
extracted factors (components) are chosen.  If ‘FACTORS(N)’ is
specified, where N is an integer, then N factors are extracted.
Otherwise, the ‘MINEIGEN’ setting is used.  ‘MINEIGEN(L)’ requests that
all factors whose eigenvalues are greater than or equal to L are
extracted.  The default value of L is 1.  The ‘ECONVERGE’ setting has
effect only when using iterative algorithms for factor extraction (such
as Principal Axis Factoring).  ‘ECONVERGE(DELTA)’ specifies that
iteration should cease when the maximum absolute value of the
communality estimate between one iteration and the previous is less than
DELTA.  The default value of DELTA is 0.001.

   The ‘ITERATE(M)’ may appear any number of times and is used for two
different purposes.  It is used to set the maximum number of iterations
(M) for convergence and also to set the maximum number of iterations for
rotation.  Whether it affects convergence or rotation depends upon which
subcommand follows the ‘ITERATE’ subcommand.  If ‘EXTRACTION’ follows,
it affects convergence.  If ‘ROTATION’ follows, it affects rotation.  If
neither ‘ROTATION’ nor ‘EXTRACTION’ follow a ‘ITERATE’ subcommand, then
the entire subcommand is ignored.  The default value of M is 25.

   The ‘MISSING’ subcommand determines the handling of missing
variables.  If ‘INCLUDE’ is set, then user-missing values are included
in the calculations, but system-missing values are not.  If ‘EXCLUDE’ is
set, which is the default, user-missing values are excluded as well as
system-missing values.  This is the default.  If ‘LISTWISE’ is set, then
the entire case is excluded from analysis whenever any variable
specified in the ‘VARIABLES’ subcommand contains a missing value.

   If ‘PAIRWISE’ is set, then a case is considered missing only if
either of the values for the particular coefficient are missing.  The
default is ‘LISTWISE’.


File: pspp.info,  Node: GLM,  Next: LOGISTIC REGRESSION,  Prev: FACTOR,  Up: Statistics

15.9 GLM
========

     GLM DEPENDENT_VARS BY FIXED_FACTORS
          [/METHOD = SSTYPE(TYPE)]
          [/DESIGN = INTERACTION_0 [INTERACTION_1 [... INTERACTION_N]]]
          [/INTERCEPT = {INCLUDE|EXCLUDE}]
          [/MISSING = {INCLUDE|EXCLUDE}]

   The ‘GLM’ procedure can be used for fixed effects factorial Anova.

   The DEPENDENT_VARS are the variables to be analysed.  You may analyse
several variables in the same command in which case they should all
appear before the ‘BY’ keyword.

   The FIXED_FACTORS list must be one or more categorical variables.
Normally it does not make sense to enter a scalar variable in the
FIXED_FACTORS and doing so may cause PSPP to do a lot of unnecessary
processing.

   The ‘METHOD’ subcommand is used to change the method for producing
the sums of squares.  Available values of TYPE are 1, 2 and 3.  The
default is type 3.

   You may specify a custom design using the ‘DESIGN’ subcommand.  The
design comprises a list of interactions where each interaction is a list
of variables separated by a ‘*’.  For example the command
     GLM subject BY sex age_group race
         /DESIGN = age_group sex group age_group*sex age_group*race
specifies the model subject = age_group + sex + race + age_group*sex +
age_group*race.  If no ‘DESIGN’ subcommand is specified, then the
default is all possible combinations of the fixed factors.  That is to
say
     GLM subject BY sex age_group race
   implies the model subject = age_group + sex + race + age_group*sex +
age_group*race + sex*race + age_group*sex*race.

   The ‘MISSING’ subcommand determines the handling of missing
variables.  If ‘INCLUDE’ is set then, for the purposes of GLM analysis,
only system-missing values are considered to be missing; user-missing
values are not regarded as missing.  If ‘EXCLUDE’ is set, which is the
default, then user-missing values are considered to be missing as well
as system-missing values.  A case for which any dependent variable or
any factor variable has a missing value is excluded from the analysis.


File: pspp.info,  Node: LOGISTIC REGRESSION,  Next: MEANS,  Prev: GLM,  Up: Statistics

15.10 LOGISTIC REGRESSION
=========================

     LOGISTIC REGRESSION [VARIABLES =] DEPENDENT_VAR WITH PREDICTORS

          [/CATEGORICAL = CATEGORICAL_PREDICTORS]

          [{/NOCONST | /ORIGIN | /NOORIGIN }]

          [/PRINT = [SUMMARY] [DEFAULT] [CI(CONFIDENCE)] [ALL]]

          [/CRITERIA = [BCON(MIN_DELTA)] [ITERATE(MAX_INTERATIONS)]
                       [LCON(MIN_LIKELIHOOD_DELTA)] [EPS(MIN_EPSILON)]
                       [CUT(CUT_POINT)]]

          [/MISSING = {INCLUDE|EXCLUDE}]

   Bivariate Logistic Regression is used when you want to explain a
dichotomous dependent variable in terms of one or more predictor
variables.

   The minimum command is
     LOGISTIC REGRESSION Y WITH X1 X2 ... XN.
   Here, Y is the dependent variable, which must be dichotomous and X1
... XN are the predictor variables whose coefficients the procedure
estimates.

   By default, a constant term is included in the model.  Hence, the
full model is {\bf y} = b_0 + b_1 {\bf x_1} + b_2 {\bf x_2} + \dots +
b_n {\bf x_n}

   Predictor variables which are categorical in nature should be listed
on the ‘/CATEGORICAL’ subcommand.  Simple variables as well as
interactions between variables may be listed here.

   If you want a model without the constant term b_0, use the keyword
‘/ORIGIN’.  ‘/NOCONST’ is a synonym for ‘/ORIGIN’.

   An iterative Newton-Raphson procedure is used to fit the model.  The
‘/CRITERIA’ subcommand is used to specify the stopping criteria of the
procedure, and other parameters.  The value of CUT_POINT is used in the
classification table.  It is the threshold above which predicted values
are considered to be 1.  Values of CUT_POINT must lie in the range
[0,1].  During iterations, if any one of the stopping criteria are
satisfied, the procedure is considered complete.  The stopping criteria
are:
   • The number of iterations exceeds MAX_ITERATIONS.  The default value
     of MAX_ITERATIONS is 20.
   • The change in the all coefficient estimates are less than
     MIN_DELTA.  The default value of MIN_DELTA is 0.001.
   • The magnitude of change in the likelihood estimate is less than
     MIN_LIKELIHOOD_DELTA.  The default value of MIN_DELTA is zero.
     This means that this criterion is disabled.
   • The differential of the estimated probability for all cases is less
     than MIN_EPSILON.  In other words, the probabilities are close to
     zero or one.  The default value of MIN_EPSILON is 0.00000001.

   The ‘PRINT’ subcommand controls the display of optional statistics.
Currently there is one such option, ‘CI’, which indicates that the
confidence interval of the odds ratio should be displayed as well as its
value.  ‘CI’ should be followed by an integer in parentheses, to
indicate the confidence level of the desired confidence interval.

   The ‘MISSING’ subcommand determines the handling of missing
variables.  If ‘INCLUDE’ is set, then user-missing values are included
in the calculations, but system-missing values are not.  If ‘EXCLUDE’ is
set, which is the default, user-missing values are excluded as well as
system-missing values.  This is the default.


File: pspp.info,  Node: MEANS,  Next: NPAR TESTS,  Prev: LOGISTIC REGRESSION,  Up: Statistics

15.11 MEANS
===========

     MEANS [TABLES =]
           {VAR_LIST}
             [ BY {VAR_LIST} [BY {VAR_LIST} [BY {VAR_LIST} ... ]]]

           [ /{VAR_LIST}
              [ BY {VAR_LIST} [BY {VAR_LIST} [BY {VAR_LIST} ... ]]] ]

           [/CELLS = [MEAN] [COUNT] [STDDEV] [SEMEAN] [SUM] [MIN] [MAX] [RANGE]
             [VARIANCE] [KURT] [SEKURT]
             [SKEW] [SESKEW] [FIRST] [LAST]
             [HARMONIC] [GEOMETRIC]
             [DEFAULT]
             [ALL]
             [NONE] ]

           [/MISSING = [INCLUDE] [DEPENDENT]]

   You can use the ‘MEANS’ command to calculate the arithmetic mean and
similar statistics, either for the dataset as a whole or for categories
of data.

   The simplest form of the command is
     MEANS V.
which calculates the mean, count and standard deviation for V.  If you
specify a grouping variable, for example
     MEANS V BY G.
then the means, counts and standard deviations for V after having been
grouped by G are calculated.  Instead of the mean, count and standard
deviation, you could specify the statistics in which you are interested:
     MEANS X Y BY G
           /CELLS = HARMONIC SUM MIN.
   This example calculates the harmonic mean, the sum and the minimum
values of X and Y grouped by G.

   The ‘CELLS’ subcommand specifies which statistics to calculate.  The
available statistics are:
   • ‘MEAN’ The arithmetic mean.
   • ‘COUNT’ The count of the values.
   • ‘STDDEV’ The standard deviation.
   • ‘SEMEAN’ The standard error of the mean.
   • ‘SUM’ The sum of the values.
   • ‘MIN’ The minimum value.
   • ‘MAX’ The maximum value.
   • ‘RANGE’ The difference between the maximum and minimum values.
   • ‘VARIANCE’ The variance.
   • ‘FIRST’ The first value in the category.
   • ‘LAST’ The last value in the category.
   • ‘SKEW’ The skewness.
   • ‘SESKEW’ The standard error of the skewness.
   • ‘KURT’ The kurtosis
   • ‘SEKURT’ The standard error of the kurtosis.
   • ‘HARMONIC’ The harmonic mean.
   • ‘GEOMETRIC’ The geometric mean.

   In addition, three special keywords are recognized:
   • ‘DEFAULT’ This is the same as ‘MEAN’ ‘COUNT’ ‘STDDEV’.
   • ‘ALL’ All of the above statistics are calculated.
   • ‘NONE’ No statistics are calculated (only a summary is shown).

   More than one “table” can be specified in a single command.  Each
table is separated by a ‘/’.  For example
     MEANS TABLES =
           C D E BY X
           /A B BY X Y
           /F BY Y BY Z.
   has three tables (the ‘TABLE =’ is optional).  The first table has
three dependent variables C, D and E and a single categorical variable
X.  The second table has two dependent variables A and B, and two
categorical variables X and Y.  The third table has a single dependent
variables F and a categorical variable formed by the combination of Y
and Z.

   By default values are omitted from the analysis only if missing
values (either system missing or user missing) for any of the variables
directly involved in their calculation are encountered.  This behaviour
can be modified with the ‘/MISSING’ subcommand.  Three options are
possible: ‘TABLE’, ‘INCLUDE’ and ‘DEPENDENT’.

   ‘/MISSING = INCLUDE’ says that user missing values, either in the
dependent variables or in the categorical variables should be taken at
their face value, and not excluded.

   ‘/MISSING = DEPENDENT’ says that user missing values, in the
dependent variables should be taken at their face value, however cases
which have user missing values for the categorical variables should be
omitted from the calculation.

15.11.1 Example Means
---------------------

The dataset in ‘repairs.sav’ contains the mean time between failures
(mtbf) for a sample of artifacts produced by different factories and
trialed under different operating conditions.  Since there are four
combinations of categorical variables, by simply looking at the list of
data, it would be hard to how the scores vary for each category.  *note
Example 15.4: means:ex. shows one way of tabulating the mtbf in a way
which is easier to understand.

     get file='repairs.sav'.
     
     means tables = mtbf
           by factory by environment.

Example 15.4: Running ‘MEANS’ on the mtbf score with categories factory
and environment

   The results are shown in *note Result 15.3: means:res.  The figures
shown indicate the mean, standard deviation and number of samples in
each category.  These figures however do not indicate whether the
results are statistically significant.  For that, you would need to use
the procedures ‘ONEWAY’, ‘GLM’ or ‘T-TEST’ depending on the hypothesis
being tested.

 [image src="pspp-figures/means.png" text="                    Case Processing Summary
+----------------------------+-------------------------------+
|                            |             Cases             |
|                            +----------+---------+----------+
|                            | Included | Excluded|   Total  |
|                            +--+-------+-+-------+--+-------+
|                            | N|Percent|N|Percent| N|Percent|
+----------------------------+--+-------+-+-------+--+-------+
|mtbf * factory * environment|30| 100.0%|0|    .0%|30| 100.0%|
+----------------------------+--+-------+-+-------+--+-------+

                                Report
+--------------------------------------------+-----+--+--------------+
|Manufacturing facility Operating Environment| Mean| N|Std. Deviation|
+--------------------------------------------+-----+--+--------------+
|0                      Temperate            | 7.26| 9|          2.57|
|                       Tropical             | 7.47| 7|          2.68|
|                       Total                | 7.35|16|          2.53|
+--------------------------------------------+-----+--+--------------+
|1                      Temperate            |13.38| 6|          7.77|
|                       Tropical             | 8.20| 8|          8.39|
|                       Total                |10.42|14|          8.26|
+--------------------------------------------+-----+--+--------------+
|Total                  Temperate            | 9.71|15|          5.91|
|                       Tropical             | 7.86|15|          6.20|
|                       Total                | 8.78|30|          6.03|
+--------------------------------------------+-----+--+--------------+" ]


Result 15.3: The mtbf categorised by factory and environment

   Note that there is no limit to the number of variables for which you
can calculate statistics, nor to the number of categorical variables per
layer, nor the number of layers.  However, running ‘MEANS’ on a large
numbers of variables, or with categorical variables containing a large
number of distinct values may result in an extremely large output, which
will not be easy to interpret.  So you should consider carefully which
variables to select for participation in the analysis.


File: pspp.info,  Node: NPAR TESTS,  Next: T-TEST,  Prev: MEANS,  Up: Statistics

15.12 NPAR TESTS
================

     NPAR TESTS

          nonparametric test subcommands
          .
          .
          .

          [ /STATISTICS={DESCRIPTIVES} ]

          [ /MISSING={ANALYSIS, LISTWISE} {INCLUDE, EXCLUDE} ]

          [ /METHOD=EXACT [ TIMER [(N)] ] ]

   ‘NPAR TESTS’ performs nonparametric tests.  Non parametric tests make
very few assumptions about the distribution of the data.  One or more
tests may be specified by using the corresponding subcommand.  If the
‘/STATISTICS’ subcommand is also specified, then summary statistics are
produces for each variable that is the subject of any test.

   Certain tests may take a long time to execute, if an exact figure is
required.  Therefore, by default asymptotic approximations are used
unless the subcommand ‘/METHOD=EXACT’ is specified.  Exact tests give
more accurate results, but may take an unacceptably long time to
perform.  If the ‘TIMER’ keyword is used, it sets a maximum time, after
which the test is abandoned, and a warning message printed.  The time,
in minutes, should be specified in parentheses after the ‘TIMER’
keyword.  If the ‘TIMER’ keyword is given without this figure, then a
default value of 5 minutes is used.

* Menu:

* BINOMIAL::                Binomial Test
* CHISQUARE::               Chi-square Test
* COCHRAN::                 Cochran Q Test
* FRIEDMAN::                Friedman Test
* KENDALL::                 Kendall's W Test
* KOLMOGOROV-SMIRNOV::      Kolmogorov Smirnov Test
* KRUSKAL-WALLIS::          Kruskal-Wallis Test
* MANN-WHITNEY::            Mann Whitney U Test
* MCNEMAR::                 McNemar Test
* MEDIAN::                  Median Test
* RUNS::                    Runs Test
* SIGN::                    The Sign Test
* WILCOXON::                Wilcoxon Signed Ranks Test


File: pspp.info,  Node: BINOMIAL,  Next: CHISQUARE,  Up: NPAR TESTS

15.12.1 Binomial test
---------------------

          [ /BINOMIAL[(P)]=VAR_LIST[(VALUE1[, VALUE2)] ] ]

   The ‘/BINOMIAL’ subcommand compares the observed distribution of a
dichotomous variable with that of a binomial distribution.  The variable
P specifies the test proportion of the binomial distribution.  The
default value of 0.5 is assumed if P is omitted.

   If a single value appears after the variable list, then that value is
used as the threshold to partition the observed values.  Values less
than or equal to the threshold value form the first category.  Values
greater than the threshold form the second category.

   If two values appear after the variable list, then they are used as
the values which a variable must take to be in the respective category.
Cases for which a variable takes a value equal to neither of the
specified values, take no part in the test for that variable.

   If no values appear, then the variable must assume dichotomous
values.  If more than two distinct, non-missing values for a variable
under test are encountered then an error occurs.

   If the test proportion is equal to 0.5, then a two-tailed test is
reported.  For any other test proportion, a one-tailed test is reported.
For one-tailed tests, if the test proportion is less than or equal to
the observed proportion, then the significance of observing the observed
proportion or more is reported.  If the test proportion is more than the
observed proportion, then the significance of observing the observed
proportion or less is reported.  That is to say, the test is always
performed in the observed direction.

   PSPP uses a very precise approximation to the gamma function to
compute the binomial significance.  Thus, exact results are reported
even for very large sample sizes.


File: pspp.info,  Node: CHISQUARE,  Next: COCHRAN,  Prev: BINOMIAL,  Up: NPAR TESTS

15.12.2 Chi-square Test
-----------------------

          [ /CHISQUARE=VAR_LIST[(LO,HI)] [/EXPECTED={EQUAL|F1, F2 ... FN}] ]

   The ‘/CHISQUARE’ subcommand produces a chi-square statistic for the
differences between the expected and observed frequencies of the
categories of a variable.  Optionally, a range of values may appear
after the variable list.  If a range is given, then non integer values
are truncated, and values outside the specified range are excluded from
the analysis.

   The ‘/EXPECTED’ subcommand specifies the expected values of each
category.  There must be exactly one non-zero expected value, for each
observed category, or the ‘EQUAL’ keyword must be specified.  You may
use the notation ‘N*F’ to specify N consecutive expected categories all
taking a frequency of F.  The frequencies given are proportions, not
absolute frequencies.  The sum of the frequencies need not be 1.  If no
‘/EXPECTED’ subcommand is given, then equal frequencies are expected.

15.12.2.1 Chi-square Example
............................

A researcher wishes to investigate whether there are an equal number of
persons of each sex in a population.  The sample chosen for invesigation
is that from the ‘physiology.sav’ dataset.  The null hypothesis for the
test is that the population comprises an equal number of males and
females.  The analysis is performed as shown in *note Example 15.5:
chisquare:ex.

     get file='physiology.sav'.
     
     npar test
          /chisquare=sex.

Example 15.5: Performing a chi-square test to check for equal
distribution of sexes

   There is only one test variable, viz: sex.  The other variables in
the dataset are ignored.

 [image src="screenshots/chisquare-ad.png" ]

Screenshot 15.4: Performing a chi-square test using the graphic user
interface

   In *note Result 15.4: chisquare:res. the summary box shows that in
the sample, there are more males than females.  However the significance
of chi-square result is greater than 0.05 -- the most commonly accepted
p-value -- and therefore there is not enough evidence to reject the null
hypothesis and one must conclude that the evidence does not indicate
that there is an imbalance of the sexes in the population.

 [image src="pspp-figures/chisquare.png" text="             Sex of subject
+------+----------+----------+--------+
|Value |Observed N|Expected N|Residual|
+------+----------+----------+--------+
|Male  |        22|     20.00|    2.00|
|Female|        18|     20.00|   -2.00|
|Total |        40|          |        |
+------+----------+----------+--------+

              Test Statistics
+--------------+----------+--+-----------+
|              |Chi-square|df|Asymp. Sig.|
+--------------+----------+--+-----------+
|Sex of subject|       .40| 1|       .527|
+--------------+----------+--+-----------+" ]


Result 15.4: The results of running a chi-square test on sex


File: pspp.info,  Node: COCHRAN,  Next: FRIEDMAN,  Prev: CHISQUARE,  Up: NPAR TESTS

15.12.3 Cochran Q Test
----------------------

          [ /COCHRAN = VAR_LIST ]

   The Cochran Q test is used to test for differences between three or
more groups.  The data for VAR_LIST in all cases must assume exactly two
distinct values (other than missing values).

   The value of Q is displayed along with its Asymptotic significance
based on a chi-square distribution.


File: pspp.info,  Node: FRIEDMAN,  Next: KENDALL,  Prev: COCHRAN,  Up: NPAR TESTS

15.12.4 Friedman Test
---------------------

          [ /FRIEDMAN = VAR_LIST ]

   The Friedman test is used to test for differences between repeated
measures when there is no indication that the distributions are normally
distributed.

   A list of variables which contain the measured data must be given.
The procedure prints the sum of ranks for each variable, the test
statistic and its significance.


File: pspp.info,  Node: KENDALL,  Next: KOLMOGOROV-SMIRNOV,  Prev: FRIEDMAN,  Up: NPAR TESTS

15.12.5 Kendall's W Test
------------------------

          [ /KENDALL = VAR_LIST ]

   The Kendall test investigates whether an arbitrary number of related
samples come from the same population.  It is identical to the Friedman
test except that the additional statistic W, Kendall's Coefficient of
Concordance is printed.  It has the range [0,1] -- a value of zero
indicates no agreement between the samples whereas a value of unity
indicates complete agreement.


File: pspp.info,  Node: KOLMOGOROV-SMIRNOV,  Next: KRUSKAL-WALLIS,  Prev: KENDALL,  Up: NPAR TESTS

15.12.6 Kolmogorov-Smirnov Test
-------------------------------

          [ /KOLMOGOROV-SMIRNOV ({NORMAL [MU, SIGMA], UNIFORM [MIN, MAX], POISSON [LAMBDA], EXPONENTIAL [SCALE] }) = VAR_LIST ]

   The one-sample Kolmogorov-Smirnov subcommand is used to test whether
or not a dataset is drawn from a particular distribution.  Four
distributions are supported, viz: Normal, Uniform, Poisson and
Exponential.

   Ideally you should provide the parameters of the distribution against
which you wish to test the data.  For example, with the normal
distribution the mean (MU)and standard deviation (SIGMA) should be
given; with the uniform distribution, the minimum (MIN)and maximum (MAX)
value should be provided.  However, if the parameters are omitted they
are imputed from the data.  Imputing the parameters reduces the power of
the test so should be avoided if possible.

   In the following example, two variables SCORE and AGE are tested to
see if they follow a normal distribution with a mean of 3.5 and a
standard deviation of 2.0.
       NPAR TESTS
             /KOLMOGOROV-SMIRNOV (normal 3.5 2.0) = SCORE AGE.
   If the variables need to be tested against different distributions,
then a separate subcommand must be used.  For example the following
syntax tests SCORE against a normal distribution with mean of 3.5 and
standard deviation of 2.0 whilst AGE is tested against a normal
distribution of mean 40 and standard deviation 1.5.
       NPAR TESTS
             /KOLMOGOROV-SMIRNOV (normal 3.5 2.0) = SCORE
             /KOLMOGOROV-SMIRNOV (normal 40 1.5) =  AGE.

   The abbreviated subcommand ‘K-S’ may be used in place of
‘KOLMOGOROV-SMIRNOV’.


File: pspp.info,  Node: KRUSKAL-WALLIS,  Next: MANN-WHITNEY,  Prev: KOLMOGOROV-SMIRNOV,  Up: NPAR TESTS

15.12.7 Kruskal-Wallis Test
---------------------------

          [ /KRUSKAL-WALLIS = VAR_LIST BY var (LOWER, UPPER) ]

   The Kruskal-Wallis test is used to compare data from an arbitrary
number of populations.  It does not assume normality.  The data to be
compared are specified by VAR_LIST.  The categorical variable
determining the groups to which the data belongs is given by VAR.  The
limits LOWER and UPPER specify the valid range of VAR.  If UPPER is
smaller than LOWER, the PSPP will assume their values to be reversed.
Any cases for which VAR falls outside [LOWER, UPPER] are ignored.

   The mean rank of each group as well as the chi-squared value and
significance of the test are printed.  The abbreviated subcommand ‘K-W’
may be used in place of ‘KRUSKAL-WALLIS’.


File: pspp.info,  Node: MANN-WHITNEY,  Next: MCNEMAR,  Prev: KRUSKAL-WALLIS,  Up: NPAR TESTS

15.12.8 Mann-Whitney U Test
---------------------------

          [ /MANN-WHITNEY = VAR_LIST BY var (GROUP1, GROUP2) ]

   The Mann-Whitney subcommand is used to test whether two groups of
data come from different populations.  The variables to be tested should
be specified in VAR_LIST and the grouping variable, that determines to
which group the test variables belong, in VAR.  VAR may be either a
string or an alpha variable.  GROUP1 and GROUP2 specify the two values
of VAR which determine the groups of the test data.  Cases for which the
VAR value is neither GROUP1 or GROUP2 are ignored.

   The value of the Mann-Whitney U statistic, the Wilcoxon W, and the
significance are printed.  You may abbreviated the subcommand
‘MANN-WHITNEY’ to ‘M-W’.


File: pspp.info,  Node: MCNEMAR,  Next: MEDIAN,  Prev: MANN-WHITNEY,  Up: NPAR TESTS

15.12.9 McNemar Test
--------------------

          [ /MCNEMAR VAR_LIST [ WITH VAR_LIST [ (PAIRED) ]]]

   Use McNemar's test to analyse the significance of the difference
between pairs of correlated proportions.

   If the ‘WITH’ keyword is omitted, then tests for all combinations of
the listed variables are performed.  If the ‘WITH’ keyword is given, and
the ‘(PAIRED)’ keyword is also given, then the number of variables
preceding ‘WITH’ must be the same as the number following it.  In this
case, tests for each respective pair of variables are performed.  If the
‘WITH’ keyword is given, but the ‘(PAIRED)’ keyword is omitted, then
tests for each combination of variable preceding ‘WITH’ against variable
following ‘WITH’ are performed.

   The data in each variable must be dichotomous.  If there are more
than two distinct variables an error will occur and the test will not be
run.


File: pspp.info,  Node: MEDIAN,  Next: RUNS,  Prev: MCNEMAR,  Up: NPAR TESTS

15.12.10 Median Test
--------------------

          [ /MEDIAN [(VALUE)] = VAR_LIST BY VARIABLE (VALUE1, VALUE2) ]

   The median test is used to test whether independent samples come from
populations with a common median.  The median of the populations against
which the samples are to be tested may be given in parentheses
immediately after the ‘/MEDIAN’ subcommand.  If it is not given, the
median is imputed from the union of all the samples.

   The variables of the samples to be tested should immediately follow
the ‘=’ sign.  The keyword ‘BY’ must come next, and then the grouping
variable.  Two values in parentheses should follow.  If the first value
is greater than the second, then a 2 sample test is performed using
these two values to determine the groups.  If however, the first
variable is less than the second, then a k sample test is conducted and
the group values used are all values encountered which lie in the range
[VALUE1,VALUE2].


File: pspp.info,  Node: RUNS,  Next: SIGN,  Prev: MEDIAN,  Up: NPAR TESTS

15.12.11 Runs Test
------------------

          [ /RUNS ({MEAN, MEDIAN, MODE, VALUE})  = VAR_LIST ]

   The ‘/RUNS’ subcommand tests whether a data sequence is randomly
ordered.

   It works by examining the number of times a variable's value crosses
a given threshold.  The desired threshold must be specified within
parentheses.  It may either be specified as a number or as one of
‘MEAN’, ‘MEDIAN’ or ‘MODE’.  Following the threshold specification comes
the list of variables whose values are to be tested.

   The subcommand shows the number of runs, the asymptotic significance
based on the length of the data.


File: pspp.info,  Node: SIGN,  Next: WILCOXON,  Prev: RUNS,  Up: NPAR TESTS

15.12.12 Sign Test
------------------

          [ /SIGN VAR_LIST [ WITH VAR_LIST [ (PAIRED) ]]]

   The ‘/SIGN’ subcommand tests for differences between medians of the
variables listed.  The test does not make any assumptions about the
distribution of the data.

   If the ‘WITH’ keyword is omitted, then tests for all combinations of
the listed variables are performed.  If the ‘WITH’ keyword is given, and
the ‘(PAIRED)’ keyword is also given, then the number of variables
preceding ‘WITH’ must be the same as the number following it.  In this
case, tests for each respective pair of variables are performed.  If the
‘WITH’ keyword is given, but the ‘(PAIRED)’ keyword is omitted, then
tests for each combination of variable preceding ‘WITH’ against variable
following ‘WITH’ are performed.


File: pspp.info,  Node: WILCOXON,  Prev: SIGN,  Up: NPAR TESTS

15.12.13 Wilcoxon Matched Pairs Signed Ranks Test
-------------------------------------------------

          [ /WILCOXON VAR_LIST [ WITH VAR_LIST [ (PAIRED) ]]]

   The ‘/WILCOXON’ subcommand tests for differences between medians of
the variables listed.  The test does not make any assumptions about the
variances of the samples.  It does however assume that the distribution
is symmetrical.

   If the ‘WITH’ keyword is omitted, then tests for all combinations of
the listed variables are performed.  If the ‘WITH’ keyword is given, and
the ‘(PAIRED)’ keyword is also given, then the number of variables
preceding ‘WITH’ must be the same as the number following it.  In this
case, tests for each respective pair of variables are performed.  If the
‘WITH’ keyword is given, but the ‘(PAIRED)’ keyword is omitted, then
tests for each combination of variable preceding ‘WITH’ against variable
following ‘WITH’ are performed.


File: pspp.info,  Node: T-TEST,  Next: ONEWAY,  Prev: NPAR TESTS,  Up: Statistics

15.13 T-TEST
============

     T-TEST
             /MISSING={ANALYSIS,LISTWISE} {EXCLUDE,INCLUDE}
             /CRITERIA=CI(CONFIDENCE)


     (One Sample mode.)
             TESTVAL=TEST_VALUE
             /VARIABLES=VAR_LIST


     (Independent Samples mode.)
             GROUPS=var(VALUE1 [, VALUE2])
             /VARIABLES=VAR_LIST


     (Paired Samples mode.)
             PAIRS=VAR_LIST [WITH VAR_LIST [(PAIRED)] ]


   The ‘T-TEST’ procedure outputs tables used in testing hypotheses
about means.  It operates in one of three modes:
   • One Sample mode.
   • Independent Groups mode.
   • Paired mode.

Each of these modes are described in more detail below.  There are two
optional subcommands which are common to all modes.

   The ‘/CRITERIA’ subcommand tells PSPP the confidence interval used in
the tests.  The default value is 0.95.

   The ‘MISSING’ subcommand determines the handling of missing
variables.  If ‘INCLUDE’ is set, then user-missing values are included
in the calculations, but system-missing values are not.  If ‘EXCLUDE’ is
set, which is the default, user-missing values are excluded as well as
system-missing values.  This is the default.

   If ‘LISTWISE’ is set, then the entire case is excluded from analysis
whenever any variable specified in the ‘/VARIABLES’, ‘/PAIRS’ or
‘/GROUPS’ subcommands contains a missing value.  If ‘ANALYSIS’ is set,
then missing values are excluded only in the analysis for which they
would be needed.  This is the default.

* Menu:

* One Sample Mode::             Testing against a hypothesized mean
* Independent Samples Mode::    Testing two independent groups for equal mean
* Paired Samples Mode::         Testing two interdependent groups for equal mean


File: pspp.info,  Node: One Sample Mode,  Next: Independent Samples Mode,  Up: T-TEST

15.13.1 One Sample Mode
-----------------------

The ‘TESTVAL’ subcommand invokes the One Sample mode.  This mode is used
to test a population mean against a hypothesized mean.  The value given
to the ‘TESTVAL’ subcommand is the value against which you wish to test.
In this mode, you must also use the ‘/VARIABLES’ subcommand to tell PSPP
which variables you wish to test.

15.13.1.1 Example - One-Sample T-test
.....................................

A researcher wishes to know whether the weight of persons in a
population is different from the national average.  The samples are
drawn from the population under investigation and recorded in the file
‘physiology.sav’.  From the Department of Health, she knows that the
national average weight of healthy adults is 76.8kg.  Accordingly the
‘TESTVAL’ is set to 76.8.  The null hypothesis therefore is that the
mean average weight of the population from which the sample was drawn is
76.8kg.

   As previously noted (*note Identifying incorrect data::), one sample
in the dataset contains a weight value which is clearly incorrect.  So
this is excluded from the analysis using the ‘SELECT’ command.

     get file='physiology.sav'.
     
     select if (weight > 0).
     
     t-test testval = 76.8
     	/variables = weight.

Example 15.6: Running a one-sample T-Test after excluding all
non-positive values

 [image src="screenshots/one-sample-t-ad.png" ]

Screenshot 15.5: Using the One-Sample T-Test dialog box to test weight
for a mean of 76.8kg

   *note Results 15.2: one-sample-t:res. shows that the mean of our
sample differs from the test value by -1.40kg.  However the significance
is very high (0.610).  So one cannot reject the null hypothesis, and
must conclude there is not enough evidence to suggest that the mean
weight of the persons in our population is different from 76.8kg.

 [image src="pspp-figures/one-sample-t.png" text="                 One-Sample Statistics
+-------------------+--+-----+--------------+---------+
|                   | N| Mean|Std. Deviation|S.E. Mean|
+-------------------+--+-----+--------------+---------+
|Weight in kilograms|39|75.40|         17.08|     2.73|
+-------------------+--+-----+--------------+---------+

                                One-Sample Test
+--------------+--------------------------------------------------------------+
|              |                       Test Value = 76.8                      |
|              +----+--+------------+------------+----------------------------+
|              |    |  |            |            | 95% Confidence Interval of |
|              |    |  |            |            |       the Difference       |
|              |    |  |  Sig. (2-  |    Mean    +--------------+-------------+
|              |  t |df|   tailed)  | Difference |     Lower    |    Upper    |
+--------------+----+--+------------+------------+--------------+-------------+
|Weight in     |-.51|38|        .610|       -1.40|         -6.94|         4.13|
|kilograms     |    |  |            |            |              |             |
+--------------+----+--+------------+------------+--------------+-------------+" ]


Results 15.2: The results of a one-sample T-test of weight using a test
value of 76.8kg


File: pspp.info,  Node: Independent Samples Mode,  Next: Paired Samples Mode,  Prev: One Sample Mode,  Up: T-TEST

15.13.2 Independent Samples Mode
--------------------------------

The ‘GROUPS’ subcommand invokes Independent Samples mode or 'Groups'
mode.  This mode is used to test whether two groups of values have the
same population mean.  In this mode, you must also use the ‘/VARIABLES’
subcommand to tell PSPP the dependent variables you wish to test.

   The variable given in the ‘GROUPS’ subcommand is the independent
variable which determines to which group the samples belong.  The values
in parentheses are the specific values of the independent variable for
each group.  If the parentheses are omitted and no values are given, the
default values of 1.0 and 2.0 are assumed.

   If the independent variable is numeric, it is acceptable to specify
only one value inside the parentheses.  If you do this, cases where the
independent variable is greater than or equal to this value belong to
the first group, and cases less than this value belong to the second
group.  When using this form of the ‘GROUPS’ subcommand, missing values
in the independent variable are excluded on a listwise basis, regardless
of whether ‘/MISSING=LISTWISE’ was specified.

15.13.2.1 Example - Independent Samples T-test
..............................................

A researcher wishes to know whether within a population, adult males are
taller than adult females.  The samples are drawn from the population
under investigation and recorded in the file ‘physiology.sav’.

   As previously noted (*note Identifying incorrect data::), one sample
in the dataset contains a height value which is clearly incorrect.  So
this is excluded from the analysis using the ‘SELECT’ command.

     get file='physiology.sav'.
     
     select if (height >= 200).
     
     t-test /variables = height
            /groups = sex(0,1).

Example 15.7: Running a independent samples T-Test after excluding all
observations less than 200kg

   The null hypothesis is that both males and females are on average of
equal height.

 [image src="screenshots/independent-samples-t-ad.png" ]

Screenshot 15.6: Using the Independent Sample T-test dialog, to test for
differences of height between values of sex

   In this case, the grouping variable is sex, so this is entered as the
variable for the ‘GROUP’ subcommand.  The group values are 0 (male) and
1 (female).

   If you are running the proceedure using syntax, then you need to
enter the values corresponding to each group within parentheses.  If you
are using the graphic user interface, then you have to open the "Define
Groups" dialog box and enter the values corresponding to each group as
shown in *note Screenshot 15.7: define-groups-t:scr.  If, as in this
case, the dataset has defined value labels for the group variable, then
you can enter them by label or by value.

 [image src="screenshots/define-groups-t-ad.png" ]

Screenshot 15.7: Setting the values of the grouping variable for an
Independent Samples T-test

   From *note Result 15.5: independent-samples-t:res, one can clearly
see that the _sample_ mean height is greater for males than for females.
However in order to see if this is a significant result, one must
consult the T-Test table.

   The T-Test table contains two rows; one for use if the variance of
the samples in each group may be safely assumed to be equal, and the
second row if the variances in each group may not be safely assumed to
be equal.

   In this case however, both rows show a 2-tailed significance less
than 0.001 and one must therefore reject the null hypothesis and
conclude that within the population the mean height of males and of
females are unequal.

 [image src="pspp-figures/independent-samples-t.png" text="                         Group Statistics
+----------------------------+--+-------+--------------+---------+
|                      Group | N|  Mean |Std. Deviation|S.E. Mean|
+----------------------------+--+-------+--------------+---------+
|Height in millimeters Male  |22|1796.49|         49.71|    10.60|
|                      Female|17|1610.77|         25.43|     6.17|
+----------------------------+--+-------+--------------+---------+

                          Independent Samples Test
+---------------------+----------+------------------------------------------
|                     | Levene's |
|                     | Test for |
|                     | Equality |
|                     |    of    |
|                     | Variances|              T-Test for Equality of Means
|                     +----+-----+-----+-----+-------+----------+----------+
|                     |    |     |     |     |       |          |          |
|                     |    |     |     |     |       |          |          |
|                     |    |     |     |     |       |          |          |
|                     |    |     |     |     |       |          |          |
|                     |    |     |     |     |  Sig. |          |          |
|                     |    |     |     |     |  (2-  |   Mean   |Std. Error|
|                     |  F | Sig.|  t  |  df |tailed)|Difference|Difference|
+---------------------+----+-----+-----+-----+-------+----------+----------+
|Height in   Equal    | .97| .331|14.02|37.00|   .000|    185.72|     13.24|
|millimeters variances|    |     |     |     |       |          |          |
|            assumed  |    |     |     |     |       |          |          |
|            Equal    |    |     |15.15|32.71|   .000|    185.72|     12.26|
|            variances|    |     |     |     |       |          |          |
|            not      |    |     |     |     |       |          |          |
|            assumed  |    |     |     |     |       |          |          |
+---------------------+----+-----+-----+-----+-------+----------+----------+

+---------------------+-------------+
|                     |             |
|                     |             |
|                     |             |
|                     |             |
|                     |             |
|                     +-------------+
|                     |     95%     |
|                     |  Confidence |
|                     | Interval of |
|                     |     the     |
|                     |  Difference |
|                     +------+------+
|                     | Lower| Upper|
+---------------------+------+------+
|Height in   Equal    |158.88|212.55|
|millimeters variances|      |      |
|            assumed  |      |      |
|            Equal    |160.76|210.67|
|            variances|      |      |
|            not      |      |      |
|            assumed  |      |      |
+---------------------+------+------+" ]


Result 15.5: The results of an independent samples T-test of height by
sex


File: pspp.info,  Node: Paired Samples Mode,  Prev: Independent Samples Mode,  Up: T-TEST

15.13.3 Paired Samples Mode
---------------------------

The ‘PAIRS’ subcommand introduces Paired Samples mode.  Use this mode
when repeated measures have been taken from the same samples.  If the
‘WITH’ keyword is omitted, then tables for all combinations of variables
given in the ‘PAIRS’ subcommand are generated.  If the ‘WITH’ keyword is
given, and the ‘(PAIRED)’ keyword is also given, then the number of
variables preceding ‘WITH’ must be the same as the number following it.
In this case, tables for each respective pair of variables are
generated.  In the event that the ‘WITH’ keyword is given, but the
‘(PAIRED)’ keyword is omitted, then tables for each combination of
variable preceding ‘WITH’ against variable following ‘WITH’ are
generated.


File: pspp.info,  Node: ONEWAY,  Next: QUICK CLUSTER,  Prev: T-TEST,  Up: Statistics

15.14 ONEWAY
============

     ONEWAY
             [/VARIABLES = ] VAR_LIST BY VAR
             /MISSING={ANALYSIS,LISTWISE} {EXCLUDE,INCLUDE}
             /CONTRAST= VALUE1 [, VALUE2] ... [,VALUEN]
             /STATISTICS={DESCRIPTIVES,HOMOGENEITY}
             /POSTHOC={BONFERRONI, GH, LSD, SCHEFFE, SIDAK, TUKEY, ALPHA ([VALUE])}

   The ‘ONEWAY’ procedure performs a one-way analysis of variance of
variables factored by a single independent variable.  It is used to
compare the means of a population divided into more than two groups.

   The dependent variables to be analysed should be given in the
‘VARIABLES’ subcommand.  The list of variables must be followed by the
‘BY’ keyword and the name of the independent (or factor) variable.

   You can use the ‘STATISTICS’ subcommand to tell PSPP to display
ancillary information.  The options accepted are:
   • DESCRIPTIVES Displays descriptive statistics about the groups
     factored by the independent variable.
   • HOMOGENEITY Displays the Levene test of Homogeneity of Variance for
     the variables and their groups.

   The ‘CONTRAST’ subcommand is used when you anticipate certain
differences between the groups.  The subcommand must be followed by a
list of numerals which are the coefficients of the groups to be tested.
The number of coefficients must correspond to the number of distinct
groups (or values of the independent variable).  If the total sum of the
coefficients are not zero, then PSPP will display a warning, but will
proceed with the analysis.  The ‘CONTRAST’ subcommand may be given up to
10 times in order to specify different contrast tests.  The ‘MISSING’
subcommand defines how missing values are handled.  If ‘LISTWISE’ is
specified then cases which have missing values for the independent
variable or any dependent variable are ignored.  If ‘ANALYSIS’ is
specified, then cases are ignored if the independent variable is missing
or if the dependent variable currently being analysed is missing.  The
default is ‘ANALYSIS’.  A setting of ‘EXCLUDE’ means that variables
whose values are user-missing are to be excluded from the analysis.  A
setting of ‘INCLUDE’ means they are to be included.  The default is
‘EXCLUDE’.

   Using the ‘POSTHOC’ subcommand you can perform multiple pairwise
comparisons on the data.  The following comparison methods are
available:
   • ‘LSD’ Least Significant Difference.
   • ‘TUKEY’ Tukey Honestly Significant Difference.
   • ‘BONFERRONI’ Bonferroni test.
   • ‘SCHEFFE’ Scheffé's test.
   • ‘SIDAK’ Sidak test.
   • ‘GH’ The Games-Howell test.

Use the optional syntax ‘ALPHA(VALUE)’ to indicate that ‘ONEWAY’ should
perform the posthoc tests at a confidence level of VALUE.  If
‘ALPHA(VALUE)’ is not specified, then the confidence level used is 0.05.


File: pspp.info,  Node: QUICK CLUSTER,  Next: RANK,  Prev: ONEWAY,  Up: Statistics

15.15 QUICK CLUSTER
===================

     QUICK CLUSTER VAR_LIST
           [/CRITERIA=CLUSTERS(K) [MXITER(MAX_ITER)] CONVERGE(EPSILON) [NOINITIAL]]
           [/MISSING={EXCLUDE,INCLUDE} {LISTWISE, PAIRWISE}]
           [/PRINT={INITIAL} {CLUSTER}]
           [/SAVE[=[CLUSTER[(MEMBERSHIP_VAR)]] [DISTANCE[(DISTANCE_VAR)]]]

   The ‘QUICK CLUSTER’ command performs k-means clustering on the
dataset.  This is useful when you wish to allocate cases into clusters
of similar values and you already know the number of clusters.

   The minimum specification is ‘QUICK CLUSTER’ followed by the names of
the variables which contain the cluster data.  Normally you will also
want to specify ‘/CRITERIA=CLUSTERS(K)’ where K is the number of
clusters.  If this is not specified, then K defaults to 2.

   If you use ‘/CRITERIA=NOINITIAL’ then a naive algorithm to select the
initial clusters is used.  This will provide for faster execution but
less well separated initial clusters and hence possibly an inferior
final result.

   ‘QUICK CLUSTER’ uses an iterative algorithm to select the clusters
centers.  The subcommand ‘/CRITERIA=MXITER(MAX_ITER)’ sets the maximum
number of iterations.  During classification, PSPP will continue
iterating until until MAX_ITER iterations have been done or the
convergence criterion (see below) is fulfilled.  The default value of
MAX_ITER is 2.

   If however, you specify ‘/CRITERIA=NOUPDATE’ then after selecting the
initial centers, no further update to the cluster centers is done.  In
this case, MAX_ITER, if specified.  is ignored.

   The subcommand ‘/CRITERIA=CONVERGE(EPSILON)’ is used to set the
convergence criterion.  The value of convergence criterion is EPSILON
times the minimum distance between the _initial_ cluster centers.
Iteration stops when the mean cluster distance between one iteration and
the next is less than the convergence criterion.  The default value of
EPSILON is zero.

   The ‘MISSING’ subcommand determines the handling of missing
variables.  If ‘INCLUDE’ is set, then user-missing values are considered
at their face value and not as missing values.  If ‘EXCLUDE’ is set,
which is the default, user-missing values are excluded as well as
system-missing values.

   If ‘LISTWISE’ is set, then the entire case is excluded from the
analysis whenever any of the clustering variables contains a missing
value.  If ‘PAIRWISE’ is set, then a case is considered missing only if
all the clustering variables contain missing values.  Otherwise it is
clustered on the basis of the non-missing values.  The default is
‘LISTWISE’.

   The ‘PRINT’ subcommand requests additional output to be printed.  If
‘INITIAL’ is set, then the initial cluster memberships will be printed.
If ‘CLUSTER’ is set, the cluster memberships of the individual cases are
displayed (potentially generating lengthy output).

   You can specify the subcommand ‘SAVE’ to ask that each case's cluster
membership and the euclidean distance between the case and its cluster
center be saved to a new variable in the active dataset.  To save the
cluster membership use the ‘CLUSTER’ keyword and to save the distance
use the ‘DISTANCE’ keyword.  Each keyword may optionally be followed by
a variable name in parentheses to specify the new variable which is to
contain the saved parameter.  If no variable name is specified, then
PSPP will create one.


File: pspp.info,  Node: RANK,  Next: REGRESSION,  Prev: QUICK CLUSTER,  Up: Statistics

15.16 RANK
==========

     RANK
             [VARIABLES=] VAR_LIST [{A,D}] [BY VAR_LIST]
             /TIES={MEAN,LOW,HIGH,CONDENSE}
             /FRACTION={BLOM,TUKEY,VW,RANKIT}
             /PRINT[={YES,NO}
             /MISSING={EXCLUDE,INCLUDE}

             /RANK [INTO VAR_LIST]
             /NTILES(k) [INTO VAR_LIST]
             /NORMAL [INTO VAR_LIST]
             /PERCENT [INTO VAR_LIST]
             /RFRACTION [INTO VAR_LIST]
             /PROPORTION [INTO VAR_LIST]
             /N [INTO VAR_LIST]
             /SAVAGE [INTO VAR_LIST]

   The ‘RANK’ command ranks variables and stores the results into new
variables.

   The ‘VARIABLES’ subcommand, which is mandatory, specifies one or more
variables whose values are to be ranked.  After each variable, ‘A’ or
‘D’ may appear, indicating that the variable is to be ranked in
ascending or descending order.  Ascending is the default.  If a ‘BY’
keyword appears, it should be followed by a list of variables which are
to serve as group variables.  In this case, the cases are gathered into
groups, and ranks calculated for each group.

   The ‘TIES’ subcommand specifies how tied values are to be treated.
The default is to take the mean value of all the tied cases.

   The ‘FRACTION’ subcommand specifies how proportional ranks are to be
calculated.  This only has any effect if ‘NORMAL’ or ‘PROPORTIONAL’ rank
functions are requested.

   The ‘PRINT’ subcommand may be used to specify that a summary of the
rank variables created should appear in the output.

   The function subcommands are ‘RANK’, ‘NTILES’, ‘NORMAL’, ‘PERCENT’,
‘RFRACTION’, ‘PROPORTION’ and ‘SAVAGE’.  Any number of function
subcommands may appear.  If none are given, then the default is RANK.
The ‘NTILES’ subcommand must take an integer specifying the number of
partitions into which values should be ranked.  Each subcommand may be
followed by the ‘INTO’ keyword and a list of variables which are the
variables to be created and receive the rank scores.  There may be as
many variables specified as there are variables named on the ‘VARIABLES’
subcommand.  If fewer are specified, then the variable names are
automatically created.

   The ‘MISSING’ subcommand determines how user missing values are to be
treated.  A setting of ‘EXCLUDE’ means that variables whose values are
user-missing are to be excluded from the rank scores.  A setting of
‘INCLUDE’ means they are to be included.  The default is ‘EXCLUDE’.

